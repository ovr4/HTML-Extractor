{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTML_Table_Extract.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovr4/NIST/blob/main/HTML_Table_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rBKXM8eJkSq"
      },
      "source": [
        "## **This program extracts tabular data from cement/concrete research articles**\n",
        "![PIPELINE2.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRUEcrJSDfHN"
      },
      "source": [
        "**Installing additional Python Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqtlsbMU3Llk"
      },
      "source": [
        "#pip install bleach\n",
        "#pip install beautifulsoup4\n",
        "#pip install units\n",
        "#pip install pint"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BndEoJccdqLy",
        "outputId": "fdb28a7e-79c9-46a2-dd1e-a3041d655c60"
      },
      "source": [
        "pip install pint"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pint in /usr/local/lib/python3.7/dist-packages (0.17)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pint) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pint) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pint) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pint) (2.4.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjW6diu3duLZ",
        "outputId": "1b794f6e-963b-4265-f46b-7e6204f640bf"
      },
      "source": [
        "pip install units"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: units in /usr/local/lib/python3.7/dist-packages (0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-X4eesJEflx"
      },
      "source": [
        "**Importing additional python libraries/modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UXnKDp0f_Wm"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import bleach\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2OJtOTBEnX3"
      },
      "source": [
        "**Mounting google drive to access html files of articles.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2JR7E_fHdf",
        "outputId": "fff31b8b-8443-47b7-b8e1-c6edfa005085"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G17FzmoPXCyp"
      },
      "source": [
        "**Default CONSTANTS, specified by users, that identify the units, compoounds, raw materials, product identifications to look for when extracting data from the article tables.**\n",
        "\n",
        "**IDS_TO_LOOK_FOR**: This is a list of potential table headers that describe mixture codes. The contents of this list would indicate whether the column of a Table is referring to mixture codes that link various table entries within the article together. \n",
        "\n",
        "*   Example: ['Authors', 'system', 'code', 'ID', 'No.', 'Mix', 'Mixtures', 'Code', 'name', 'mix', 'Mixture', 'Curing', 'Notation' , 'N ']\n",
        "*   Note: Need knowledge of how mixtures of concrete/mortar/paste are labelled in various articles. \n",
        "\n",
        "\n",
        "\n",
        "\t**LIST_OF_ALL_UNITS**: This is a list of units used in the cement/concrete literature. Knowledge of the industry is necessary in this case to identify whether a sequence of strings contains a relevant unit.\n",
        "\n",
        "\n",
        "*   Example: ['%', 'ratio', 'kg/m2', 'kg/m3', 'by cement weight', 'weight', 'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'N', 'N.mm', 'wt. %', 'h1', 'kg/m', 'kg', 'k', 'min', 'hours', 'time', 'set time', 'C', '', 'sec', 'N.mm', 'm2', '']\n",
        "*   Note: Need a much larger unit list to search through to identify units in tables. Search through the literature and identify all the units that have been used and add them to this unit list.\n",
        "\n",
        "\n",
        "\t**COMPOUNDS_TO_LOOK_FOR**: This is a list of compounds that make up the raw materials (cement, fly ash, etc) used to prepare the final products (concrete, mortar). This list should include all potential compounds to look out for in Tables (especially the compositional tables) of articles. \n",
        "\n",
        "\n",
        "*   Example: ['CaO', 'SiO2', 'Al2O3', 'Fe2O3', 'MgO', 'K2O', 'Na2O', 'SO3', 'SrO', 'P2O5', 'TiO2', 'MoO3',  'BaO', 'Cl', 'MnO', 'C3S', 'C2S', 'C3A', 'C4AF', 'ZrO2', 'Cr2O3', 'CuO', 'ZnO', 'Mn2O3', 'LOI', 'Loss on ignition', 'Specific gravity', 'Specific surface', 'Setting time', 'Compressive ', 'Flexural', 'Flexural ', 'Density', 'surface area', 'SSD', 'OD', 'Specific', 'Bulk', 'Blaine', 'gravity', 'sieve']\n",
        "\n",
        "\n",
        "\n",
        "\t**PROP_DICT**: This dictionary (dict) identifies the raw materials that make up the concrete/mortar/paste products. They, along with the COMPOUNDS_TO_LOOK_FOR, form the basis of the compositional table for that article  see P2 function Z for details. The keys in the dictionary refers to the raw material, while the values of each key indicates the synonyms/alternatives names for the raw material. If more raw materials are identified in articles, add their key to the PROP_DICT and include alternative names for this raw material as the keys values. \n",
        "\n",
        "\n",
        "*   \tExample: {'Cement': ['Cement', 'OPC', 'ASTM', 'P.O', 'PO', 'cement'], 'Limestone': ['Limestone', 'Limestone filler', 'LF'], 'Fly ash': ['FA', 'FAM', 'Fly Ash', 'Fly ash'], 'Slag': ['Slag', 'SL'], 'Water': ['Water', 'H2O'], 'Quartz powder': ['Quartz powder'], 'Sand': ['Quartz sand', 'Sand', 'Fine aggregates', 'sand'], 'Coarse': ['Coarse aggregates', 'Coarse '], 'Metakaolin': ['MK'], 'Silica': ['Silica', 'Silica fume']}\n",
        "\n",
        "\n",
        "\t**FINAL_PRODUCTS**: This a dict of the final products to extract from the articles  represented by the key (product names), and values (the alternative names of the products to identify in various tables).\n",
        "\n",
        "*  Example: {'CONCRETE': ['SCC', 'Concrete', 'concrete', 'SCLC', 'HPC', 'UHPC'], 'PASTE': ['paste', 'Paste'], 'MORTAR': ['Mortar', 'mortar', 'grout', 'Grout']}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kjZoIcbO8na"
      },
      "source": [
        "'''CONSTANTS SPECIFIED BY USERS'''\n",
        "\n",
        "## Raw materials \n",
        "PROP_DICT = {'Cement': ['Cement', 'OPC', 'ASTM', 'P.O', 'PO', 'cement'], 'Limestone': ['Limestone', 'Limestone filler', 'LF'], \n",
        "                  'Fly ash': ['FA', 'FAM', 'Fly Ash', 'Fly ash'], 'Slag': ['Slag', 'SL'],\n",
        "                  'Water': ['Water', 'H2O'], 'Quartz powder': ['Quartz powder'],\n",
        "                  'Sand': ['Quartz sand', 'Sand', 'Fine aggregates', 'sand'],\n",
        "                  'Coarse': ['Coarse aggregates', 'Coarse '], 'Metakaolin': ['MK'],\n",
        "                  'Silica': ['Silica', 'Silica fume']}\n",
        "\n",
        "### Final products  \n",
        "FINAL_PRODUCTS = {'CONCRETE': ['SCC', 'Concrete', 'concrete', 'SCLC', 'HPC', 'UHPC'], 'PASTE': ['paste', 'Paste'], 'MORTAR': ['Mortar', 'mortar', 'grout', 'Grout']}\n",
        "\n",
        "\n",
        "###Compositions of materials \n",
        "COMPOUNDS_TO_LOOK_FOR = ['CaO', 'SiO2', 'Al2O3', 'Fe2O3', \n",
        "                            'MgO', 'K2O', 'Na2O', 'SO3', 'SrO', 'P2O5', \n",
        "                            'TiO2', 'MoO3',  'BaO', 'Cl', 'MnO', 'C3S', \n",
        "                            'C2S', 'C3A', 'C4AF', 'ZrO2', 'Cr2O3', 'CuO', \n",
        "                            'ZnO', 'Mn2O3', 'LOI', 'Loss on ignition']\n",
        "\n",
        "\n",
        "\n",
        "###List of all probable units for this subfield\n",
        "LIST_OF_ALL_UNITS = ['%', 'ratio', 'kg/m2', 'kg/m3', 'by cement weight', 'weight',\n",
        "                          'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'N', 'N.mm' \n",
        "                          'wt. %', 'h1', 'kg/m', 'kg', \n",
        "                          'k', 'min', 'hours', 'time', 'set time', 'C', '', 'sec', 'N.mm', 'm2', '', 'nm', \n",
        "                          'kN', 'm2/kg', 'm', 'ml/s', 'N']\n",
        "\n",
        "\n",
        "##Header ID to look for i.e. the likely header name of unique mixtures in article\n",
        "IDS_TO_LOOK_FOR = ['Authors', 'system', 'code', 'ID', 'No.', 'Mix', 'Material', 'Mixtures', 'Code', 'name', 'mix', 'Mixture', 'Notation' , 'N ', 'batch', 'Label', 'label']\n",
        "control_ids = ['Control', 'CO']\n",
        "\n",
        "\n",
        "###Place holders for entries to refer back to \n",
        "place_holder = 'NA'\n",
        "\n",
        "##Making all fixed variables global across all functions\n",
        "global IDS_TO_LOOK_FOR, control_ids\n",
        "global COMPOUNDS_TO_LOOK_FOR\n",
        "global PROP_DICT, FINAL_PRODUCTS\n",
        "global LIST_OF_ALL_UNITS, keep"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA4UApaTs1ij"
      },
      "source": [
        "**Step 1 (Extract Article Tables\n",
        "):** The first step involves of this process entails reading html files and parsing out tabular data from these files. In this step, the Beautifulsoup library was heavily used to read and extract data based on the pertinent html tags associated with table columns and rows in the file. Beautifulsoup uses various html parses but the htmlib4 was chosen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii1N274JgJLt"
      },
      "source": [
        " def get_doi(path): ## returns paper doi - ONLY WORKS FOR SCIENCE-DIRECT FILES\n",
        "  '''this function extracts the doi of the article from its html file'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        path: *str*\n",
        "            A string containing the path of the article to be extracted.\n",
        "\n",
        "        **Returns**\n",
        "          DOI of the article\n",
        "  '''            \n",
        "  soup = BeautifulSoup(path, 'html5lib')\n",
        "  s = soup.find_all('html')\n",
        "  h = s[0].find_all('head')\n",
        "  for mname in h[0].find_all('meta'):\n",
        "      mname = str(mname)\n",
        "      if 'name=\"citation_doi\"' in mname:\n",
        "        doi = mname.split('content=')[1].split('name=')[0]\n",
        "        doi = doi.replace('\"', '')\n",
        "        return doi    \n",
        " \n",
        " class HTMLTableParser:\n",
        "       \n",
        "        def parse_url(self, url):\n",
        "            response = requests.get(url)\n",
        "            soup = BeautifulSoup(response.text, 'xml') #'html5lib', 'html.parser', lxml, lxml-xml, xml \n",
        "            return [(table['id'],self.parse_html_table(table))\\\n",
        "                    for table in soup.find_all('table')]\n",
        "\n",
        "        def parse_html_file(self, path, table_id = 'All'):\n",
        "            ''' This method extracts the tables from articles (i.e. path) and returns each table as a pandas dataFrame, along with its title and table headers'''\n",
        "\n",
        "            '''    **Parameters**\n",
        "\n",
        "                  path: *str*\n",
        "                      A string containing the path of the article to be extracted.\n",
        "                  table_id: *int* or 'All'\n",
        "                      The specific ID of table to be extracted or extract 'All' the tables\n",
        "                \n",
        "                **Returns**\n",
        "                A list of table properties (table title, pandas Dataframe, table headers)\n",
        "            '''\n",
        "            soup = BeautifulSoup(path, 'html5lib') ## lxml or html.parser or xml or html5lib\n",
        "\n",
        "\n",
        "            all_tables = soup.find_all('table')\n",
        "            all_divs = soup.find_all('div')\n",
        "            table_title_index_list, table_title_list = [], []\n",
        "            \n",
        "            for i in all_divs:\n",
        "              table_title = self.parse_html_table_title(i)\n",
        "              if table_title != None:\n",
        "                table_index = int(table_title.split('.')[0].split('Table')[1])\n",
        "\n",
        "                if table_index not in table_title_index_list:\n",
        "                  table_title_index_list.append(table_index)\n",
        "                  table_title_list.append(table_title)\n",
        "              else:\n",
        "                continue\n",
        "            \n",
        "            c_m_p = concrete_mortar_paste(table_title_list)\n",
        "\n",
        "            if table_id == 'All':\n",
        "              all_list = []\n",
        "              new_c_m_p = []\n",
        "              for table, title, c_mp in zip(all_tables, table_title_list, c_m_p):\n",
        "                try:\n",
        "                  all_list.append(self.parse_html_table(table, title, c_mp))                 \n",
        "                except:\n",
        "                  pass\n",
        "              return all_list\n",
        "            else:  \n",
        "              return self.parse_html_table(all_tables[table_id-1], table_title_list[table_id-1], c_m_p[table_id-1])\n",
        "\n",
        "\n",
        "        def parse_html_table_title(self, div): ## returns table name and title\n",
        "          \n",
        "          '''this method extracts the title of a table'''\n",
        "          \n",
        "          if div.find_all('table') != []:\n",
        "\n",
        "            if div.find_all('span') != []:\n",
        "\n",
        "              for spans in div.find_all('span'):\n",
        "\n",
        "                spans = str(spans)\n",
        "                if 'span class=\"label\"' in spans:\n",
        "                  spans_list = spans.split('span class=\"label\"')[1].split('</span>') ## this identifies the Table id\n",
        "                  table_id = spans_list[0]\n",
        "                                  \n",
        "                  \n",
        "                  if 'Table' in table_id:\n",
        "                    table_title = spans_list[1]\n",
        "                    table_title = BeautifulSoup(table_title)\n",
        "                    table_title = table_title.get_text()\n",
        "\n",
        "                    table_title = table_id+table_title\n",
        "                    table_title = table_title.replace('>', '')\n",
        "                    \n",
        "                    return table_title\n",
        "                   \n",
        "          return None\n",
        "\n",
        "        def parse_html_table(self, table, title, c_m_p):\n",
        "            \n",
        "            '''this method returns the table as pandas DataFrame and table headers'''\n",
        "            n_columns = 0\n",
        "            n_rows=0\n",
        "            column_names = []\n",
        "            sub_column_names= []\n",
        "            sub_sub_column_names = []\n",
        "            header_row_count = 0\n",
        "            first_non_header_row = [] \n",
        "            move_to_second_column = False\n",
        "\n",
        "            # Find number of rows and columns, we also find the column titles if we can\n",
        "\n",
        "            for row in table.find_all('tr'):\n",
        "                \n",
        "                # Determine the number of rows in the table\n",
        "                td_tags = row.find_all('td')\n",
        "\n",
        "                holder = 0 \n",
        "\n",
        "                if len(td_tags) >= holder: ### switched from 0 to 1 - assumes that every table has at least two columns\n",
        "                    n_rows+=1\n",
        "                    if n_columns == 0:\n",
        "                        # Set the number of columns for our table\n",
        "                        n_columns = len(td_tags)\n",
        "                        for the_column in td_tags: ## getting the first non header row\n",
        "                          first_non_header_row.append(the_column.get_text())                          \n",
        "                          move_to_second_column = True\n",
        "\n",
        "\n",
        "                        \n",
        "                # Handle column names if we find them\n",
        "                th_tags = row.find_all('th') \n",
        "                if len(th_tags) > 0 and len(column_names) == 0 and header_row_count == 0:\n",
        "                    for th in th_tags:\n",
        "                        column_names.append(th.get_text())                                              \n",
        "                    header_row_count += 1\n",
        "                \n",
        "                # Handle sub_column_names if we find them\n",
        "                elif len(th_tags) > 0 and len(sub_column_names) == 0 and header_row_count == 1:\n",
        "                    for th in th_tags:\n",
        "                      sub_column_names.append(th.get_text())\n",
        "                    header_row_count += 1                \n",
        "                \n",
        "                #Handles the second sub header if we find them\n",
        "                elif len(th_tags) > 0 and len(sub_sub_column_names) == 0 and header_row_count == 2: ## Cases where there are two sub headers\n",
        "                    for th in th_tags:\n",
        "                      sub_sub_column_names.append(th.get_text())                \n",
        "                \n",
        "\n",
        "            header_row_count = 0\n",
        "            colspan_column_names = []\n",
        "            colspan_sub_column_names = []\n",
        "            colspan_sub_sub_column_names = []\n",
        "\n",
        "            for row in table.find_all('tr'):\n",
        "                th_tags = row.find_all('th')\n",
        "                if header_row_count == 0: \n",
        "                  for th in th_tags:\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_column_names.append(1)\n",
        "                  header_row_count += 1\n",
        "\n",
        "                elif header_row_count == 1: \n",
        "                  for th in th_tags:\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_sub_column_names.append(1)                    \n",
        "                  header_row_count += 1\n",
        "\n",
        "                elif header_row_count == 2: \n",
        "                  for th in th_tags:\n",
        "\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_sub_sub_column_names.append(1)\n",
        "                  header_row_count += 1                  \n",
        "                    \n",
        "\n",
        "            def get_rid_of_empty_space(col_name, colspan):\n",
        "              new_col_name = []\n",
        "              new_colspan = []\n",
        "              \n",
        "              for i, j in zip(col_name, colspan):\n",
        "                if i != '':\n",
        "                  new_col_name.append(i)\n",
        "                  new_colspan.append(j)\n",
        "              return new_col_name, new_colspan\n",
        "\n",
        "            def update_empty_space_in_first_row(col_name, colspan):\n",
        "              new_col_name = []\n",
        "              new_colspan = []\n",
        "              use_old_approach = False\n",
        "              empyt_first_column = False\n",
        "              index_track = -1\n",
        "              for i, j in zip(col_name, colspan):\n",
        "                index_track+=1\n",
        "                \n",
        "                if i != '':\n",
        "                  new_col_name.append(i)\n",
        "                  new_colspan.append(j)\n",
        "                \n",
        "                else:  \n",
        "                  if index_track == 0:\n",
        "                    new_col_name.append('Mix / COMP')\n",
        "                    new_colspan.append(1)\n",
        "                    empyt_first_column = True\n",
        "                    use_old_approach = True\n",
        "                  \n",
        "                  else:\n",
        "                    if new_colspan[index_track-1] == 0:\n",
        "                      new_colspan[index_track-1] += 1\n",
        "                    else:\n",
        "                      new_col_name.append('BLANK HEADER')\n",
        "                      new_colspan.append(j)\n",
        "                                 \n",
        "              return new_col_name, new_colspan, use_old_approach\n",
        "            \n",
        "            column_names, colspan_column_names, use_old_approach = update_empty_space_in_first_row(column_names, colspan_column_names)            \n",
        "            \n",
        "            sub_column_names, colspan_sub_column_names = get_rid_of_empty_space(sub_column_names, colspan_sub_column_names)\n",
        "            \n",
        "            sub_sub_column_names, colspan_sub_sub_column_names = get_rid_of_empty_space(sub_sub_column_names, colspan_sub_sub_column_names)\n",
        "\n",
        "            ## Using method 1 to determine column names\n",
        "            if not use_old_approach and max(len(colspan_column_names), len(colspan_sub_column_names), len(colspan_sub_sub_column_names)) != 0: \n",
        "              columns = []\n",
        "              cols_col_index_rec = 0\n",
        "              sub_cols_index_rec = 0\n",
        "              sub_sub_cols_index_rec = 0\n",
        "              full_header_list = []\n",
        "              for col, span in zip(column_names, colspan_column_names):\n",
        "\n",
        "                if span == 1:\n",
        "                  columns.append(col)\n",
        "                  full_header_list.append([col])\n",
        "\n",
        "                else:\n",
        "                  holder_list= [[col]]\n",
        "                  holder_list.append(sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec])\n",
        "                                   \n",
        "                  for sub_index, sub_span in enumerate(colspan_sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec]):\n",
        "\n",
        "                    if sub_span == 1:\n",
        "                      columns.append(sub_column_names[sub_cols_index_rec+sub_index])\n",
        "\n",
        "                    else:\n",
        "                      holder_list.append(sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec])\n",
        "                      for sub_sub_index, sub_sub_span in enumerate(colspan_sub_sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec]):               \n",
        "                        columns.append(sub_sub_column_names[sub_sub_cols_index_rec+sub_sub_index])\n",
        "\n",
        "                  full_header_list.append(holder_list)\n",
        "                  sub_cols_index_rec += span\n",
        "                  sub_sub_cols_index_rec +=  sub_span\n",
        "            \n",
        "            ## Using method 2 (an older approach) to determine column names\n",
        "            else:\n",
        "              columns = old_approach(column_names, sub_column_names, sub_sub_column_names, n_columns)\n",
        "              cols_col_index_rec = 0\n",
        "              sub_cols_index_rec = 0\n",
        "              sub_sub_cols_index_rec = 0\n",
        "              full_header_list = []\n",
        "              for col, span in zip(column_names, colspan_column_names):\n",
        "                if span == 1:\n",
        "                  full_header_list.append([col])\n",
        "                else:\n",
        "                  holder_list= [[col]]\n",
        "                  holder_list.append(sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec])\n",
        "                                   \n",
        "                  for sub_index, sub_span in enumerate(colspan_sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec]):\n",
        "\n",
        "                    if sub_span == 1:\n",
        "                      pass\n",
        "                  \n",
        "                    else:\n",
        "                      holder_list.append(sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec])\n",
        "                    sub_sub_cols_index_rec +=  sub_span\n",
        "                  full_header_list.append(holder_list)\n",
        "                  sub_cols_index_rec += span\n",
        "                  \n",
        "\n",
        "            def priority_headers(columns):\n",
        "              #switch_2 = 1\n",
        "              change_No = False\n",
        "              mix_headers =  [header for header in columns if any(head in header for head in IDS_TO_LOOK_FOR) and not any('('+unit_+')' in header for unit_ in LIST_OF_ALL_UNITS)] ##gets all Ids\n",
        "              \n",
        "              new_columns = []\n",
        "              ##print('O')\n",
        "              for index, col in enumerate(columns):\n",
        "                if col in mix_headers:\n",
        "                  if mix_headers.count(col) > 1:\n",
        "                    new_columns.append('!'*index+str(col))\n",
        "                  else:\n",
        "                    new_columns.append(col)\n",
        "                else:\n",
        "                  new_columns.append(col)\n",
        "              for index, col in enumerate(columns):\n",
        "                if 'No.' in columns and 'No.' not in col and any(header in col for header in IDS_TO_LOOK_FOR):\n",
        "                  switch_2 = index\n",
        "                  change_No = True\n",
        "\n",
        "\n",
        "          \n",
        "              if 'No.' in columns and change_No: ##No and material/mix etc\n",
        "                switch_1 = columns.index('No.')\n",
        "                columns[switch_1] = 'No!'\n",
        "                return columns, switch_1, switch_2\n",
        "\n",
        "              else:\n",
        "                return columns, 1, 1\n",
        "\n",
        "            columns, switch_1, switch_2 = priority_headers(columns)\n",
        "            \n",
        "            \n",
        "\n",
        "\n",
        "            columns = remove_math_symbols(columns)\n",
        "            final_column_names = columns\n",
        "            df = pd.DataFrame(columns = columns,\n",
        "                              index= range(0,n_rows))\n",
        "            \n",
        " \n",
        "\n",
        "            '''Here we build the tables'''\n",
        " \n",
        "            final_row_list = []\n",
        "            final_final_row_list = []\n",
        "            max_copy_rows = -1\n",
        "            \n",
        "            for row_marker, row in enumerate(table.find_all('tr')):\n",
        "                empty = True\n",
        "                column_marker = 0\n",
        "\n",
        "                if row_marker == 0:\n",
        "                  pass\n",
        "                \n",
        "                columns = row.find_all('td')\n",
        "                if len(columns) == len(final_column_names)-1:\n",
        "                  columns=row.find_all(['th', 'td'])\n",
        "\n",
        "\n",
        "                holder_row_list = []\n",
        "               \n",
        "                \n",
        "                if row_marker > max_copy_rows:\n",
        "                  final_final_row_list = []\n",
        "                  for column in columns:\n",
        "                      final_row_list = []\n",
        "                      if 'rowspan' in column.attrs and column.attrs['rowspan'].isdigit():\n",
        "                        number_row = int(column.attrs['rowspan'])                                              \n",
        "                        holder_row_list = [row_marker+ i for i in range(1, number_row)]\n",
        "\n",
        "                        for i in holder_row_list:\n",
        "                          final_row_list.append(i)\n",
        "                        \n",
        "                        final_final_row_list.append(final_row_list)\n",
        "                        max_copy_rows = max(final_row_list)\n",
        "\n",
        "                    \n",
        "                      else:\n",
        "                        final_final_row_list.append([])\n",
        "                        pass\n",
        "\n",
        "\n",
        "                confirm = True\n",
        "                for index, i in enumerate(final_final_row_list):\n",
        "                  if i == []:\n",
        "                    col_index_to_add = index \n",
        "                    confirm = False\n",
        "                    break\n",
        "                                \n",
        "                try:\n",
        "                  new_add_rows_name +=1\n",
        "                except:\n",
        "                  pass\n",
        "                \n",
        "                for col_index, column in enumerate(columns):\n",
        "\n",
        "                    if row_marker in final_final_row_list[col_index]:                      \n",
        "                      add_rows_name +=1                      \n",
        "                      df.iat[row_marker,column_marker] = copy_forward_list[col_index]+'-'+str(new_add_rows_name) #copy_forward+'-'+str(add_rows_name)                                             \n",
        "                      df.iat[row_marker,col_index+col_index_to_add] = column.get_text()\n",
        "\n",
        "                    elif final_final_row_list[col_index] == [] and len(columns) < n_columns:\n",
        "                       df.iat[row_marker,column_marker+col_index_to_add] = column.get_text()\n",
        "                    else:\n",
        "                      df.iat[row_marker,column_marker] = column.get_text()                      \n",
        "                      \n",
        "                      if column_marker == 0:\n",
        "                        copy_forward = column.get_text()\n",
        "                        add_rows_name = 0\n",
        "                        new_add_rows_name = 0\n",
        "                        copy_forward_list = []                        \n",
        "                      copy_forward_list.append(column.get_text())\n",
        "\n",
        "                    column_marker += 1\n",
        "\n",
        "            # Convert to float if possible\n",
        "            for col in df:\n",
        "                try:\n",
        "                    df[col] = df[col].astype(float)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            df.dropna(0, 'all', inplace=True)\n",
        "\n",
        "            if switch_1 == 0:\n",
        "              df = df_column_switch(df, df.columns[switch_1], df.columns[switch_2])\n",
        "              final_column_names = list(df.columns)\n",
        "\n",
        "            \n",
        "            column_is_header = column_checkers(df)\n",
        "            is_first_column_a_header = column_is_header[0]\n",
        "            \n",
        "            \n",
        "            ### this section fills the column and sub_column_names and determines units\n",
        "\n",
        "            if  'BLANK HEADER' not in df.columns:\n",
        "              pass \n",
        "\n",
        "            else:\n",
        "              if is_first_column_a_header and len(sub_column_names) > len(sub_sub_column_names):\n",
        "                if sub_column_names[0] == 'BLANK HEADER':\n",
        "                  final_column_names = [column_names[0]]+sub_column_names[1:]                  \n",
        "                else:  \n",
        "                  final_column_names = [column_names[0]]+sub_column_names\n",
        "                df.columns = final_column_names\n",
        "              elif is_first_column_a_header and len(sub_column_names) < len(sub_sub_column_names):\n",
        "                final_column_names = [column_names[0]]+sub_sub_column_names\n",
        "                df.columns = final_column_names\n",
        "            \n",
        "            if len(sub_column_names) >= len(sub_sub_column_names):\n",
        "              likely_unit_col = column_names\n",
        "              likely_colspan = colspan_column_names\n",
        "            elif len(sub_column_names) < len(sub_sub_column_names):\n",
        "              likely_unit_col = sub_column_names\n",
        "              likely_colspan = colspan_sub_column_names\n",
        "\n",
        "\n",
        "            ## UNIT CLEANING\n",
        "\n",
        "            number_of_same_entries = sum(x == y for x, y in zip(final_column_names, likely_unit_col))\n",
        "            if number_of_same_entries != 0 and number_of_same_entries != len(final_column_names):\n",
        "              if check_units(likely_unit_col).count('No unit') == len(likely_unit_col): ##checking if units are in title\n",
        "                the_unit = check_units(title)\n",
        "                for index, col in enumerate(final_column_names):\n",
        "                  if not column_is_header[index] and not check_units(col, True):\n",
        "                    final_column_names[index] = col +'('+the_unit+')'\n",
        "                    df.columns = final_column_names\n",
        "              else:\n",
        "                the_unit = check_units(likely_unit_col)\n",
        "                for index_p, i in enumerate(range(number_of_same_entries, len(likely_unit_col))):\n",
        "                  from_ = likely_colspan[i-1]*index_p+number_of_same_entries\n",
        "                  try:\n",
        "                    if the_unit[i+1] == 'No unit':\n",
        "                      to_ = from_+ likely_colspan[i]+1\n",
        "                    else:\n",
        "                      to_ = from_+ likely_colspan[i]\n",
        "\n",
        "                  except:\n",
        "                      to_ = from_+ likely_colspan[i]\n",
        "                  \n",
        "                  for index, col in zip(range(from_,to_), final_column_names[from_:to_]):\n",
        "                    if not check_units(col, True):\n",
        "                      final_column_names[index] = likely_unit_col[i]+'/'+ col +'('+the_unit[i]+')'\n",
        "                    else:\n",
        "                      final_column_names[index] = likely_unit_col[i]+'/'+ col\n",
        "                df.columns = final_column_names             \n",
        "            \n",
        "            else:\n",
        "              if check_units(likely_unit_col).count('No unit') == len(likely_unit_col): ##checking if units are in title\n",
        "                the_unit = check_units(title)\n",
        "                for index, col in enumerate(final_column_names):\n",
        "                  if not column_is_header[index] and not check_units(col, True):\n",
        "                    final_column_names[index] = col +'('+the_unit+')'\n",
        "                    df.columns = final_column_names\n",
        "              else:\n",
        "                pass\n",
        "            \n",
        "            ### FINAL STEPS OF CLEANING (AUXILLIARY)\n",
        "\n",
        "            df = swap_first_and_second_column(df)\n",
        "\n",
        "\n",
        "            df = convert_ids_to_string(df)\n",
        "\n",
        "\n",
        "\n",
        "            if should_table_be_transposed(df): ## TRANSPOSE COMPOSTIONAL TABLES              \n",
        "              new_df, new_full_header_list = transpose_table(df)\n",
        "              new_df = make_first_colname_material(new_df)\n",
        "              new_df.columns = clean_table_headers(new_df.columns)\n",
        "              return [title, new_df, column_is_header, new_full_header_list, c_m_p]\n",
        "\n",
        "            df.columns = clean_table_headers(df.columns)\n",
        "            pot_new_df, t_f, new_col_added = special_table(df) \n",
        "\n",
        "\n",
        "            if t_f:\n",
        "              df = pot_new_df.copy(deep = True)\n",
        "            if new_col_added:\n",
        "              column_is_header.append(True)\n",
        "              full_header_list.append([df.columns[-1]])\n",
        "            df = make_first_colname_material(df)\n",
        "\n",
        "\n",
        "            if omit_table(df):\n",
        "              raise Exception('This table has too many empty cells so it wasnt extracted')\n",
        "\n",
        "            \n",
        "            df = sandwhich_table(df, full_header_list, df.columns)\n",
        "            \n",
        "            return [title, df, column_is_header, full_header_list, c_m_p]\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZAN1FEI0Gz"
      },
      "source": [
        "**Step 2 (Link all article Tables by mixture codes):** This process links each table in an article by their mixture identification (e.g. Mix no.) and chemical compositions of raw materials (e.g. OPC and FAM). This results in a aggregated table for each article containing its studied mixtures, their associated material and compositional properties, article DOI, and the article title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6I2D-eBsxoR"
      },
      "source": [
        "class ExtractDF:\n",
        "\n",
        "    '''takes in a list of LISTS - table properties i.e. title, df, column_rows_are_headers, list of headers and sub_headers, and whether to transpose the table or not\n",
        "     for each paper and links the tables together'''\n",
        "\n",
        "    def __init__(self, t_prop, article_title, article_doi):\n",
        "      self.t_prop = t_prop[0]#[0] #'''all tables are linked together'''\n",
        "      self.article_title = article_title\n",
        "      self.doi = article_doi      \n",
        "\n",
        "\n",
        "    def check_improper_table_heading(self):\n",
        "      '''this method updates the tabular headers for tables in a particular articles'''\n",
        "\n",
        "      \n",
        "      df_of_tables = [table[1] for table in self.t_prop]\n",
        "      df_headers = [[header for header in df.columns if any(head in header for head in IDS_TO_LOOK_FOR) and not any('('+unit_+')' in header for unit_ in LIST_OF_ALL_UNITS)] for df in df_of_tables]\n",
        "      df_title = [table[0] for table in self.t_prop]\n",
        "\n",
        "      def update_id_with_title(title):\n",
        "        broken = title.split()\n",
        "        for index, breaks in enumerate(broken):\n",
        "          if any(breaks == unit for unit in LIST_OF_ALL_UNITS):\n",
        "            return ' '.join(broken[index-1:])\n",
        "          elif '%' in breaks:\n",
        "            return ' '.join(broken[index:])\n",
        "\n",
        "        try:\n",
        "          return ' '.join(broken[:5]) ##first 5 entries\n",
        "        except:\n",
        "          return ' '.join(broken[:])\n",
        "              \n",
        "\n",
        "      update_headers = []\n",
        "      checker_list = []\n",
        "      for df1, headers1 in zip(df_of_tables, df_headers):\n",
        "        df1_cols = df1.columns\n",
        "        for df2, headers2 in zip(df_of_tables, df_headers):\n",
        "          df2_cols = df2.columns\n",
        "          if not df1.equals(df2):\n",
        "            for head1 in headers1:\n",
        "              df1_entry = list(df1[head1])\n",
        "              for head2 in headers2:\n",
        "                df2_entry = list(df2[head2])\n",
        "                similar_entry = len(set(df1_entry) & set(df2_entry))\n",
        "                if similar_entry > 0 and head2 != head1:\n",
        "                  new_entry = '/'.join(sorted([head1, head2]))\n",
        "                  old_entry = head1\n",
        "                  if list(df1.columns) not in checker_list: \n",
        "                    update_headers.append([df1, {old_entry: new_entry}])\n",
        "                    checker_list.append(list(df1.columns))\n",
        "      new_df = []\n",
        "      for df in df_of_tables:\n",
        "        got_it = False\n",
        "        for df_to_up in update_headers:\n",
        "          if df_to_up[0].equals(df):\n",
        "           df.rename(columns = df_to_up[1], inplace = True)\n",
        "           new_df.append(df)\n",
        "           got_it = True\n",
        "        if not got_it:\n",
        "          new_df.append(df)\n",
        "        \n",
        "      \n",
        "      new_df_mix_headers = [[header for header in df.columns if any(head in header for head in IDS_TO_LOOK_FOR) and not any('('+unit_+')' in header for unit_ in LIST_OF_ALL_UNITS)] for df in new_df]\n",
        "      '''this method looks for tables that repeat the same columns and first column IDs - see '''\n",
        "      #CASE A same headers and first columns across each table\n",
        "      dict_ = {}\n",
        "      joined_col = []\n",
        "      for n_df, title in zip(new_df, df_title):\n",
        "        columns = ''.join(list(n_df.columns))\n",
        "        mix_ids = ''.join(map(str, list(n_df.iloc[:, 0]))) ##first col only \n",
        "        table_id = int(title.split('.')[0].split('Table')[-1])\n",
        "        joined_col.append([columns, mix_ids, table_id])\n",
        "      \n",
        "      tables_to_check = []\n",
        "      for col1 in joined_col:\n",
        "        for col2 in joined_col:\n",
        "          if col1[2] != col2[2] and len(common(col1[0], col2[0])) >= 0.9*max(len(col1[0]), len(col2[0])):\n",
        "            if len(common(col1[1], col2[1])) >= 0.9*max(len(col1[1]), len(col2[1])):\n",
        "              tables_to_check.append(col1[2])\n",
        "              tables_to_check.append(col2[2])\n",
        "\n",
        "      tables_to_check = list(set(tables_to_check))\n",
        "\n",
        "\n",
        "      for n_df, headers, title in zip(new_df, new_df_mix_headers, df_title):\n",
        "        if any('Table '+str(id) in title for id in tables_to_check):\n",
        "          new_mixture_ids = []\n",
        "\n",
        "          for mix in list(n_df.iloc[:, 0]):\n",
        "            try:\n",
        "              new_mix = str(mix) + '-' + update_id_with_title(''.join(title.split('.')[1]))\n",
        "            except:\n",
        "              new_mix = mix\n",
        "            new_mixture_ids.append(new_mix)          \n",
        "          n_df.iloc[:, 0] = new_mixture_ids\n",
        "\n",
        "      #CASE B Same mixture ID-s within the table \n",
        "      for n_df, headers, title in zip(new_df, new_df_mix_headers, df_title):\n",
        "        columns = n_df.columns\n",
        "        repeat = [] \n",
        "        for index1, header in enumerate(headers):\n",
        "          index_of_header = get_index_positions(list(columns), header)\n",
        "          if len(index_of_header) == 1:\n",
        "            index_of_header = index_of_header[0]\n",
        "            mixture_entries = list(n_df[header])\n",
        "          else:  \n",
        "            repeat.append(header)\n",
        "            break\n",
        "\n",
        "          holder_new = []\n",
        "          holder_rep = []\n",
        "          for mixture in mixture_entries:\n",
        "            if mixture not in holder_new:\n",
        "              holder_new.append(mixture)\n",
        "            else:\n",
        "              holder_rep.append(mixture)\n",
        "          new_mixture_ids = []\n",
        "          for index, mix in enumerate(mixture_entries):\n",
        "\n",
        "            if mix in control_ids:\n",
        "              new_mix = mix + '-' + update_id_with_title(''.join(title.split('.')[1]))\n",
        "              new_mixture_ids.append(new_mix) \n",
        "             \n",
        "            elif mix in holder_rep and not isNaN(mix):\n",
        "              try:\n",
        "                new_mix = mix+'-'+columns[index_of_header+1]+'='+str(n_df.iloc[index, index_of_header+1])\n",
        "              except:\n",
        "                new_mix = mix+'-'+columns[index_of_header+-1]+'='+str(n_df.iloc[index, index_of_header-1])\n",
        "\n",
        "              new_mixture_ids.append(new_mix)\n",
        "            else:\n",
        "               new_mixture_ids.append(mix)\n",
        "\n",
        "          n_df.iloc[:, index_of_header] = new_mixture_ids\n",
        "\n",
        "\n",
        "      for i, n_df in zip(list(range(len(self.t_prop))), new_df):\n",
        "        self.t_prop[i][1] = n_df\n",
        "      \n",
        "      return self.t_prop\n",
        "        \n",
        "\n",
        "    def extract_compositions(self):\n",
        "      '''this method extracts the composition of cement, fly ash and slag in the article'''\n",
        "\n",
        "      keep = []\n",
        "      n_compounds_to_look_for = COMPOUNDS_TO_LOOK_FOR + keep  #+ LIST_OF_ALL_UNITS                            \n",
        "      combinations = [' ', '', '(', ' (']\n",
        "      new_comp = []\n",
        "      for comp in n_compounds_to_look_for:\n",
        "        n_l = [comb1+comp+comb2 for comb1 in combinations for comb2 in combinations]\n",
        "        new_comp = new_comp + n_l\n",
        "\n",
        "      n_compounds_to_look_for = n_compounds_to_look_for + new_comp\n",
        "      full_header_list = []\n",
        "      full_property_list = []\n",
        "      for table_id, table in enumerate(self.t_prop):\n",
        "        df = table[1]\n",
        "        table_columns = df.columns\n",
        "        first_col = table_columns[0]\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "          holder_list = []\n",
        "          header_list = []\n",
        "          for material in PROP_DICT.keys():\n",
        "            if any(prop in str(row[first_col]) for prop in PROP_DICT[material]): ##if material is in table \n",
        "             for cols in table_columns:\n",
        "               if any(comps in str(cols) for comps in n_compounds_to_look_for): ##composition is in row\n",
        "                full_property_list.append(row[cols])\n",
        "                if '(' in row[first_col] and '%' not in row[first_col]:\n",
        "                  full_header_list.append(cols +' in/for '+row[first_col].split('(')[0] + ' ('+material+')' )\n",
        "                else:\n",
        "                  full_header_list.append(cols +' in/for '+row[first_col] + ' ('+material+')' )\n",
        "      final_header = []\n",
        "\n",
        "      holder = []\n",
        "      holder_prop = []\n",
        "      for i, j in zip(full_header_list, full_property_list):\n",
        "        if j != '' and j != np.nan:\n",
        "          material, compound = get_compound_and_material(i)\n",
        "          holder.append(compound +' in/for '+material)\n",
        "          holder_prop.append(j) \n",
        "      full_header_list = holder\n",
        "      full_property_list = holder_prop\n",
        "\n",
        "      for i in full_header_list:\n",
        "        to_add = set(i)\n",
        "        for j in to_add:\n",
        "          if j not in final_header:\n",
        "            final_header.append(j)\n",
        "\n",
        "      final_header = full_header_list\n",
        "      new_df = pd.DataFrame(columns = final_header)\n",
        "      final_row = [np.nan]*len(final_header)\n",
        "      for prop, prop_header in zip(full_property_list, full_header_list):\n",
        "          index_of_val = final_header.index(prop_header)\n",
        "          final_row[index_of_val] = prop\n",
        "      row_series = pd.Series(final_row, index = new_df.columns)\n",
        "\n",
        "      number_nan = row_series.isna().sum(axis = 0)\n",
        "      number_nan = final_row.count(np.nan)\n",
        "      new_df = new_df.append(row_series, ignore_index=True)\n",
        "      new_df = new_df.dropna(thresh=3)\n",
        "      new_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      return new_df\n",
        "\n",
        "    def make_table(self):\n",
        "      ''''extracting propery data based on mixture identification'''\n",
        "\n",
        "      all_id_w_table = []\n",
        "      \n",
        "      \n",
        "      table_id_list = []\n",
        "      table_title_list= []\n",
        "      splitters = [' ', '/', '.']\n",
        "\n",
        "      for table_id, table in enumerate(self.t_prop):\n",
        "        table_id_list.append(int(table[0].split('.')[0].split('Table')[1]))\n",
        "        ids = []\n",
        "        table_title_list.append(table[0])\n",
        "        df_columns = table[1].columns\n",
        "\n",
        "        for splitter in splitters:\n",
        "          for index, col_header in enumerate(table[2]):\n",
        "              if col_header and any(item in df_columns[index].split(splitter) for item in IDS_TO_LOOK_FOR) and not any('('+unit_+')' in df_columns[index].split(splitter) for unit_ in LIST_OF_ALL_UNITS): ## conditionals for \n",
        "\n",
        "                if list(df_columns).count(df_columns[index]) == 1:\n",
        "                  loop_around = table[1][df_columns[index]]\n",
        "                  \n",
        "                else:\n",
        "                  loop_around = table[1].iloc[:, index]\n",
        "                for entries in loop_around:\n",
        "                  if entries not in ids:\n",
        "                    ids.append(entries)\n",
        "        if ids != []:\n",
        "          t_id = int(table[0].split('.')[0].split('Table')[1])\n",
        "          all_id_w_table.append([ids, t_id])      \n",
        "\n",
        "      '''searching for which ids repeat across different tables'''\n",
        "      removable_characters = ['-', '']\n",
        "      non_entry_characters = ['', '']\n",
        "      \n",
        "      for remove in non_entry_characters:\n",
        "        for index, i in enumerate(all_id_w_table):\n",
        "          try:\n",
        "            all_id_w_table[index][0].remove(remove)\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "      ignore_sims = [np.nan, '', 'BLANK', 'RAW CONSTITUENTS']\n",
        "      new_id_list_w_table = []\n",
        "      for remove in removable_characters:\n",
        "        for index, ids_in_table in enumerate(all_id_w_table):\n",
        "          compare_list = list(range(len(all_id_w_table)))\n",
        "          compare_list.remove(index)\n",
        "          ids_to_keep = []\n",
        "          for checking_index in compare_list:\n",
        "              for id1 in ids_in_table[0]:\n",
        "                 for id2 in all_id_w_table[checking_index][0]:\n",
        "                   checker = min(len(str(id1).replace(remove, '')), len(str(id2).replace(remove, '')))\n",
        "                   if len(common(str(id1), str(id2))) >= checker:\n",
        "                      ids_to_keep.append(id1)\n",
        "                   else:\n",
        "                      ids_to_keep.append(id1)        ### DELETE THIS CODE BLOCK IF EDITING                                 \n",
        "          holder_list = []\n",
        "          ids_to_keep = list(dict.fromkeys(ids_to_keep))\n",
        "          for i in ids_to_keep:\n",
        "            if i not in ignore_sims:\n",
        "              holder_list.append(i)\n",
        "          if holder_list != []:\n",
        "             new_id_list_w_table.append([holder_list, ids_in_table[1]])\n",
        "      dictm = {}\n",
        "      \n",
        "      if new_id_list_w_table == []:\n",
        "        new_id_list_w_table = all_id_w_table            \n",
        "\n",
        "      for index, table in enumerate(new_id_list_w_table):\n",
        "        holder = [table[1]]\n",
        "        for index2, table2 in enumerate(new_id_list_w_table):\n",
        "\n",
        "          if index != index2 or len(new_id_list_w_table) == 1:\n",
        "            \n",
        "            for entry in table[0]:\n",
        "              for entry2 in table2[0]:\n",
        "                if entry == entry2:\n",
        "                  if table2[1] not in holder:\n",
        "                    holder.append(table2[1])\n",
        "                dictm[entry] = holder\n",
        "\n",
        "      rows = []\n",
        "      rows_headers = []\n",
        "      headers = []\n",
        "      for key, value in zip(dictm.keys(), dictm.values()):        \n",
        "        for table in value:          \n",
        "          df = self.t_prop[table_id_list.index(table)][1]\n",
        "          for index, cols in enumerate(df.columns):\n",
        "            if list(df.columns).count(df.columns[index]) == 1: ## if col_name not repated in table\n",
        "                list_row = df.loc[df[cols] == key].values.flatten().tolist()\n",
        "                if len(df.columns) != len(list_row):\n",
        "                  number_rep = list_row.count(key)\n",
        "                  for i in range(number_rep):\n",
        "                    m_holder_list = list_row[i*len(df.columns):(i+1)*len(df.columns)]\n",
        "                    index_of_key = m_holder_list.index(key)\n",
        "                    try: \n",
        "                      m_holder_list[index_of_key] = str(key)+'-'+str(df.columns[0])+'='+str(m_holder_list[0])\n",
        "                    except: \n",
        "                      m_holder_list[index_of_key] = str(key)+'-'+str(df.columns[index_of_key + 1])+'='+str(m_holder_list[index_of_key + 1])\n",
        "                    value.sort()\n",
        "                    \n",
        "                    str_value = ['['+str(v)+']' for v in value]\n",
        "                    table_number = ''.join(str_value)\n",
        "                         \n",
        "                    rows.append(m_holder_list+[table_number])\n",
        "                    rows_headers.append(df.columns.tolist()+['Table Entry'])\n",
        "                  list_row = []\n",
        "            else:\n",
        "                mask = df.iloc[:, index] == key\n",
        "                pos = np.flatnonzero(mask)\n",
        "                list_row = df.iloc[pos].values.flatten().tolist()\n",
        "            try:\n",
        "              if list_row != []:\n",
        "                value.sort()\n",
        "                \n",
        "                str_value = ['['+str(v)+']' for v in value]\n",
        "                table_number = ''.join(str_value)\n",
        "                                \n",
        "                rows.append(list_row+[table_number])\n",
        "                rows_headers.append(df.columns.tolist()+['Table Entry'])\n",
        "                for i in df.columns.tolist():\n",
        "                  if i not in headers:\n",
        "                    headers.append(i)\n",
        "              else:\n",
        "                continue\n",
        "            except:\n",
        "              continue\n",
        "      \n",
        "      ### spliting up rows with different IDS in each row\n",
        "      new_rows = []\n",
        "      new_rows_header = []\n",
        "      top_row_index = -1\n",
        "      row_index = -1 \n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "            top_row_index += 1\n",
        "            row_index = -1 \n",
        "            for row2, row_header2 in zip(rows, rows_headers):\n",
        "              row_index += 1 \n",
        "              for index_j, j in enumerate(row2):\n",
        "                if row[0] == j and row != row2 and (index_j != 0):\n",
        "                  for index_i, i in enumerate(row):\n",
        "                    if row_header2[index_j] == row_header[index_i]:# found the id that is present eslewhere or row_header2 == row_header:\n",
        "                      if row_header2.count(row_header2[index_j]) > 1: ## if header is repeated  in the row\n",
        "                        new_row_to_add = row2[index_j:]\n",
        "                        new_row_header_to_add = row_header2[index_j:]\n",
        "                        rows[row_index][index_j:] = '-'\n",
        "                        rows_headers[row_index][index_j:] = '-'                      \n",
        "                        if new_row_to_add not in new_rows:\n",
        "                          new_rows.append(new_row_to_add)\n",
        "                          new_rows_header.append(new_row_header_to_add)\n",
        "\n",
        "      rows = rows+new_rows\n",
        "      rows_headers = rows_headers + new_rows_header\n",
        "      \n",
        "\n",
        "      ## cleaning 0 - removing rows with different dash or blank characters \n",
        "      charac_to_remove = ['', '-', '', '', '']\n",
        "      new_rows = []\n",
        "      new_rows_headers = []\n",
        "      index_a = -1\n",
        "      \n",
        "      for row, header in zip(rows, rows_headers):\n",
        "        index_a +=1\n",
        "        if len(row) != len(header):\n",
        "          continue\n",
        "        holder_list, holder_header = [], []\n",
        "        for index, entry in enumerate(row):\n",
        "           if entry not in charac_to_remove:\n",
        "             holder_list.append(entry)\n",
        "             holder_header.append(header[index])\n",
        "        new_rows.append(holder_list)\n",
        "        new_rows_headers.append(holder_header)\n",
        "\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_headers\n",
        "\n",
        "      \n",
        "\n",
        "      ## cleaning 1 - removing any repeated entries\n",
        "      new_rows = []\n",
        "      new_rows_headers = []\n",
        "      indexz = -1\n",
        "      \n",
        "      for row, header in zip(rows, rows_headers):\n",
        "        indexz += 1\n",
        "        new_row_entry = []\n",
        "        new_header_entry = []\n",
        "        for index, entry in enumerate(row):\n",
        "          if entry not in charac_to_remove:\n",
        "            new_row_entry.append(entry)\n",
        "            new_header_entry.append(header[index])\n",
        "\n",
        "        if new_row_entry not in new_rows:\n",
        "          new_rows.append(new_row_entry)\n",
        "          new_rows_headers.append(new_header_entry)\n",
        "        else:\n",
        "          continue\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_headers\n",
        "\n",
        "      # cleaning 2 - joining all rows with identical first entry i.e. ID\n",
        "      used = []\n",
        "      new_rows = []\n",
        "      new_rows_header = []\n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "          holder_row = row\n",
        "          holder_row_header = row_header\n",
        "          if row[0] not in used:\n",
        "            for row2, row_header2 in zip(rows, rows_headers):\n",
        "              if row != row2 and row[0] not in used:\n",
        "                if row[0] == row2[0]:\n",
        "                  holder_row = holder_row + row2[1:]\n",
        "                  holder_row_header = holder_row_header + row_header2[1:]\n",
        "            used.append(row[0])\n",
        "            new_rows.append(holder_row)\n",
        "            new_rows_header.append(holder_row_header)\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_header\n",
        "\n",
        "      \n",
        "      import itertools\n",
        "      headers = []\n",
        "      for row in rows_headers:\n",
        "        for r in row:\n",
        "          if r not in headers: \n",
        "            headers.append(r)\n",
        "      \n",
        "      \n",
        "      new_df = pd.DataFrame(columns = headers)\n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "          final_row = [np.nan]*len(headers)\n",
        "          for r, r_h in zip(row, row_header):\n",
        "            index_of_val = headers.index(r_h)\n",
        "            final_row[index_of_val] = r\n",
        "          row_series = pd.Series(final_row, index = new_df.columns)\n",
        "          new_df = new_df.append(row_series, ignore_index=True)\n",
        "      new_df = new_df.dropna(thresh=2)\n",
        "      new_df.reset_index(drop=True, inplace=True)\n",
        "      new_df['Article Title'] = len(new_df)*[self.article_title]\n",
        "      new_df['DOI'] = len(new_df)*[self.doi]\n",
        "\n",
        "      ### last step is grouping rows wit identical IDs###\n",
        "      to_group = []\n",
        "      non_group = []\n",
        "      for col in new_df.columns:\n",
        "        if any(ids in col for ids in IDS_TO_LOOK_FOR):\n",
        "          to_group.append(col)\n",
        "        else:\n",
        "          non_group.append(col)\n",
        "      final_new_df = new_df\n",
        "      self.new_df = final_new_df\n",
        "      return final_new_df, table_title_list\n",
        "\n",
        "\n",
        "def join_comp_with_mix(mixtures, compositions):\n",
        "  if len(mixtures) != 0:\n",
        "    new_comp  = pd.DataFrame(np.repeat(compositions.values,len(mixtures),axis=0))\n",
        "    new_comp.columns  = compositions.columns\n",
        "    result = pd.concat([mixtures, new_comp], axis = 1)\n",
        "    return result\n",
        "  else:\n",
        "    return compositions\n",
        "\n",
        "def prettify(df):\n",
        "\n",
        "    ''' CLEANS UP MERGED COMPOSITIONAL AND MIXTURE TABLES ONE LAST TIME'''\n",
        "\n",
        "    df.columns = clean_table_headers(df.columns)\n",
        "    \n",
        "    comp_headers_to_look_for = [j for i in list(PROP_DICT.values()) for j in i]\n",
        "    \n",
        "\n",
        "    df_mix_headers = [header for header in df.columns if any(head in header for head in IDS_TO_LOOK_FOR) and not any(head in header for head in comp_headers_to_look_for) and not any('('+unit_+')' in header for unit_ in LIST_OF_ALL_UNITS)]\n",
        "\n",
        "    df_comp_headers = [header for header in df.columns if any(head in header for head in COMPOUNDS_TO_LOOK_FOR)]\n",
        "    \n",
        "    headers_to_avoid = df_mix_headers+df_comp_headers+['Article Title', 'CONCRETE/MORTAR/PASTE', 'DOI']\n",
        "\n",
        "\n",
        "    for index, header in enumerate(df_mix_headers): #renaming all mixtures columns\n",
        "      new_entry = []\n",
        "      for i in df[header]:\n",
        "          if '()' in str(i):\n",
        "            i = i.replace('()', '')\n",
        "            new_entry.append(i)\n",
        "          else:\n",
        "            new_entry.append(i)\n",
        "      df[header] = new_entry\n",
        "      df = df.rename(columns = {header: 'CODE/MIX TAG-'+str(index+1)})\n",
        "      headers_to_avoid.append('CODE/MIX TAG-'+str(index+1))\n",
        "\n",
        "    for index, header in enumerate(df_comp_headers):\n",
        "      df = df.rename(columns = {header: 'COMPOSITION: '+header})\n",
        "      headers_to_avoid.append('COMPOSITION: '+header)\n",
        "\n",
        "\n",
        "\n",
        "    for header in df.columns:\n",
        "      if header not in headers_to_avoid:\n",
        "        df  = df.rename(columns = {header: 'PROPERTY: '+header})\n",
        "  \n",
        "\n",
        "    df.sort_index(axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t3alnqFJgb2"
      },
      "source": [
        "**Step 3 (ML-Clustering):** This final process involves merge all the aggregated article tables and gathering all the property headers (e.g. compression strength, Yield Stress) from this final table. We then use a ML-clustering algorithm to group property headers based on their lexical similarity and then assigning uniform labels to each cluster (a new CANONICAL property name). We perform this step because property headers are uniquely named across each research article, so there is a need to keep the naming consistent within our database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f1xUlEUZO4z"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, OPTICS, Birch\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import nltk, gensim\n",
        "import pickle\n",
        "#nltk.download('punkt')\n",
        "''' resources = https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm'''\n",
        "\n",
        "def ml_clustering_headers(df, algo = 'agglom', fill_cluster = True, distance_threshold = 0.5, plot_dendo  = True, k = 20, num_feature = 10):\n",
        "  ''' this function runs a clustering algorithm on the table headers to derive a list of synonyms for properties extracted'''\n",
        "  ''' this function '''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        1: *str*\n",
        "            A string containing the path of the article to be extracted.\n",
        "        \n",
        "        2: *int* or 'All'\n",
        "            The specific ID of table to be extracted or extract 'All' the tables\n",
        "      \n",
        "      **Returns**\n",
        "      A list of table properties (table title, pandas Dataframe, table headers)\n",
        "  '''\n",
        "  if True:\n",
        "    properties = df.columns.values.astype(\"U\")\n",
        "    old_properties = []\n",
        "    new_properties = []\n",
        "    units_properties = []\n",
        "    avg_properties = []\n",
        "    to_omit = ['COMPOSITION', 'CODE/MIX TAG', 'Article Title', 'CONCRETE/MORTAR/PASTE', 'DOI', 'in/for']\n",
        "    for prop in properties:\n",
        "      if not any(omit in prop for omit in to_omit):\n",
        "\n",
        "        prop = prop.split('PROPERTY:')[-1]\n",
        "        new_prop, unit = remove_unit(prop)\n",
        "        old_properties.append(prop)\n",
        "        new_properties.append(new_prop)\n",
        "        units_properties.append(unit)\n",
        "\n",
        "    ## storing original properties and units for regrouping in update_final_table function \n",
        "\n",
        "    saved_properties_and_units = [old_properties, units_properties]\n",
        "    \n",
        "\n",
        "    properties = new_properties#.astype(\"U\")\n",
        "\n",
        "\n",
        "    ## Data preprocessing\n",
        "\n",
        "    from pint import UnitRegistry\n",
        "    ureg = UnitRegistry()\n",
        "    check = 10 * ureg('Pa')\n",
        "\n",
        "    ##change text data into unicode and getting feature vectors\n",
        "\n",
        "    ##Bag of words\n",
        "    vectorizer = CountVectorizer(stop_words='english')\n",
        "    features = vectorizer.fit_transform(properties) \n",
        "\n",
        "    ##Tdfif vectorizer - Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "    vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "    features = vectorizer.fit_transform(properties)\n",
        "\n",
        "\n",
        "    ##word2vec features\n",
        "\n",
        "    w2vec_model = gensim.models.word2vec.Word2Vec(properties, size=300,   \n",
        "              window=8, min_count=1, sg=1, iter=30)\n",
        "    mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2vec_model)\n",
        "    #features = mean_embedding_vectorizer.fit_transform(properties) \n",
        "    ##print(features)\n",
        "    if algo == 'k_means':\n",
        "      model = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=1)\n",
        "      plot_dendo = False  \n",
        "    elif algo == 'agglom':\n",
        "      model =  AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold)\n",
        "      features = features.toarray()\n",
        "    elif algo == 'DBSCAN':\n",
        "      model = DBSCAN(eps = 1.0, min_samples=1)\n",
        "      plot_dendo = False\n",
        "    elif algo == 'OPTICS':\n",
        "      model = OPTICS(min_samples =1)\n",
        "      features = features.toarray()\n",
        "      plot_dendo = False\n",
        "    elif algo == 'Birch':\n",
        "      model = Birch(threshold = distance_threshold+0.0, n_clusters=None)\n",
        "      features = features.toarray()\n",
        "      plot_dendo = False\n",
        "\n",
        "    model.fit(features)\n",
        "    \n",
        "    if plot_dendo:\n",
        "      plot_dendrogram(model)\n",
        "    \n",
        "\n",
        "    new_df = pd.DataFrame(columns = ['properties', 'cluster', 'terms'])\n",
        "    new_df['cluster'] = model.labels_\n",
        "    new_df['properties'] = properties\n",
        "\n",
        "    # order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "    terms = vectorizer.get_feature_names()\n",
        "\n",
        "    new_df.sort_values(['cluster'], inplace = True)\n",
        "\n",
        "\n",
        "    df_dict = {}\n",
        "    number_of_headers = len(new_df)\n",
        "    number_of_cluster = int(max(new_df['cluster']))\n",
        "    for i in range(number_of_cluster):\n",
        "      holder = new_df.loc[new_df['cluster'] == i]\n",
        "\n",
        "      df_dict[str(i)] = list(holder['properties']) \n",
        "\n",
        "    \n",
        "    final_df = pd.DataFrame.from_dict(df_dict, orient = 'index')\n",
        "    if fill_cluster: ## IF FALSE, YOU WOULD HAVE TO FILL CLUSTERS MANUALLY VIA THE CSV FILE\n",
        "      #print('A', len(final_df))\n",
        "      holder = []\n",
        "      for i in range(1, len(final_df)+1):\n",
        "        holder.append('A'+str(i))\n",
        "      final_df['Cluster'] = holder\n",
        "      cols = final_df.columns.tolist()\n",
        "      cols = cols[-1:] + cols[:-1]\n",
        "      final_df = final_df[cols]\n",
        "    display(final_df)\n",
        "    f_name = str(number_of_headers)+'_headers_'+str(number_of_cluster)+'_clusters_birch-threshold_'+str(distance_threshold)\n",
        "    final_df.to_csv('/content/drive/My Drive/'+f_name+'.csv', index = True)\n",
        "\n",
        "\n",
        "\n",
        "    pickle.dump(vectorizer, open('/content/drive/My Drive/'+f_name+'_vectorizer.pickle', \"wb\"))\n",
        "    pickle.dump(model, open('/content/drive/My Drive/'+f_name+'_model.pickle', \"wb\"))\n",
        "    pickle.dump(saved_properties_and_units, open('/content/drive/My Drive/'+f_name+'_properties.pickle', \"wb\"))\n",
        "    \n",
        "    return new_df, f_name\n",
        "\n",
        "def update_final_table(df, name_of_properties_file, name_of_cluster_file, name_of_model_object, name_of_vectorizer_file):\n",
        "\n",
        "\n",
        "  ##loading model\n",
        "  vectorizer, model =  pickle.load(open(name_of_vectorizer_file, 'rb')), pickle.load(open(name_of_model_object, 'rb'))\n",
        "  \n",
        "  saved_properties_units = pickle.load(open(name_of_properties_file, 'rb'))\n",
        "  \n",
        "  old_properties, units_properties = saved_properties_units[0], saved_properties_units[1]\n",
        "\n",
        "  derived_df = pd.read_csv(name_of_cluster_file)\n",
        "  \n",
        "\n",
        "  index_of_cluster = list(derived_df.columns).index('Cluster')\n",
        "  label_dic = {}\n",
        "  for index, row in derived_df.iterrows():\n",
        "    new_row = []\n",
        "    holder = []\n",
        "    for index, vals in enumerate(row):\n",
        "      if index > index_of_cluster:\n",
        "        new_row.append(str(vals))\n",
        "\n",
        "    for i in new_row:\n",
        "      for j, k in zip(old_properties, units_properties):\n",
        "        if i in j and k in j: \n",
        "          holder.append('PROPERTY:'+j)\n",
        "\n",
        "        elif i in j and k == 'No unit':\n",
        "          holder.append('PROPERTY:'+j)\n",
        "\n",
        "    label_dic[row['Cluster']] = holder\n",
        "    \n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "  test = 'Yield Paste 32 Stress' ##Yield stress\n",
        "  test = 'Cement 1e31' ## Cement\n",
        "  test = 'ompressives strength' #Compressive Strength\n",
        "\n",
        "  label_test = [['Yield Paste 32 Stress', 'Yield stress'], \n",
        "                ['Cement 1e31', 'Cement'], ['compressive stregth', 'Compressive Strength'],\n",
        "                ['Flo\\ rate', 'Flow rate']]\n",
        "\n",
        "   \n",
        "  for index, testers in enumerate(label_test):\n",
        "\n",
        "    print('TEST ----->', index+1)\n",
        "\n",
        "    test, true_label = testers[0], testers[1]\n",
        "\n",
        "    vectorized_test = vectorizer.transform([test]).toarray()\n",
        "\n",
        "\n",
        "    cluster = model.predict(vectorized_test)[0]\n",
        "    print('Testing Property', test, 'which is meant to be...', true_label)\n",
        "    print('RESULT!')\n",
        "    print('Cluster = ', list(derived_df['Cluster'])[cluster])\n",
        "    other_labels = [i for i in list(derived_df.iloc[cluster])[2:] if str(i) != 'nan']\n",
        "    print('Labels in cluster from training', other_labels)\n",
        "    print('-------------------------------------------')\n",
        "\n",
        "  all_columns = df.columns\n",
        "  print('OLD columns length BEFORE canonical cleaning', len(df.columns))\n",
        "  for key in label_dic.keys():\n",
        "    cols = label_dic[key]\n",
        "\n",
        "    try: \n",
        "      df[key] = df[cols].sum(1)\n",
        "      df = df.drop(cols, 1)      \n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "  print('NEW columns length AFTER canonical cleaning', len(df.columns))\n",
        "  df.to_csv('/content/drive/My Drive/'+f_name+'_dataframe.csv', index = False)\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# A method for generating dendrogram\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    from scipy.cluster.hierarchy import dendrogram\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)\n",
        "\n",
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        transformed_X = []\n",
        "        for document in X:\n",
        "            tokenized_doc = []\n",
        "            for sent in nltk.sent_tokenize(document):\n",
        "                tokenized_doc += nltk.word_tokenize(sent)\n",
        "            transformed_X.append(np.array(tokenized_doc))\n",
        "        return np.array(transformed_X)\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        return self.transform(X)\n",
        "\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(word2vec.wv.syn0[0])\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = MyTokenizer().fit_transform(X)\n",
        "        \n",
        "        return np.array([\n",
        "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        return self.transform(X)\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhsgEec1Hq6p"
      },
      "source": [
        "**Auxilliary functions to help in the data extraction process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3iDL8Yvef63"
      },
      "source": [
        "def convert_ids_to_string(df):\n",
        "  for index, i in enumerate(df.columns):\n",
        "    new_col  = []\n",
        "    if any(header in i for header in IDS_TO_LOOK_FOR):\n",
        "      for j in df.iloc[:, index]:\n",
        "        new_col.append(str(j))\n",
        "      df.iloc[:, index] = new_col\n",
        "  return df\n",
        "\n",
        "def clean_table_headers(columns):\n",
        "    ##clean column units nicely\n",
        "    new_head = []\n",
        "    possible_unit_format = [', ', '-']\n",
        "    for i in columns:\n",
        "      got_it_a, got_it_b = False, False     \n",
        "      i = i.replace('BLANK HEADER/', '')\n",
        "      try:\n",
        "        unit = i.split(')')[0].split('(')[-1]\n",
        "        for format in possible_unit_format:\n",
        "          if format+unit in i and '('+unit+')' in i:# and not got_it_a:\n",
        "            new_name = i.replace(format+unit, '')\n",
        "            got_it_a = True\n",
        "            break\n",
        "          elif int(common('('+unit+')', i, get_length=True)) > 1:# and not got_it_b:\n",
        "            if '('+unit+')/' in i:\n",
        "              new_name = i.replace('('+unit+')/', '/')\n",
        "              got_it_b = True\n",
        "              break\n",
        "        if got_it_b or got_it_a:      \n",
        "          new_head.append(new_name)\n",
        "        else:\n",
        "          new_head.append(i)\n",
        "      except:        \n",
        "          new_head.append(i)\n",
        "    new_head = remove_math_symbols(new_head)\n",
        "    final_header = []\n",
        "    for i in new_head:\n",
        "      if '()' in i:\n",
        "        i = i.replace('()', '')\n",
        "      final_header.append(i)\n",
        "    return final_header\n",
        "\n",
        "def remove_math_symbols(columns):\n",
        "  new_columns = []\n",
        "  for col in columns:\n",
        "    o_col = col\n",
        "    col = str(col)\n",
        "    if '<math>' in col:\n",
        "      new_col = col.split('<math>')[0]\n",
        "      unit = col.split('</math>')[-1]\n",
        "      new_columns.append(new_col+' '+unit)\n",
        "    else:\n",
        "      new_columns.append(o_col)\n",
        "  return new_columns\n",
        "\n",
        "def concrete_mortar_paste(title): \n",
        "  \n",
        "  ''' this function determines whether a table is reporting the concrete, mortar or paste properties'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        title: *str*\n",
        "            The title of the table         \n",
        "      \n",
        "      **Returns**\n",
        "      Label identifying the FINAL_PRODUCTS being reported in the table: Concrete, mortar, or paste\n",
        "  '''\n",
        "\n",
        "\n",
        "  \n",
        "  material_table_list = []\n",
        "  \n",
        "  if type(title) == list:\n",
        "    for i in title:\n",
        "      sum_key = ''\n",
        "      got_it = False\n",
        "      for keys in FINAL_PRODUCTS.keys():\n",
        "        if any(mat in i for mat in FINAL_PRODUCTS[keys]):\n",
        "          if keys not in sum_key:\n",
        "            sum_key += keys+'/'\n",
        "      \n",
        "      if sum_key == '':\n",
        "        material_table_list.append(None)\n",
        "      else:\n",
        "        if sum_key[-1] == '/':\n",
        "          sum_key = sum_key[:-1]\n",
        "        material_table_list.append(sum_key)\n",
        "    return material_table_list\n",
        "  \n",
        "  elif type(title) == str:\n",
        "    sum_key=''\n",
        "    for keys in FINAL_PRODUCTS.keys():\n",
        "      if any(mat in title for mat in FINAL_PRODUCTS[keys]):\n",
        "        if keys not in sum_key:\n",
        "          sum_key += keys+'/'\n",
        "    if sum_key =='':  \n",
        "      return None\n",
        "    else:\n",
        "      if sum_key[-1] == '/':\n",
        "        sum_key = sum_key[:-1]\n",
        "      return sum_key\n",
        "  \n",
        "\n",
        "def check_units(object_to_check, get_all_units_list=False):\n",
        "  '''this function checks if there is unit in a column entry or title and returns the unit'''\n",
        "  \n",
        "  if get_all_units_list:\n",
        "    if type(object_to_check) == str:\n",
        "\n",
        "      for unit in LIST_OF_ALL_UNITS:\n",
        "        if '('+unit+')' in object_to_check or ' '+unit+' ' in object_to_check or '/'+unit in object_to_check or ', '+unit in object_to_check:\n",
        "          return True ## meaning that the column already has a unit\n",
        "\n",
        "  else:\n",
        "    if type(object_to_check) == list:\n",
        "      unit_list = []\n",
        "      \n",
        "      for col in object_to_check:\n",
        "        current_len_unit_list = len(unit_list)\n",
        "        \n",
        "\n",
        "        for unit in LIST_OF_ALL_UNITS:\n",
        "          if '('+unit+')' in col or ' '+unit+' ' in col or '/'+unit in col or ', '+unit in col:\n",
        "            unit_list.append(unit) \n",
        "\n",
        "        if current_len_unit_list == len(unit_list):\n",
        "          unit_list.append('No unit')\n",
        "      return unit_list\n",
        "    \n",
        "    elif type(object_to_check) == str:                  \n",
        "        for unit in LIST_OF_ALL_UNITS:\n",
        "          if '('+unit in object_to_check or '('+unit in object_to_check or '('+unit+')' in object_to_check or ' '+unit+' ' in object_to_check or '/'+unit in object_to_check or ', '+unit in object_to_check:\n",
        "            return unit\n",
        "        if '(' in object_to_check and ')' in object_to_check:\n",
        "          unit = object_to_check.split(')')[0].split('(')[-1]\n",
        "          return unit\n",
        "        elif ', ' in object_to_check:\n",
        "          unit = object_to_check.split(', ')[-1]\n",
        "          return unit          \n",
        "        else:                        \n",
        "          return ''      \n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWrH5et2emVj"
      },
      "source": [
        "def special_table(df):\n",
        "  '''this function handles sepcial tables: see Table 6 in An experimental approach to design self-consolidating concrete - ScienceDirect'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        df: *pandas Dataframe*\n",
        "            A dataframe of the extracted table \n",
        "      \n",
        "      **Returns**\n",
        "      Updated dataFrame \n",
        "  '''\n",
        "\n",
        "  df_headers = [header for header in df.columns if any(head in header for head in IDS_TO_LOOK_FOR)]\n",
        "  number_nan_rows = df.isnull().sum(axis=1).tolist()\n",
        "\n",
        "  if number_nan_rows.count(len(df.columns) -1) > 1:\n",
        "    pass\n",
        "  else:\n",
        "    return False, False, False\n",
        "  count = 0\n",
        "  list_of_appendages= []\n",
        "  new_df = pd.DataFrame(columns = df.columns)\n",
        "  for col in df_headers:\n",
        "    appendage = ''\n",
        "    for index, row in df.iterrows():\n",
        "      final_row = [np.nan] * len(df.columns)\n",
        "      if number_nan_rows[index-1] == len(df.columns)-1 and col == df.columns[0]: ###id must be in first index with all other column entries being Nan\n",
        "        if row[col] != '': \n",
        "          appendage = '-'+row[col]\n",
        "          count += 1 ##number of time auxillary row has an entry\n",
        "        continue\n",
        "      list_of_appendages.append(appendage)      \n",
        "        \n",
        "      for index2, final_col in enumerate(new_df.columns):\n",
        "        if index2 == 0:\n",
        "          final_row[index2] = row[final_col] + appendage\n",
        "        else:\n",
        "          final_row[index2] = row[final_col]\n",
        "      row_series = pd.Series(final_row, index = new_df.columns)\n",
        "      new_df = new_df.append(row_series, ignore_index=True)\n",
        "  if count != 1 or list_of_appendages[0] == '':\n",
        "    return new_df, True, False\n",
        "  else: ## only 1 ancillary entry was found as in - Table 4 in article - The effect of zinc oxide additions on the performance of calcined sodium montmorillonite and illite\n",
        "    first_col = list(new_df[new_df.columns[0]])\n",
        "    updated_columns = ['UPDATED'] + list(new_df.columns[1:])\n",
        "    new_df.columns = updated_columns\n",
        "    new_col = []\n",
        "    for col in first_col:\n",
        "      new_col.append(col.split('-')[0])\n",
        "    new_df['Code'] = new_col\n",
        "    return new_df, True, True \n",
        "\n",
        "def remove_parenthesis(string):\n",
        "  try:\n",
        "    s1 = string.replace('(', '')\n",
        "    s2 = s1.replace(')', '')\n",
        "    return s2\n",
        "  except:\n",
        "    return string\n",
        "\n",
        "def sandwhich_table(df, true_cols, current_col):\n",
        "  '''See Table 2 in Changes in rheology and mechanical properties of ultra-high performance concrete with silica fume content - ScienceDirect'''\n",
        "  header_num = []\n",
        "  for i in true_cols:\n",
        "    header_num.append(len(i))\n",
        "  checker = header_num[1:-1]\n",
        "  final_col = []\n",
        "  for i, j in zip(true_cols, header_num):\n",
        "    if j >1:\n",
        "      for k in i[1]:\n",
        "        unit = check_units(i[0][0])\n",
        "        back = i[0][0].replace(unit, '')\n",
        "\n",
        "        if unit == '':\n",
        "          unit = check_units(k)\n",
        "          k = k.replace(unit, '')\n",
        "\n",
        "        back = remove_parenthesis(back)\n",
        "        k = remove_parenthesis(k)\n",
        "        \n",
        "        if unit != '':\n",
        "          final_col.append(back+'/' + k + ' ('+unit+')')\n",
        "        else:\n",
        "          final_col.append(back+'/' + k)\n",
        "    else:\n",
        "      unit = check_units(i[0])\n",
        "      back = i[0].replace(unit, '')\n",
        "\n",
        "      back = remove_parenthesis(back)\n",
        "      \n",
        "      if unit != '':\n",
        "        final_col.append(back+'/' + ' ('+unit+')')\n",
        "      else:\n",
        "        final_col.append(back)      \n",
        "      \n",
        "  \n",
        "  if any(len(col.split('/'))>2 for col in current_col):\n",
        "    df.columns = final_col\n",
        "    return df\n",
        "  else:\n",
        "    return df "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK8mEfo9dO7N"
      },
      "source": [
        "def should_table_be_transposed(df, thresh = 0.2):\n",
        "\n",
        "    ''' this function determines whether the table extracted from the article should be transposed '''\n",
        "\n",
        "    '''    **Parameters**\n",
        "\n",
        "          df: *pandas DataFrame*\n",
        "              df of the table that is checked.\n",
        "          \n",
        "        **Returns**\n",
        "        True is the table should be transposed, False if it should be kept as is\n",
        "    '''\n",
        "\n",
        "    l_units = []\n",
        "\n",
        "    keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h1', \n",
        "            'min', '(min)', 'time', 'C', 'gravity']\n",
        "\n",
        "    for unit in LIST_OF_ALL_UNITS:\n",
        "      l_units.append('('+unit+')')\n",
        "      l_units.append('('+unit)\n",
        "      l_units.append(unit+')')\n",
        "      if unit in keep:\n",
        "        l_units.append(' '+unit)\n",
        "      \n",
        "\n",
        "    first_col = df.iloc[:, 0]\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    must_transpose = [j for i in list(PROP_DICT.values()) for j in i]\n",
        "        \n",
        "    \n",
        "    store = 0\n",
        "    for col in df.columns[1:]:\n",
        "      if any(header in df.columns[0] for header in IDS_TO_LOOK_FOR) and '()' in col: #any(unit not in col for unit in LIST_OF_ALL_UNITS)):\n",
        "        store+=1\n",
        "    if store == len(df.columns)-1:\n",
        "      return True\n",
        "\n",
        "    if len(df.iloc[:, 0]) <2:\n",
        "      return False\n",
        "    \n",
        "\n",
        "\n",
        "    for entry in first_col:\n",
        "      if not any(header in df.columns[0] for header in IDS_TO_LOOK_FOR) or any(the_col.split('(')[0] in must_transpose for the_col in df.columns):\n",
        "        if any(units in str(entry) for units in l_units):\n",
        "          count += 1\n",
        "        elif any(comps in str(entry) for comps in COMPOUNDS_TO_LOOK_FOR):\n",
        "          count +=1\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    if count >= thresh*len(list(first_col)):\n",
        "      return True\n",
        "\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "def omit_table(df, thresh = 0.5): \n",
        "  '''we omit this table if it contains multiple Nan values - meaning that the table contained blank entries that might correspond to any column \n",
        "  see - Table 3 in 'Changes in rheology and mechanical properties of ultra-high performance concrete with silica fume content '''\n",
        "  '''if half of the tables have nan values greater than half of the entries for a column - then omit table from extraction'''\n",
        "  number_nan = df.isna().sum()\n",
        "  size_df = len(df)\n",
        "  count = 0\n",
        "  for i in number_nan:\n",
        "    if i > size_df*thresh:\n",
        "      count += 1\n",
        "  if count > 1:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def make_first_colname_material(df):\n",
        "    \n",
        "  must_transpose = [j for i in list(PROP_DICT.values()) for j in i]\n",
        "  if any(str(the_col).split('(')[0] in must_transpose for the_col in df[df.columns[0]]):\n",
        "    df = df.rename(columns = {df.columns[0]: 'RAW CONSTITUENTS'})\n",
        "  return df\n",
        "\n",
        "def swap_first_and_second_column(df, thresh = 0.6):\n",
        "\n",
        "    list_of_all_units = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'wt. %', 'h1', 'k']\n",
        "    l_units = []\n",
        "\n",
        "    for unit in list_of_all_units:\n",
        "      l_units.append('('+unit+')')\n",
        "      l_units.append('('+unit)\n",
        "\n",
        "    list_of_all_units = l_units\n",
        "    first_col = df.iloc[:, 0]\n",
        "    second_col = df.iloc[:, 1]\n",
        "    count1 = 0\n",
        "    count2 = 0 \n",
        "\n",
        "    for entry1, entry2 in zip(first_col, second_col):\n",
        "      if any(units in str(entry1) for units in list_of_all_units):\n",
        "        count1 += 1\n",
        "      elif any(comps in str(entry1) for comps in COMPOUNDS_TO_LOOK_FOR):\n",
        "        count1 +=1\n",
        "\n",
        "      if any(units in str(entry2) for units in list_of_all_units):\n",
        "        count2 += 1\n",
        "      elif any(comps in str(entry2) for comps in COMPOUNDS_TO_LOOK_FOR):\n",
        "        count2 +=1\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "\n",
        "    if count1 >= thresh*len(list(first_col)):\n",
        "      return df\n",
        "    elif count2 >= thresh*len(list(first_col)):\n",
        "      df = df_column_switch(df, df.columns[0],df.columns[1])\n",
        "      return df\n",
        "    else:\n",
        "      return df\n",
        "\n",
        "def df_column_switch(df, column1, column2):\n",
        "  i = list(df.columns)\n",
        "  a, b = i.index(column1), i.index(column2)\n",
        "  i[b], i[a] = i[a], i[b]\n",
        "  df = df[i]\n",
        "  return df\n",
        "\n",
        "def transpose_table(df): \n",
        "  '''Takes in old table properties - title, dataframe, col_headers_true_false, and names and returns new props'''\n",
        "  df = df.T.reset_index()\n",
        "  new_header = df.iloc[0] \n",
        "  df = df[1:]\n",
        "  h_list = []\n",
        "  for header in list(new_header):\n",
        "    if header == '':\n",
        "      h_list.append('Code')\n",
        "    else:\n",
        "      h_list.append(header)\n",
        "\n",
        "  df.columns = remove_math_symbols(h_list)\n",
        "\n",
        "  new_titles = []\n",
        "  for col in df.columns:\n",
        "    if col == '':\n",
        "      new_titles.append(['Code'])\n",
        "    else:\n",
        "      new_titles.append([col])\n",
        "\n",
        "  return df, new_titles"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wPbQTEzUDCu"
      },
      "source": [
        "'''Old approach'''\n",
        "def old_approach(column_names, sub_column_names, sub_sub_column_names, n_columns):\n",
        "    for i, name in enumerate(column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        column_names[i] = 'BLANK HEADER'\n",
        "    for i, name in enumerate(sub_column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        sub_column_names[i] = 'BLANK HEADER'\n",
        "    for i, name in enumerate(sub_sub_column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        sub_sub_column_names[i] = 'BLANK HEADER'\n",
        "\n",
        "    if n_columns < max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]): ## case where first column entries are all headers - see Table 1 in ('Mixture design of concrete using simplex centroid design method - ScienceDirect.html'):\n",
        "      first_column_is_header = True\n",
        "      first_row_is_header = False\n",
        "      if max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(column_names):\n",
        "          columns = column_names\n",
        "          \n",
        "      elif max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(sub_column_names):\n",
        "          columns = sub_column_names\n",
        "      elif max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(sub_sub_column_names):\n",
        "          columns = sub_sub_column_names\n",
        "    \n",
        "    elif n_columns >  len(column_names) + len(sub_column_names) + len(sub_sub_column_names): ## handling cases where column headers are missing see Table 8 (Mixture design method of self-compacting lightweight aggregate concrete based on rheological property and strength of mortar - ScienceDirect.html)\n",
        "          first_row_is_header = False\n",
        "          first_column_is_header = True\n",
        "      \n",
        "    else: ##Other cases\n",
        "      first_column_is_header = False\n",
        "      first_row_is_header = False\n",
        "      for i in range(n_columns):\n",
        "        if n_columns == len(column_names) + len(sub_column_names) - i: ## if header and sub_header are perfectly split\n",
        "            columns = column_names[0:len(column_names)-i]+sub_column_names            \n",
        "            break\n",
        "        elif n_columns == len(column_names) + len(sub_sub_column_names) - i: ## if header and second sub_header are perfectly split\n",
        "            columns = column_names[0:len(column_names)-i]+sub_sub_column_names\n",
        "\n",
        "            break\n",
        "        elif n_columns == len(sub_column_names):\n",
        "            columns = sub_column_names\n",
        "            break\n",
        "        elif n_columns == len(column_names):\n",
        "            columns = column_names\n",
        "            break \n",
        "    return columns                                       "
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFLXBRyvzw_"
      },
      "source": [
        "## function to confirm if table header is actually a column of headers - see Table 1 in ('Mixture design of concrete using simplex centroid design method - ScienceDirect.html')\n",
        "def column_checkers(df, thresh = 0.5): ##takes in a pandas dataframe\n",
        "  breakers = [' ', '-', '%', '&', '', '', '<', '']\n",
        "  known_col_header_names = ['No.']\n",
        "  vacant_property_entries = ['', None]\n",
        "  column_is_header = []\n",
        "  for col_index in range(len(df.columns)):\n",
        "    if df.columns[col_index] in known_col_header_names:\n",
        "      column_is_header.append(True)\n",
        "      continue\n",
        "    all_breakers_checker = 0#True\n",
        "    for breaks in breakers:\n",
        "      row_entry_is_property =0\n",
        "      for i in range(len(df)):\n",
        "        first_column_of_row = df.iloc[i][col_index]\n",
        "        is_property = 0\n",
        "        try:\n",
        "          check_if_string = first_column_of_row.split(breaks) ## split by spaces\n",
        "          for j in check_if_string:\n",
        "            try:\n",
        "              float(j)\n",
        "            except:\n",
        "              if j in vacant_property_entries:\n",
        "                is_property +=0\n",
        "              else:\n",
        "                is_property += 1\n",
        "\n",
        "        except:\n",
        "          is_property = 0\n",
        "        if is_property == 0: ## if all the entries converted to a float then the column is not a header\n",
        "          continue\n",
        "        else:\n",
        "          row_entry_is_property +=1\n",
        "    \n",
        "      if row_entry_is_property >= len(df)*thresh: ## if the number of rows in the first column that are properties are greater than 80% of the entire number of columns the column is likely a header\n",
        "        all_breakers_checker +=1  ## meaninng entire column is now classified as a property column \n",
        "      else:\n",
        "        pass\n",
        "    column_is_header.append(bool(all_breakers_checker > thresh * len(breakers)))\n",
        "  return column_is_header\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7cTeXpuxwu8"
      },
      "source": [
        "def remove_unit(string):\n",
        "  '''this function removes strings containing units and returns a string without the unit and the unit itself'''                    \n",
        "  l_units = []\n",
        "\n",
        "  \n",
        "  keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h1', \n",
        "          'min', '(min)', 'time', 'C', 'gravity']\n",
        "\n",
        "  for unit in LIST_OF_ALL_UNITS:\n",
        "    l_units.append('('+unit+')')\n",
        "  for unit in l_units:\n",
        "    if unit in string:\n",
        "      new_string = string.replace(unit, '')\n",
        "      if '()' in new_string:\n",
        "        new_string = new_string.replace('()', '')\n",
        "      return new_string, unit\n",
        "  if '()' in string:\n",
        "    string = string.replace('()', '')\n",
        "  return string, 'No unit'\n",
        "\n",
        "def conversion_to_si(df_columns, unit):\n",
        "  from pint import UnitRegistry\n",
        "  ureg = UnitRegistry()\n",
        "  new_column = []\n",
        "  for i in df_columns:\n",
        "      try:\n",
        "        value = i *ureg(unit)\n",
        "        n_value = value.to_base_units().magnitude\n",
        "      except:\n",
        "        n_value = i\n",
        "      try:\n",
        "        new_column.append(float(n_value))\n",
        "      except: ##cases where value is reported as a string\n",
        "        try:\n",
        "          new_column.append(float(n_value.split()[0]))\n",
        "        except:\n",
        "          new_column.append(0)\n",
        "  return np.nanmean(new_column)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iTdb5uybIzR"
      },
      "source": [
        "'''https://www.geeksforgeeks.org/python-code-#print-common-characters-two-strings-alphabetical-order/'''\n",
        "from collections import Counter \n",
        "def common(str1,str2, get_length = False): \n",
        "      \n",
        "    # convert both strings into counter dictionary \n",
        "    dict1 = Counter(str1) \n",
        "    dict2 = Counter(str2) \n",
        "    \n",
        "    # take intersection of these dictionaries \n",
        "    commonDict = dict1 & dict2 \n",
        "  \n",
        "    if len(commonDict) == 0: \n",
        "        ##print (-1)\n",
        "        return '0'\n",
        "  \n",
        "    # get a list of common elements \n",
        "    commonChars = list(commonDict.elements()) \n",
        "  \n",
        "    # sort list in ascending order to #print resultant \n",
        "    # string on alphabetical order \n",
        "    commonChars = sorted(commonChars) \n",
        "\n",
        "    if get_length:\n",
        "      return len(commonDict)\n",
        "\n",
        "    # join characters without space to produce \n",
        "    # resultant string \n",
        "    return ''.join(commonChars)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLmHYfIF2IRi"
      },
      "source": [
        "def isNaN(num):\n",
        "    try:\n",
        "      if float('-inf') < float(num) < float('inf'):\n",
        "          return False \n",
        "      else:\n",
        "          return True\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "def remove_math_symbols_in_table(df):\n",
        "  for i in df.columns:\n",
        "    new_col = remove_math_symbols(list(df[i]))\n",
        "    df[i] = new_col\n",
        "  return df\n",
        "\n",
        "def get_index_positions(list_of_elems, element):\n",
        "    ''' Returns the indexes of all occurrences of give element in\n",
        "    the list- listOfElements see https://thispointer.com/python-how-to-find-all-indexes-of-an-item-in-a-list/'''\n",
        "    index_pos_list = []\n",
        "    index_pos = 0\n",
        "    while True:\n",
        "        try:\n",
        "            index_pos = list_of_elems.index(element, index_pos)\n",
        "            index_pos_list.append(index_pos)\n",
        "            index_pos += 1\n",
        "        except ValueError as e:\n",
        "            break\n",
        "    return index_pos_list\n",
        "\n",
        "def pandas_should_have_this(df, tab_titles):\n",
        "  '''this function joins rows that have the same mixture entries'''\n",
        "\n",
        "  ## Here we correct the No! and No. discrepancy in the switch funcion in the make table if applicable\n",
        "  no, no_ = [], []\n",
        "  if 'No.' in df.columns and 'No!' in df.columns:\n",
        "    for i in df['No.']:\n",
        "      if not isNaN(i):\n",
        "        try:\n",
        "          new = str(float(i))\n",
        "        except:\n",
        "          new= str(i)\n",
        "        no.append(new)\n",
        "    for i in df['No!']:\n",
        "      if not isNaN(i):\n",
        "        try:\n",
        "          new = str(float(i))\n",
        "        except:\n",
        "          new= str(i)        \n",
        "        no_.append(new)\n",
        "    no__ = no+no_\n",
        "    df['No.'] = no__\n",
        "    del df['No!']\n",
        "\n",
        "  ##Here we clean up entries in table with math symbols\n",
        "  \n",
        "  df = remove_math_symbols_in_table(df)\n",
        "  \n",
        "\n",
        "\n",
        "  must_transpose = [j for i in list(PROP_DICT.values()) for j in i]  \n",
        "\n",
        "  fin_mat_col = '/'.join(material.keys())\n",
        "\n",
        "  df_headers = [header for header in df.columns if any(head in header for head in IDS_TO_LOOK_FOR) and not any(compo in header for compo in must_transpose)]  \n",
        "  new_df_cols = pd.Index(list(df.columns)+[fin_mat_col])\n",
        "  new_df = pd.DataFrame(columns = new_df_cols)\n",
        "  from collections import Counter\n",
        "  checker = []\n",
        "  for col in df_headers:    \n",
        "    check = list(Counter(df[col]).values())\n",
        "    checker.append(sum([1 for i in check if i > 1])) ##number of repeats in frame\n",
        "  try:\n",
        "    col = df_headers[checker.index(max(checker))]\n",
        "  except:\n",
        "    pass\n",
        "      \n",
        "  used = []\n",
        "  \n",
        "  try:\n",
        "    pass\n",
        "  except:\n",
        "    return df\n",
        "  table_id_numbers = [int(i.split('.')[0].split('Table')[1]) for i in tab_titles] #[for i in range(1, len(tab_titles)+1)]\n",
        "  \n",
        "  for index, row in df.iterrows():\n",
        "    found = False\n",
        "    which_tables = [tab_titles[index] for index, i in enumerate(table_id_numbers) if str(i) in row['Table Entry']]\n",
        "    the_material = [mat for mat in [concrete_mortar_paste(t_table) for t_table in which_tables] if mat != None]\n",
        "    try:\n",
        "      if the_material.count(the_material[0]) == len(the_material):\n",
        "        the_material = the_material[0]\n",
        "      else:\n",
        "        the_material = '/'.join(the_material)\n",
        "    except:\n",
        "      the_material = 'UNKNOWN' \n",
        "    for keys in FINAL_PRODUCTS.keys():\n",
        "      if any(mat in str(row[col]) for mat in FINAL_PRODUCTS[keys]):\n",
        "        the_material = concrete_mortar_paste(row[col])\n",
        "        break\n",
        "    for index2, row2 in df.iterrows():\n",
        "      for col1 in df_headers:\n",
        "        for col2 in df_headers:\n",
        "          if row[col1] == row2[col2] and index != index2 and index2 not in used and index not in used:\n",
        "            s1 = pd.Series(row.tolist())\n",
        "            s2 = pd.Series(row2.tolist())\n",
        "            new_row = s1.combine_first(s2)\n",
        "            new_row = new_row.tolist()\n",
        "            s1 = pd.Series(new_row+[the_material], index = new_df_cols)\n",
        "            new_df = new_df.append(s1, ignore_index=True)\n",
        "            used.append(index)\n",
        "            used.append(index2)\n",
        "            found = True\n",
        "            break\n",
        "    if not found and index not in used:\n",
        "      used.append(index)\n",
        "      hold = pd.Index(list(df.columns)+[fin_mat_col])      \n",
        "      s1 = pd.Series(row.tolist()+[the_material], index = new_df_cols)\n",
        "      new_df = new_df.append(s1, ignore_index=True)\n",
        "  return new_df    "
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gKbBTYUCzlz"
      },
      "source": [
        "def get_compound_and_material(string):\n",
        "  material, compound = 'NA', 'NA'\n",
        "  for i in PROP_DICT.keys():\n",
        "    if i in string:\n",
        "      material = i\n",
        "      break\n",
        "  for i in COMPOUNDS_TO_LOOK_FOR:\n",
        "    if i in string:\n",
        "      compound = i\n",
        "      break    \n",
        "  return material, compound"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2MKYeYVLYgZ"
      },
      "source": [
        "**Selecting 'ScienceDirect' files** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC2BqgmzLLA9"
      },
      "source": [
        "import os\n",
        "header_path = '/content/drive/My Drive/SERI_AI_Concrete/data_extraction/html/'\n",
        "list_of_html_files = os.listdir(header_path)\n",
        "content_of_html_files = []\n",
        "new_list_of_html_files = []\n",
        "for i in list_of_html_files:\n",
        "  if '.html' in i and 'ScienceDirect' in i:\n",
        "    contents = open(header_path+i, 'r').read()\n",
        "    content_of_html_files.append(contents)\n",
        "    new_list_of_html_files.append(i)\n",
        "list_of_html_files = new_list_of_html_files[:] "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8kLmDP1K4JQ"
      },
      "source": [
        "**Processing a single article**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJFxcAVOUVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc2872b8-ff9a-4fe0-dea1-20356313848e"
      },
      "source": [
        "## Select article to parse\n",
        "article = list_of_html_files[1] \n",
        "\n",
        "article_name = article.split('.html')[0]\n",
        "\n",
        "article, article1 = open(header_path+article, 'r'), open(header_path+article, 'r')  \n",
        "\n",
        "## Extract DOI from article \n",
        "doi = get_doi(article1)\n",
        "\n",
        "## Run HTML Parser to Extract Tables\n",
        "hp = HTMLTableParser()\n",
        "\n",
        "\n",
        "hp_table = hp.parse_html_file(article, table_id ='All')\n",
        "\n",
        "# hp_table = hp.parse_html_file(article, table_id =4)  \n",
        "# #display(hp_table[1])\n",
        "\n",
        "## Begin STEP 2: Table Linking Process  \n",
        "article_table = ExtractDF([hp_table], article_name, doi).check_improper_table_heading()\n",
        "\n",
        "mixtures, tab_titles = ExtractDF([article_table], article_name, doi).make_table()\n",
        "\n",
        "compositions = ExtractDF([article_table], article_name, doi).extract_compositions()\n",
        "\n",
        "mixtures = pandas_should_have_this(mixtures, tab_titles)\n",
        "new_df = join_comp_with_mix(mixtures,  compositions) ## Here we merge mixtures and compositional tables\n",
        "\n",
        "## Clean up resulting Table and Display Final Table\n",
        "n_df = prettify(new_df)\n",
        "\n",
        "display(n_df)\n",
        "  \n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Title</th>\n",
              "      <th>CODE/MIX TAG-1</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: CaO in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CaO in/for Slag</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Cement</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Slag</th>\n",
              "      <th>COMPOSITION: MgO in/for Cement</th>\n",
              "      <th>COMPOSITION: MgO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: MgO in/for Slag</th>\n",
              "      <th>COMPOSITION: SO3 in/for Cement</th>\n",
              "      <th>COMPOSITION: SO3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: SO3 in/for Slag</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Cement</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Slag</th>\n",
              "      <th>DOI</th>\n",
              "      <th>PROPERTY: CONCRETE/PASTE/MORTAR</th>\n",
              "      <th>PROPERTY: Cement(%)</th>\n",
              "      <th>PROPERTY: Coarse Aggregate(%)</th>\n",
              "      <th>PROPERTY: Compressive Strength /28d(MPa)</th>\n",
              "      <th>PROPERTY: Compressive Strength /3d(MPa)</th>\n",
              "      <th>PROPERTY: Fine Aggregate(%)</th>\n",
              "      <th>PROPERTY: Fly Ash(%)</th>\n",
              "      <th>PROPERTY: Paste(%)</th>\n",
              "      <th>PROPERTY: Plastic Viscosity (Pa.s)</th>\n",
              "      <th>PROPERTY: Slag(%)</th>\n",
              "      <th>PROPERTY: Slump (mm)</th>\n",
              "      <th>PROPERTY: Table Entry</th>\n",
              "      <th>PROPERTY: Yield Stress (Pa)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.36</td>\n",
              "      <td>22.89</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.0</td>\n",
              "      <td>10.72</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>120.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>2</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>44.58</td>\n",
              "      <td>25.81</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>95.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>555.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>3</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>42.0</td>\n",
              "      <td>44.54</td>\n",
              "      <td>24.83</td>\n",
              "      <td>24.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.5</td>\n",
              "      <td>28.64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>125.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>364.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>4</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>42.85</td>\n",
              "      <td>24.95</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>15.53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>205.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>223.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>5</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.0</td>\n",
              "      <td>41.67</td>\n",
              "      <td>24.47</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>21.51</td>\n",
              "      <td>NaN</td>\n",
              "      <td>195.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>247.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>6</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.0</td>\n",
              "      <td>43.11</td>\n",
              "      <td>23.17</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>312.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>7</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.57</td>\n",
              "      <td>22.14</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>21.79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>165.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>288.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>8</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.46</td>\n",
              "      <td>23.38</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>16.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>145.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>9</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.28</td>\n",
              "      <td>24.95</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>18.79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>160.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>339.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>I</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.70</td>\n",
              "      <td>25.13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.56</td>\n",
              "      <td>0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>286.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>II</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.22</td>\n",
              "      <td>10.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.21</td>\n",
              "      <td>0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>250.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>III</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.52</td>\n",
              "      <td>11.64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.19</td>\n",
              "      <td>60</td>\n",
              "      <td>160.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>382.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>IV</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.67</td>\n",
              "      <td>15.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.04</td>\n",
              "      <td>0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>222.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>V</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.11</td>\n",
              "      <td>10.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.07</td>\n",
              "      <td>30</td>\n",
              "      <td>175.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>280.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>VI</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.09</td>\n",
              "      <td>16.81</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.95</td>\n",
              "      <td>30</td>\n",
              "      <td>170.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>264.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>VII</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.29</td>\n",
              "      <td>13.39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.65</td>\n",
              "      <td>20</td>\n",
              "      <td>178.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>203.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Article Title  ... PROPERTY: Yield Stress (Pa)\n",
              "0   Mixture design of concrete using simplex centr...  ...                      120.29\n",
              "1   Mixture design of concrete using simplex centr...  ...                      555.18\n",
              "2   Mixture design of concrete using simplex centr...  ...                      364.71\n",
              "3   Mixture design of concrete using simplex centr...  ...                      223.11\n",
              "4   Mixture design of concrete using simplex centr...  ...                      247.86\n",
              "5   Mixture design of concrete using simplex centr...  ...                      312.25\n",
              "6   Mixture design of concrete using simplex centr...  ...                      288.50\n",
              "7   Mixture design of concrete using simplex centr...  ...                      145.68\n",
              "8   Mixture design of concrete using simplex centr...  ...                      339.42\n",
              "9   Mixture design of concrete using simplex centr...  ...                      286.58\n",
              "10  Mixture design of concrete using simplex centr...  ...                      250.37\n",
              "11  Mixture design of concrete using simplex centr...  ...                      382.92\n",
              "12  Mixture design of concrete using simplex centr...  ...                      222.51\n",
              "13  Mixture design of concrete using simplex centr...  ...                      280.85\n",
              "14  Mixture design of concrete using simplex centr...  ...                      264.64\n",
              "15  Mixture design of concrete using simplex centr...  ...                      203.31\n",
              "\n",
              "[16 rows x 37 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82wDf9CNLsbi"
      },
      "source": [
        "**Aggregating all articles** \n",
        "This rerun the previous cell for all the articles and records the successfully extracted articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrtkHXF4ow2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a733f5-3e53-40f1-98d0-56c5dfe598f4"
      },
      "source": [
        "all_df = 0\n",
        "bad_mix = 0 \n",
        "bad_comp = 0 \n",
        "count_sci = 0\n",
        "count_succ = 0\n",
        "count_merged = 0\n",
        "for article in list_of_html_files:  \n",
        "  if 'ScienceDirect' in article:\n",
        "    count_sci += 1\n",
        "    try:\n",
        "      article_name = article.split('.html')[0]      \n",
        "      article, article1 = open(header_path+article, 'r'), open(header_path+article, 'r')  \n",
        "      doi = get_doi(article1)\n",
        "      hp = HTMLTableParser()\n",
        "\n",
        "      hp_table = hp.parse_html_file(article, table_id ='All')\n",
        "      \n",
        "      article_table = ExtractDF([hp_table], article_name, doi).check_improper_table_heading()\n",
        "      mixtures, tab_titles = ExtractDF([article_table], article_name, doi).make_table()\n",
        "      if len(mixtures) == 0:\n",
        "        bad_mix += 1\n",
        "      compositions = ExtractDF([article_table], article_name, doi).extract_compositions()\n",
        "      if len(compositions) == 0:\n",
        "        bad_comp += 1\n",
        "\n",
        "      mixtures = pandas_should_have_this(mixtures, tab_titles)\n",
        "      new_df = join_comp_with_mix(mixtures,  compositions)      \n",
        "      \n",
        "      n_df = prettify(new_df)\n",
        "\n",
        "      try:\n",
        "        if all_df == 0:\n",
        "          all_df = n_df\n",
        "          mix_df = mixtures\n",
        "      except:\n",
        "        try:\n",
        "          all_df = all_df.append(n_df, sort = False, ignore_index = True)\n",
        "          mix_df = mix_df.append(mixtures, sort = False, ignore_index = True)\n",
        "          count_merged += 1\n",
        "        except:\n",
        "          pass\n",
        "      count_succ += 1\n",
        "    except:\n",
        "\n",
        "      pass  \n",
        "all_df.sort_index(axis=1, inplace=True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7eH2vcQiHxp"
      },
      "source": [
        "**Running ML Clustering algorithm for various thresholds**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "Tg0XGKLHdKhk",
        "outputId": "7334ea96-01cc-4d8a-95c4-58cbb8514922"
      },
      "source": [
        "thresh = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "thresh = [0.3]\n",
        "for i in thresh:\n",
        "  clusters, f_name = ml_clustering_headers(all_df, algo = 'Birch', distance_threshold =i) ## does not cluster for composition properties"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:264: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cluster</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1</td>\n",
              "      <td>% change with respect to control*</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A2</td>\n",
              "      <td>Aeff [mm2]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3</td>\n",
              "      <td>OPC12min(but can be estimated from the SRM 2...</td>\n",
              "      <td>40% Silica20min(but can be estimated from th...</td>\n",
              "      <td>40% Silica12min(but can be estimated from th...</td>\n",
              "      <td>40% Limestone20min(but can be estimated from...</td>\n",
              "      <td>40% Limestone12min(but can be estimated from...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A4</td>\n",
              "      <td>Apparent viscosity (Pas)</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A5</td>\n",
              "      <td>OPC20min(but can be estimated from the SRM 2...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>A189</td>\n",
              "      <td>Dosage of each ingredient in the mortar /FAM</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>A190</td>\n",
              "      <td>Dosage of each ingredient in the mortar /Fine...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>A191</td>\n",
              "      <td>Dosage of each ingredient in the mortar /OPC</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>A192</td>\n",
              "      <td>Dosage of each ingredient in the mortar /SP</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>A193</td>\n",
              "      <td>Dosage of each ingredient in the mortar /Water</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows  14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Cluster                                                  0  ...    11    12\n",
              "0        A1                  % change with respect to control*  ...  None  None\n",
              "1        A2                                         Aeff [mm2]  ...  None  None\n",
              "2        A3   OPC12min(but can be estimated from the SRM 2...  ...  None  None\n",
              "3        A4                          Apparent viscosity (Pas)  ...  None  None\n",
              "4        A5   OPC20min(but can be estimated from the SRM 2...  ...  None  None\n",
              "..      ...                                                ...  ...   ...   ...\n",
              "188    A189      Dosage of each ingredient in the mortar /FAM   ...  None  None\n",
              "189    A190   Dosage of each ingredient in the mortar /Fine...  ...  None  None\n",
              "190    A191      Dosage of each ingredient in the mortar /OPC   ...  None  None\n",
              "191    A192       Dosage of each ingredient in the mortar /SP   ...  None  None\n",
              "192    A193    Dosage of each ingredient in the mortar /Water   ...  None  None\n",
              "\n",
              "[193 rows x 14 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVnxDlLDiUcR"
      },
      "source": [
        "**Relabelling final table headers based on clustering algorithm and displaying the final table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjEEoqwF3Xbv",
        "outputId": "bc055bf5-2ccc-4f18-b383-3de55b9e10c7"
      },
      "source": [
        "extention = '/content/drive/My Drive/'\n",
        "df = update_final_table(all_df, extention+f_name+'_properties.pickle', extention+f_name+'.csv', extention+f_name+'_model.pickle', extention+f_name+'_vectorizer.pickle')\n",
        "\n",
        "display(df)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST -----> 1\n",
            "Testing Property Yield Paste 32 Stress which is meant to be... Yield stress\n",
            "RESULT!\n",
            "Cluster =  A88\n",
            "Labels in cluster from training [' Yield Stress ', ' Yield stress ']\n",
            "-------------------------------------------\n",
            "TEST -----> 2\n",
            "Testing Property Cement 1e31 which is meant to be... Cement\n",
            "RESULT!\n",
            "Cluster =  A78\n",
            "Labels in cluster from training [' Cement', ' Cement ', ' Cement ', ' Cement', ' Cement', ' Cement']\n",
            "-------------------------------------------\n",
            "TEST -----> 3\n",
            "Testing Property compressive stregth which is meant to be... Compressive Strength\n",
            "RESULT!\n",
            "Cluster =  A21\n",
            "Labels in cluster from training [' Compressive Strength /3\\u202fd']\n",
            "-------------------------------------------\n",
            "TEST -----> 4\n",
            "Testing Property Flo\\ rate which is meant to be... Flow rate\n",
            "RESULT!\n",
            "Cluster =  A106\n",
            "Labels in cluster from training [' Flow rate ']\n",
            "-------------------------------------------\n",
            "OLD columns length BEFORE canonical cleaning 331\n",
            "NEW columns length AFTER canonical cleaning 297\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Title</th>\n",
              "      <th>CODE/MIX TAG-1</th>\n",
              "      <th>CODE/MIX TAG-2</th>\n",
              "      <th>CODE/MIX TAG-3</th>\n",
              "      <th>CODE/MIX TAG-4</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Limestone</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Sand</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Silica</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: BaO in/for Cement</th>\n",
              "      <th>COMPOSITION: BaO in/for Sand</th>\n",
              "      <th>COMPOSITION: C2S in/for Cement</th>\n",
              "      <th>COMPOSITION: C3A in/for Cement</th>\n",
              "      <th>COMPOSITION: C3S in/for Cement</th>\n",
              "      <th>COMPOSITION: C4AF in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CaO in/for Limestone</th>\n",
              "      <th>COMPOSITION: CaO in/for Sand</th>\n",
              "      <th>COMPOSITION: CaO in/for Silica</th>\n",
              "      <th>COMPOSITION: CaO in/for Slag</th>\n",
              "      <th>COMPOSITION: Cl in/for Cement</th>\n",
              "      <th>COMPOSITION: Cl in/for Sand</th>\n",
              "      <th>COMPOSITION: Cr2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CuO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Limestone</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Sand</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Silica</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: K2O in/for Cement</th>\n",
              "      <th>COMPOSITION: K2O in/for Fly ash</th>\n",
              "      <th>COMPOSITION: K2O in/for Sand</th>\n",
              "      <th>COMPOSITION: K2O in/for Silica</th>\n",
              "      <th>COMPOSITION: K2O in/for Slag</th>\n",
              "      <th>COMPOSITION: LOI in/for Cement</th>\n",
              "      <th>COMPOSITION: LOI in/for Fly ash</th>\n",
              "      <th>...</th>\n",
              "      <th>A148</th>\n",
              "      <th>A149</th>\n",
              "      <th>A150</th>\n",
              "      <th>A151</th>\n",
              "      <th>A152</th>\n",
              "      <th>A153</th>\n",
              "      <th>A154</th>\n",
              "      <th>A155</th>\n",
              "      <th>A156</th>\n",
              "      <th>A157</th>\n",
              "      <th>A158</th>\n",
              "      <th>A161</th>\n",
              "      <th>A162</th>\n",
              "      <th>A163</th>\n",
              "      <th>A164</th>\n",
              "      <th>A167</th>\n",
              "      <th>A168</th>\n",
              "      <th>A169</th>\n",
              "      <th>A171</th>\n",
              "      <th>A172</th>\n",
              "      <th>A173</th>\n",
              "      <th>A174</th>\n",
              "      <th>A176</th>\n",
              "      <th>A177</th>\n",
              "      <th>A178</th>\n",
              "      <th>A179</th>\n",
              "      <th>A180</th>\n",
              "      <th>A181</th>\n",
              "      <th>A182</th>\n",
              "      <th>A183</th>\n",
              "      <th>A184</th>\n",
              "      <th>A185</th>\n",
              "      <th>A186</th>\n",
              "      <th>A187</th>\n",
              "      <th>A188</th>\n",
              "      <th>A189</th>\n",
              "      <th>A190</th>\n",
              "      <th>A191</th>\n",
              "      <th>A192</th>\n",
              "      <th>A193</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MORTAR</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MORTAR</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1108.0</td>\n",
              "      <td>1026.0</td>\n",
              "      <td>11.2</td>\n",
              "      <td>229.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MORTAR</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1073.0</td>\n",
              "      <td>993.0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>253.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MORTAR</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>963.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>276.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MORTAR</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>934.0</td>\n",
              "      <td>10.2</td>\n",
              "      <td>298.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G70D</td>\n",
              "      <td>Blended cement with 70 % GGBS-3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[4]</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>UNKNOWN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[5]</td>\n",
              "      <td>38.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PASTE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G00-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[5]</td>\n",
              "      <td>20.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PASTE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[5]</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PASTE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G40-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[5]</td>\n",
              "      <td>15.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PASTE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>810 rows  297 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Article Title  ...   A193\n",
              "0    Effects of fly ash microsphere on rheology, ad...  ...    0.0\n",
              "1    Effects of fly ash microsphere on rheology, ad...  ...  229.0\n",
              "2    Effects of fly ash microsphere on rheology, ad...  ...  253.0\n",
              "3    Effects of fly ash microsphere on rheology, ad...  ...  276.0\n",
              "4    Effects of fly ash microsphere on rheology, ad...  ...  298.0\n",
              "..                                                 ...  ...    ...\n",
              "805  Effect of GGBS and curing conditions on streng...  ...    0.0\n",
              "806  Effect of GGBS and curing conditions on streng...  ...    0.0\n",
              "807  Effect of GGBS and curing conditions on streng...  ...    0.0\n",
              "808  Effect of GGBS and curing conditions on streng...  ...    0.0\n",
              "809  Effect of GGBS and curing conditions on streng...  ...    0.0\n",
              "\n",
              "[810 rows x 297 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}