{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HTML_Table_Extract.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtPXSV3QtZjSopvZwrxhcH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovr4/NIST/blob/main/HTML_Table_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQzupsIafvqr"
      },
      "source": [
        "#pip install bleach"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtRs43cCScd_"
      },
      "source": [
        "#pip install beautifulsoup4"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfC9YdWab3LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0c10d8-ae07-4914-b411-a16e32d554fc"
      },
      "source": [
        "pip install pint"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pint in /usr/local/lib/python3.7/dist-packages (0.17)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pint) (4.6.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pint) (21.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pint) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pint) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pint) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqtlsbMU3Llk",
        "outputId": "17af8888-9487-472f-c23a-b00ac742ff5b"
      },
      "source": [
        "pip install units"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: units in /usr/local/lib/python3.7/dist-packages (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rzfbqkUgAvu"
      },
      "source": [
        "This program extracts tabular data from concrete research articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UXnKDp0f_Wm"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import bleach\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2JR7E_fHdf",
        "outputId": "0ed3bb42-6f41-4677-f6c3-aad2f4e024a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G17FzmoPXCyp"
      },
      "source": [
        "The class HTMLTableParser extracts the contents of tables and returns a pandas dataframe of the table, the headers and two layers of sub headers from the table to guide aggregation in a later step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kjZoIcbO8na"
      },
      "source": [
        "'''VARIABLES SPECIFIED BY USERS'''\n",
        "\n",
        "\n",
        "##Materials to determine compositions of \n",
        "prop_dict = {'Cement': ['Cement', 'OPC', 'ASTM', 'P.O', 'P·O', 'cement'], 'Limestone': ['Limestone', 'Limestone filler', 'LF'], \n",
        "                'Fly ash': ['FA', 'FAM', 'Fly Ash', 'Fly ash'], 'Slag': ['Slag', 'SL'],\n",
        "                'Water': ['Water', 'H2O'], 'Quartz powder': ['Quartz powder'],\n",
        "                'Sand': ['Quartz sand', 'Sand', 'Fine aggregates', 'sand'],\n",
        "                'Coarse': ['Coarse aggregates', 'Coarse '], 'Metakaolin': ['MK'],\n",
        "                'Silica': ['Silica', 'Silica fume']}\n",
        "prop_dict = {'Cement': ['Cement', 'OPC', 'ASTM', 'P.O', 'P·O', 'cement'], 'Limestone': ['Limestone', 'Limestone filler', 'LF'], \n",
        "            'Fly ash': ['FA', 'FAM', 'Fly Ash', 'Fly ash'], 'Slag': ['Slag', 'SL'],\n",
        "            'Water': ['Water', 'H2O'], 'Quartz powder': ['Quartz powder'],\n",
        "            'Sand': ['Quartz sand', 'Sand', 'Fine aggregates', 'sand', 'aggregate'],\n",
        "            'Coarse': ['Coarse aggregates', 'Coarse ', 'Aggregate'], 'Metakaolin': ['MK'],\n",
        "            'Silica': ['Silica', 'Silica fume'], 'Other': ['Paste']}\n",
        "\n",
        "prop_dict = {'Cement': ['Cement', 'OPC', 'ASTM', 'P.O', 'P·O', 'cement'], 'Limestone': ['Limestone', 'Limestone filler', 'LF'], \n",
        "                  'Fly ash': ['FA', 'FAM', 'Fly Ash', 'Fly ash'], 'Slag': ['Slag', 'SL'],\n",
        "                  'Water': ['Water', 'H2O'], 'Quartz powder': ['Quartz powder'],\n",
        "                  'Sand': ['Quartz sand', 'Sand', 'Fine aggregates', 'sand'],\n",
        "                  'Coarse': ['Coarse aggregates', 'Coarse '], 'Metakaolin': ['MK'],\n",
        "                  'Silica': ['Silica', 'Silica fume']}\n",
        "\n",
        "### Final products to extract data from  \n",
        "material = {'CONCRETE': ['SCC', 'Concrete', 'concrete', 'SCLC', 'HPC', 'UHPC'], 'PASTE': ['paste', 'Paste'], 'MORTAR': ['Mortar', 'mortar', 'grout', 'Grout']}\n",
        "\n",
        "fin_mat_col = '/'.join(material.keys())\n",
        "#print(fin_mat_col)\n",
        "###Compositions of materials \n",
        "compounds_to_look_for = ['CaO', 'SiO2', 'Al2O3', 'Fe2O3', \n",
        "                            'MgO', 'K2O', 'Na2O', 'SO3', 'SrO', 'P2O5', \n",
        "                            'TiO2', 'MoO3',  'BaO', 'Cl', 'MnO', 'C3S', \n",
        "                            'C2S', 'C3A', 'C4AF', 'ZrO2', 'Cr2O3', 'CuO', \n",
        "                            'ZnO', 'Mn2O3', 'LOI', 'Loss on ignition']\n",
        "\n",
        "compounds_to_look_for = ['CaO', 'SiO2', 'Al2O3', 'Fe2O3', \n",
        "                            'MgO', 'K2O', 'Na2O', 'SO3', 'SrO', 'P2O5', \n",
        "                            'TiO2', 'MoO3',  'BaO', 'Cl', 'MnO', 'C3S', \n",
        "                            'C2S', 'C3A', 'C4AF', 'ZrO2', 'Cr2O3', 'CuO', \n",
        "                            'ZnO', 'Mn2O3', 'LOI', 'Loss on ignition']\n",
        "                            #, 'Specific gravity'\n",
        "                            #'Specific surface', 'Setting time', 'Compressive '\n",
        "                            #'Flexural', 'Flexural ', 'Density', 'surface area', 'SSD', 'OD'\n",
        "                            #'Specific', 'Bulk density', 'Blaine', 'Specific gravity', 'sieve']\n",
        "\n",
        "###List of all probable units for this subfield\n",
        "from pint import UnitRegistry\n",
        "ureg = UnitRegistry()\n",
        "\n",
        "list_of_all_units = ['°C','kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'wt. %', 'h−1', 'k', 'min', 'hours', 'time', 'set time', '°C']\n",
        "list_of_all_units = ['%', 'ratio', 'kg/m2', 'kg/m3', 'by cement weight', 'weight',\n",
        "                          'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'N', 'N.mm' \n",
        "                          'wt. %', 'h−1', 'kg/m', 'kg', \n",
        "                          'k', 'min', 'hours', 'time', 'set time', '°C', 'ηθ', 'sec', 'N.mm', 'm2', 'η', 'nm', \n",
        "                          'kN', 'm2/kg', 'μm', 'ml/s']\n",
        "\n",
        "                               \n",
        "add_ons = ['%', 'ratio', 'weight']\n",
        "\n",
        "def cubic_square_converter(unit):\n",
        "  for i, j in zip(range(2,4), ['square', 'cubic']):\n",
        "    if str(i) in unit:\n",
        "      og_unit = unit.split(str(i))[0]\n",
        "      try:\n",
        "        ureg[og_unit]\n",
        "        new_unit = j+' '+og_unit\n",
        "        unit = unit.replace(og_unit+str(i), new_unit)\n",
        "        return unit \n",
        "      except:\n",
        "        pass\n",
        "    else:\n",
        "      pass\n",
        "  return unit\n",
        "\n",
        "\n",
        "new_column = []\n",
        "##print(unit, df_columns)\n",
        "for i in list_of_all_units:\n",
        "    new_column.append('('+cubic_square_converter(i)+')')\n",
        "t = 1.0*ureg['kg/cubic m']\n",
        "##print(cubic_square_converter('m2'))\n",
        "##print(new_column)\n",
        "for i in new_column:\n",
        "  #unit = i.split('(')[-1].split(')')[0]\n",
        "  #value = 1.0*ureg[unit]  \n",
        "  try:\n",
        "    unit = i.split('(')[-1].split(')')[0]\n",
        "    value = 1.0*ureg[unit]\n",
        "    ##print(value, unit)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h−1', 'min', '(min)', 'time', '°C', 'gravity']\n",
        "keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h−1', \n",
        "            'min', '(min)', 'time', '°C', 'gravity']\n",
        "\n",
        "l_units = []\n",
        "for unit in list_of_all_units:\n",
        "  l_units.append('('+unit+')')\n",
        "  l_units.append('('+unit)\n",
        "  if unit in keep:\n",
        "    l_units.append(' '+unit)\n",
        "\n",
        "##Header ID to look for i.e. the likely header name of unique mixtures in article\n",
        "headers_to_look_for = ['code', 'ID', 'No.', 'Mix', 'Mixtures', 'Code', 'name', 'mix', 'Mixture']\n",
        "headers_to_look_for = ['ID', 'No.', 'Mix', 'Mixtures', 'Code', 'name', 'mix', 'Mixture']\n",
        "headers_to_look_for = ['ID', 'No.', 'Mix', 'Mixtures', 'Code', 'name', 'mix', 'Mixture', 'Material']\n",
        "\n",
        "headers_to_look_for = ['Authors', 'system', 'code', 'ID', 'No.', 'Mix', 'Material', 'Mixtures', 'Code', 'name', 'mix', 'Mixture', 'Notation' , 'N ', 'batch', 'Label', 'label']\n",
        "control_ids = ['Control', 'CO']\n",
        "\n",
        "global headers_to_look_for, control_ids\n",
        "global compounds_to_look_for\n",
        "global prop_dict, material\n",
        "global list_of_all_units, keep\n",
        "###The properties to extract and their synonyms\n",
        "##loaded from excel file\n",
        "\n",
        "\n",
        "#BUILT IN\n",
        "\n",
        "##Used to identify if data is a header or entry\n",
        "breakers = [' ', '-', '%', '&', '–', '≥', '<', '±']\n",
        "\n"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3iDL8Yvef63"
      },
      "source": [
        "def convert_ids_to_string(df):\n",
        "  for index, i in enumerate(df.columns):\n",
        "    new_col  = []\n",
        "    if any(header in i for header in headers_to_look_for):\n",
        "      for j in df.iloc[:, index]:\n",
        "        new_col.append(str(j))\n",
        "      df.iloc[:, index] = new_col\n",
        "  return df\n",
        "\n",
        "def clean_table_headers(columns):\n",
        "    ##clean column units nicely\n",
        "    new_head = []\n",
        "    possible_unit_format = [', ', '-']\n",
        "    for i in columns:\n",
        "      got_it_a, got_it_b = False, False     \n",
        "      i = i.replace('BLANK HEADER/', '')\n",
        "      try:\n",
        "        unit = i.split(')')[0].split('(')[-1]\n",
        "        for format in possible_unit_format:\n",
        "          if format+unit in i and '('+unit+')' in i:# and not got_it_a:\n",
        "            new_name = i.replace(format+unit, '')\n",
        "            got_it_a = True\n",
        "            break\n",
        "          elif int(common('('+unit+')', i, get_length=True)) > 1:# and not got_it_b:\n",
        "            if '('+unit+')/' in i:\n",
        "              new_name = i.replace('('+unit+')/', '/')\n",
        "              got_it_b = True\n",
        "              break\n",
        "        if got_it_b or got_it_a:      \n",
        "          new_head.append(new_name)\n",
        "        else:\n",
        "          new_head.append(i)\n",
        "      except:        \n",
        "          new_head.append(i)\n",
        "    new_head = remove_math_symbols(new_head)\n",
        "    final_header = []\n",
        "    for i in new_head:\n",
        "      if '()' in i:\n",
        "        i = i.replace('()', '')\n",
        "      final_header.append(i)\n",
        "    ##print(final_header)\n",
        "    return final_header\n",
        "\n",
        "def remove_math_symbols(columns):\n",
        "  new_columns = []\n",
        "  for col in columns:\n",
        "    o_col = col\n",
        "    col = str(col)\n",
        "    if '<math>' in col:\n",
        "      new_col = col.split('<math>')[0]\n",
        "      unit = col.split('</math>')[-1]\n",
        "      new_columns.append(new_col+' '+unit)\n",
        "    else:\n",
        "      new_columns.append(o_col)\n",
        "  return new_columns\n",
        "\n",
        "def concrete_mortar_paste(title): \n",
        "  \n",
        "  ''' this function determines whether a table is reporting the concrete, mortar or paste properties'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        title: *str*\n",
        "            The title of the table         \n",
        "      \n",
        "      **Returns**\n",
        "      Label identifying the material being reported in the table: Concrete, mortar, or paste\n",
        "  '''\n",
        "\n",
        "\n",
        "  \n",
        "  material_table_list = []\n",
        "  \n",
        "  if type(title) == list:\n",
        "    for i in title:\n",
        "      sum_key = ''\n",
        "      got_it = False\n",
        "      for keys in material.keys():\n",
        "        if any(mat in i for mat in material[keys]):\n",
        "          if keys not in sum_key:\n",
        "            sum_key += keys+'/'\n",
        "      \n",
        "      if sum_key == '':\n",
        "        material_table_list.append(None)\n",
        "      else:\n",
        "        if sum_key[-1] == '/':\n",
        "          sum_key = sum_key[:-1]\n",
        "        material_table_list.append(sum_key)\n",
        "    return material_table_list\n",
        "  \n",
        "  elif type(title) == str:\n",
        "    sum_key=''\n",
        "    for keys in material.keys():\n",
        "      if any(mat in title for mat in material[keys]):\n",
        "        if keys not in sum_key:\n",
        "          sum_key += keys+'/'\n",
        "    if sum_key =='':  \n",
        "      return None\n",
        "    else:\n",
        "      if sum_key[-1] == '/':\n",
        "        sum_key = sum_key[:-1]\n",
        "      return sum_key\n",
        "  \n",
        "\n",
        "def check_units(object_to_check, get_all_units_list=False):\n",
        "  '''this function checks if there is unit in a column entry or title and returns the unit'''\n",
        "  \n",
        "  if get_all_units_list:\n",
        "    if type(object_to_check) == str:\n",
        "\n",
        "      for unit in list_of_all_units:\n",
        "        if '('+unit+')' in object_to_check or ' '+unit+' ' in object_to_check or '/'+unit in object_to_check or ', '+unit in object_to_check:\n",
        "          return True ## meaning that the column already has a unit\n",
        "\n",
        "  else:\n",
        "    if type(object_to_check) == list:\n",
        "      unit_list = []\n",
        "      \n",
        "      for col in object_to_check:\n",
        "        current_len_unit_list = len(unit_list)\n",
        "        \n",
        "\n",
        "        for unit in list_of_all_units:\n",
        "          if '('+unit+')' in col or ' '+unit+' ' in col or '/'+unit in col or ', '+unit in col:\n",
        "            unit_list.append(unit) \n",
        "\n",
        "        if current_len_unit_list == len(unit_list):\n",
        "          unit_list.append('No unit')\n",
        "      return unit_list\n",
        "    \n",
        "    elif type(object_to_check) == str:                  \n",
        "        for unit in list_of_all_units:\n",
        "          if '('+unit in object_to_check or '('+unit in object_to_check or '('+unit+')' in object_to_check or ' '+unit+' ' in object_to_check or '/'+unit in object_to_check or ', '+unit in object_to_check:\n",
        "            return unit\n",
        "        if '(' in object_to_check and ')' in object_to_check:\n",
        "          unit = object_to_check.split(')')[0].split('(')[-1]\n",
        "          return unit\n",
        "        elif ', ' in object_to_check:\n",
        "          unit = object_to_check.split(', ')[-1]\n",
        "          return unit          \n",
        "        else:                        \n",
        "          return ''      \n"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWrH5et2emVj"
      },
      "source": [
        "def special_table(df):\n",
        "  '''this function handles sepcial tables: see Table 6 in An experimental approach to design self-consolidating concrete - ScienceDirect'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        df: *pandas Dataframe*\n",
        "            A dataframe of the extracted table \n",
        "      \n",
        "      **Returns**\n",
        "      Updated dataFrame \n",
        "  '''\n",
        "\n",
        "  df_headers = [header for header in df.columns if any(head in header for head in headers_to_look_for)]\n",
        "  number_nan_rows = df.isnull().sum(axis=1).tolist()\n",
        "\n",
        "  if number_nan_rows.count(len(df.columns) -1) > 1:\n",
        "    pass\n",
        "  else:\n",
        "    return False, False, False\n",
        "  count = 0\n",
        "  list_of_appendages= []\n",
        "  new_df = pd.DataFrame(columns = df.columns)\n",
        "  for col in df_headers:\n",
        "    appendage = ''\n",
        "    for index, row in df.iterrows():\n",
        "      final_row = [np.nan] * len(df.columns)\n",
        "      if number_nan_rows[index-1] == len(df.columns)-1 and col == df.columns[0]: ###id must be in first index with all other column entries being Nan\n",
        "        if row[col] != '': \n",
        "          appendage = '-'+row[col]\n",
        "          count += 1 ##number of time auxillary row has an entry\n",
        "        continue\n",
        "      list_of_appendages.append(appendage)      \n",
        "        \n",
        "      for index2, final_col in enumerate(new_df.columns):\n",
        "        if index2 == 0:\n",
        "          final_row[index2] = row[final_col] + appendage\n",
        "        else:\n",
        "          final_row[index2] = row[final_col]\n",
        "      row_series = pd.Series(final_row, index = new_df.columns)\n",
        "      new_df = new_df.append(row_series, ignore_index=True)\n",
        "  if count != 1 or list_of_appendages[0] == '':\n",
        "    return new_df, True, False\n",
        "  else: ## only 1 ancillary entry was found as in - Table 4 in article - The effect of zinc oxide additions on the performance of calcined sodium montmorillonite and illite\n",
        "    first_col = list(new_df[new_df.columns[0]])\n",
        "    updated_columns = ['UPDATED'] + list(new_df.columns[1:])\n",
        "    new_df.columns = updated_columns\n",
        "    new_col = []\n",
        "    for col in first_col:\n",
        "      new_col.append(col.split('-')[0])\n",
        "    new_df['Code'] = new_col\n",
        "    return new_df, True, True \n",
        "\n",
        "def remove_parenthesis(string):\n",
        "  try:\n",
        "    s1 = string.replace('(', '')\n",
        "    s2 = s1.replace(')', '')\n",
        "    return s2\n",
        "  except:\n",
        "    return string\n",
        "\n",
        "def sandwhich_table(df, true_cols, current_col):\n",
        "  '''See Table 2 in Changes in rheology and mechanical properties of ultra-high performance concrete with silica fume content - ScienceDirect'''\n",
        "  header_num = []\n",
        "  for i in true_cols:\n",
        "    header_num.append(len(i))\n",
        "  checker = header_num[1:-1]\n",
        "  final_col = []\n",
        "  for i, j in zip(true_cols, header_num):\n",
        "    if j >1:\n",
        "      for k in i[1]:\n",
        "        unit = check_units(i[0][0])\n",
        "        back = i[0][0].replace(unit, '')\n",
        "\n",
        "        if unit == '':\n",
        "          unit = check_units(k)\n",
        "          k = k.replace(unit, '')\n",
        "\n",
        "        back = remove_parenthesis(back)\n",
        "        k = remove_parenthesis(k)\n",
        "        \n",
        "        if unit != '':\n",
        "          final_col.append(back+'/' + k + ' ('+unit+')')\n",
        "        else:\n",
        "          final_col.append(back+'/' + k)\n",
        "    else:\n",
        "      unit = check_units(i[0])\n",
        "      back = i[0].replace(unit, '')\n",
        "\n",
        "      back = remove_parenthesis(back)\n",
        "      \n",
        "      if unit != '':\n",
        "        final_col.append(back+'/' + ' ('+unit+')')\n",
        "      else:\n",
        "        final_col.append(back)      \n",
        "      \n",
        "  \n",
        "  if any(len(col.split('/'))>2 for col in current_col):\n",
        "    df.columns = final_col\n",
        "    ##print('SANDWHICH', final_col)\n",
        "    return df\n",
        "  else:\n",
        "    ##print('NO SANDWHCH')\n",
        "    return df "
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK8mEfo9dO7N"
      },
      "source": [
        "def should_table_be_transposed(df, thresh = 0.2):\n",
        "\n",
        "    ''' this function determines whether the table extracted from the article should be transposed '''\n",
        "\n",
        "    '''    **Parameters**\n",
        "\n",
        "          df: *pandas DataFrame*\n",
        "              df of the table that is checked.\n",
        "          \n",
        "        **Returns**\n",
        "        True is the table should be transposed, False if it should be kept as is\n",
        "    '''\n",
        "\n",
        "    l_units = []\n",
        "\n",
        "    keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h−1', \n",
        "            'min', '(min)', 'time', '°C', 'gravity']\n",
        "\n",
        "    for unit in list_of_all_units:\n",
        "      l_units.append('('+unit+')')\n",
        "      l_units.append('('+unit)\n",
        "      l_units.append(unit+')')\n",
        "      if unit in keep:\n",
        "        l_units.append(' '+unit)\n",
        "      \n",
        "\n",
        "    #list_of_all_units = l_units\n",
        "    first_col = df.iloc[:, 0]\n",
        "    count = 0\n",
        "\n",
        "\n",
        "    must_transpose = [j for i in list(prop_dict.values()) for j in i]\n",
        "        \n",
        "    \n",
        "    store = 0\n",
        "    for col in df.columns[1:]:\n",
        "      if any(header in df.columns[0] for header in headers_to_look_for) and '()' in col: #any(unit not in col for unit in list_of_all_units)):\n",
        "        store+=1\n",
        "    if store == len(df.columns)-1:\n",
        "      return True\n",
        "\n",
        "    if len(df.iloc[:, 0]) <2:\n",
        "      return False\n",
        "    \n",
        "\n",
        "\n",
        "    for entry in first_col:\n",
        "      if not any(header in df.columns[0] for header in headers_to_look_for) or any(the_col.split('(')[0] in must_transpose for the_col in df.columns):\n",
        "        if any(units in str(entry) for units in l_units):\n",
        "          count += 1\n",
        "        elif any(comps in str(entry) for comps in compounds_to_look_for):\n",
        "          count +=1\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    if count >= thresh*len(list(first_col)):\n",
        "      ##print('IT TRANSPOSED!!!!!')\n",
        "      return True\n",
        "\n",
        "    else:\n",
        "      ##print('IT DID NOT TRANSPOSE!!!!!')\n",
        "      return False\n",
        "\n",
        "def omit_table(df, thresh = 0.5): \n",
        "  '''we omit this table if it contains multiple Nan values - meaning that the table contained blank entries that might correspond to any column \n",
        "  see - Table 3 in 'Changes in rheology and mechanical properties of ultra-high performance concrete with silica fume content '''\n",
        "  '''if half of the tables have nan values greater than half of the entries for a column - then omit table from extraction'''\n",
        "  number_nan = df.isna().sum()\n",
        "  size_df = len(df)\n",
        "  count = 0\n",
        "  for i in number_nan:\n",
        "    if i > size_df*thresh:\n",
        "      count += 1\n",
        "  if count > 1:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def make_first_colname_material(df):\n",
        "    \n",
        "  must_transpose = [j for i in list(prop_dict.values()) for j in i]\n",
        "  if any(str(the_col).split('(')[0] in must_transpose for the_col in df[df.columns[0]]):\n",
        "    df = df.rename(columns = {df.columns[0]: 'RAW CONSTITUENTS'})\n",
        "  return df\n",
        "\n",
        "def swap_first_and_second_column(df, thresh = 0.6):\n",
        "\n",
        "    list_of_all_units = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'wt. %', 'h−1', 'k']\n",
        "    l_units = []\n",
        "\n",
        "    for unit in list_of_all_units:\n",
        "      l_units.append('('+unit+')')\n",
        "      l_units.append('('+unit)\n",
        "\n",
        "    list_of_all_units = l_units\n",
        "    first_col = df.iloc[:, 0]\n",
        "    second_col = df.iloc[:, 1]\n",
        "    count1 = 0\n",
        "    count2 = 0 \n",
        "\n",
        "    for entry1, entry2 in zip(first_col, second_col):\n",
        "      if any(units in str(entry1) for units in list_of_all_units):\n",
        "        count1 += 1\n",
        "      elif any(comps in str(entry1) for comps in compounds_to_look_for):\n",
        "        count1 +=1\n",
        "\n",
        "      if any(units in str(entry2) for units in list_of_all_units):\n",
        "        count2 += 1\n",
        "      elif any(comps in str(entry2) for comps in compounds_to_look_for):\n",
        "        count2 +=1\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "\n",
        "    if count1 >= thresh*len(list(first_col)):\n",
        "      return df\n",
        "    elif count2 >= thresh*len(list(first_col)):\n",
        "      df = df_column_switch(df, df.columns[0],df.columns[1])\n",
        "      return df\n",
        "    else:\n",
        "      return df\n",
        "\n",
        "def df_column_switch(df, column1, column2):\n",
        "  i = list(df.columns)\n",
        "  a, b = i.index(column1), i.index(column2)\n",
        "  i[b], i[a] = i[a], i[b]\n",
        "  df = df[i]\n",
        "  return df\n",
        "\n",
        "def transpose_table(df): \n",
        "  '''Takes in old table properties - title, dataframe, col_headers_true_false, and names and returns new props'''\n",
        "  df = df.T.reset_index()\n",
        "  new_header = df.iloc[0] \n",
        "  df = df[1:]\n",
        "  h_list = []\n",
        "  for header in list(new_header):\n",
        "    if header == '':\n",
        "      h_list.append('Code')\n",
        "    else:\n",
        "      h_list.append(header)\n",
        "\n",
        "  df.columns = remove_math_symbols(h_list)\n",
        "\n",
        "  new_titles = []\n",
        "  for col in df.columns:\n",
        "    if col == '':\n",
        "      new_titles.append(['Code'])\n",
        "    else:\n",
        "      new_titles.append([col])\n",
        "\n",
        "  return df, new_titles"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wPbQTEzUDCu"
      },
      "source": [
        "'''Old approach'''\n",
        "def old_approach(column_names, sub_column_names, sub_sub_column_names, n_columns):\n",
        "    for i, name in enumerate(column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        column_names[i] = 'BLANK HEADER'\n",
        "    for i, name in enumerate(sub_column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        sub_column_names[i] = 'BLANK HEADER'\n",
        "    for i, name in enumerate(sub_sub_column_names): ## handling blank header i.e. headers are entries of each column\n",
        "      if name == '':\n",
        "        sub_sub_column_names[i] = 'BLANK HEADER'\n",
        "\n",
        "    if n_columns < max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]): ## case where first column entries are all headers - see Table 1 in ('Mixture design of concrete using simplex centroid design method - ScienceDirect.html'):\n",
        "      first_column_is_header = True\n",
        "      first_row_is_header = False\n",
        "      if max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(column_names):\n",
        "          columns = column_names\n",
        "          \n",
        "      elif max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(sub_column_names):\n",
        "          columns = sub_column_names\n",
        "      elif max([len(column_names), len(sub_column_names), len(sub_sub_column_names)]) == len(sub_sub_column_names):\n",
        "          columns = sub_sub_column_names\n",
        "    \n",
        "    elif n_columns >  len(column_names) + len(sub_column_names) + len(sub_sub_column_names): ## handling cases where column headers are missing see Table 8 (Mixture design method of self-compacting lightweight aggregate concrete based on rheological property and strength of mortar - ScienceDirect.html)\n",
        "          first_row_is_header = False\n",
        "          first_column_is_header = True\n",
        "      \n",
        "    else: ##Other cases\n",
        "      first_column_is_header = False\n",
        "      first_row_is_header = False\n",
        "      for i in range(n_columns):\n",
        "        if n_columns == len(column_names) + len(sub_column_names) - i: ## if header and sub_header are perfectly split\n",
        "            columns = column_names[0:len(column_names)-i]+sub_column_names            \n",
        "            break\n",
        "        elif n_columns == len(column_names) + len(sub_sub_column_names) - i: ## if header and second sub_header are perfectly split\n",
        "            columns = column_names[0:len(column_names)-i]+sub_sub_column_names\n",
        "\n",
        "            break\n",
        "        elif n_columns == len(sub_column_names):\n",
        "            columns = sub_column_names\n",
        "            break\n",
        "        elif n_columns == len(column_names):\n",
        "            columns = column_names\n",
        "            break \n",
        "    return columns                                       "
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFLXBRyvzw_"
      },
      "source": [
        "## function to confirm if table header is actually a column of headers - see Table 1 in ('Mixture design of concrete using simplex centroid design method - ScienceDirect.html')\n",
        "def column_checkers(df, thresh = 0.5): ##takes in a pandas dataframe\n",
        "  breakers = [' ', '-', '%', '&', '–', '≥', '<', '±']\n",
        "  known_col_header_names = ['No.']\n",
        "  vacant_property_entries = ['–', None]\n",
        "  column_is_header = []\n",
        "  for col_index in range(len(df.columns)):\n",
        "    if df.columns[col_index] in known_col_header_names:\n",
        "      column_is_header.append(True)\n",
        "      continue\n",
        "    all_breakers_checker = 0#True\n",
        "    for breaks in breakers:\n",
        "      row_entry_is_property =0\n",
        "      for i in range(len(df)):\n",
        "        first_column_of_row = df.iloc[i][col_index]\n",
        "        is_property = 0\n",
        "        try:\n",
        "          check_if_string = first_column_of_row.split(breaks) ## split by spaces\n",
        "          for j in check_if_string:\n",
        "            try:\n",
        "              float(j)\n",
        "            except:\n",
        "              if j in vacant_property_entries:\n",
        "                is_property +=0\n",
        "              else:\n",
        "                is_property += 1\n",
        "\n",
        "        except:\n",
        "          is_property = 0\n",
        "        if is_property == 0: ## if all the entries converted to a float then the column is not a header\n",
        "          continue\n",
        "        else:\n",
        "          row_entry_is_property +=1\n",
        "    \n",
        "      if row_entry_is_property >= len(df)*thresh: ## if the number of rows in the first column that are properties are greater than 80% of the entire number of columns the column is likely a header\n",
        "        all_breakers_checker +=1  ## meaninng entire column is now classified as a property column \n",
        "      else:\n",
        "        pass\n",
        "    column_is_header.append(bool(all_breakers_checker > thresh * len(breakers)))\n",
        "  return column_is_header\n"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7cTeXpuxwu8"
      },
      "source": [
        "def remove_unit(string):\n",
        "  '''this function removes strings containing units and returns a string without the unit and the unit itself'''\n",
        "  list_of_all_units = ['°C','kg','kg/m', '%', 'ratio', 'kg/m2', 'kg/m3', 'mm', 'Pa', 'Pa.s', 'g', 'MPa', 'wt. %', \n",
        "                         'h−1', 'k', 'min', 'hours', 'time', 'set time', '°C', 'm2/kg', 'μm']\n",
        "  list_of_all_units += ['ml/s']                       \n",
        "  l_units = []\n",
        "\n",
        "  \n",
        "  keep = ['kg', '%', 'ratio', 'kg/m2', 'kg/m3', 'Pa', 'Pa.s', 'MPa', 'wt. %', 'h−1', \n",
        "          'min', '(min)', 'time', '°C', 'gravity']\n",
        "\n",
        "  for unit in list_of_all_units:\n",
        "    l_units.append('('+unit+')')\n",
        "    #l_units.append('('+unit)\n",
        "    #l_units.append(unit+')')\n",
        "    #if unit in keep:\n",
        "      # l_units.append(' '+unit)\n",
        "  for unit in l_units:\n",
        "    if unit in string:\n",
        "      new_string = string.replace(unit, '')\n",
        "      ##print(new_string)\n",
        "      if '()' in new_string:\n",
        "        new_string = new_string.replace('()', '')\n",
        "      return new_string, unit\n",
        "  if '()' in string:\n",
        "    string = string.replace('()', '')\n",
        "  return string, 'No unit'\n",
        "\n",
        "def conversion_to_si(df_columns, unit):\n",
        "  from pint import UnitRegistry\n",
        "  ureg = UnitRegistry()\n",
        "  new_column = []\n",
        "  ##print(unit, df_columns)\n",
        "  for i in df_columns:\n",
        "      ##print(unit)\n",
        "      try:\n",
        "        value = i *ureg(unit)\n",
        "        n_value = value.to_base_units().magnitude\n",
        "      except:\n",
        "        n_value = i\n",
        "      try:\n",
        "        new_column.append(float(n_value))\n",
        "      except: ##cases where value is reported as a string\n",
        "        try:\n",
        "          new_column.append(float(n_value.split()[0]))\n",
        "        except:\n",
        "          new_column.append(0)\n",
        "  ##print(new_column)\n",
        "  return np.nanmean(new_column)\n"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iTdb5uybIzR"
      },
      "source": [
        "'''https://www.geeksforgeeks.org/python-code-#print-common-characters-two-strings-alphabetical-order/'''\n",
        "from collections import Counter \n",
        "def common(str1,str2, get_length = False): \n",
        "      \n",
        "    # convert both strings into counter dictionary \n",
        "    dict1 = Counter(str1) \n",
        "    dict2 = Counter(str2) \n",
        "    \n",
        "    # take intersection of these dictionaries \n",
        "    commonDict = dict1 & dict2 \n",
        "  \n",
        "    if len(commonDict) == 0: \n",
        "        ##print (-1)\n",
        "        return '0'\n",
        "  \n",
        "    # get a list of common elements \n",
        "    commonChars = list(commonDict.elements()) \n",
        "  \n",
        "    # sort list in ascending order to #print resultant \n",
        "    # string on alphabetical order \n",
        "    commonChars = sorted(commonChars) \n",
        "\n",
        "    if get_length:\n",
        "      return len(commonDict)\n",
        "\n",
        "    # join characters without space to produce \n",
        "    # resultant string \n",
        "    return ''.join(commonChars)"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLmHYfIF2IRi"
      },
      "source": [
        "def isNaN(num):\n",
        "    try:\n",
        "      if float('-inf') < float(num) < float('inf'):\n",
        "          return False \n",
        "      else:\n",
        "          return True\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "def remove_math_symbols_in_table(df):\n",
        "  for i in df.columns:\n",
        "    new_col = remove_math_symbols(list(df[i]))\n",
        "    ##print('H', i, new_col)\n",
        "    df[i] = new_col\n",
        "  return df\n",
        "\n",
        "def get_index_positions(list_of_elems, element):\n",
        "    ''' Returns the indexes of all occurrences of give element in\n",
        "    the list- listOfElements see https://thispointer.com/python-how-to-find-all-indexes-of-an-item-in-a-list/'''\n",
        "    index_pos_list = []\n",
        "    index_pos = 0\n",
        "    while True:\n",
        "        try:\n",
        "            # Search for item in list from indexPos to the end of list\n",
        "            index_pos = list_of_elems.index(element, index_pos)\n",
        "            # Add the index position in list\n",
        "            index_pos_list.append(index_pos)\n",
        "            index_pos += 1\n",
        "        except ValueError as e:\n",
        "            break\n",
        "    return index_pos_list\n",
        "\n",
        "def pandas_should_have_this(df, tab_titles):\n",
        "  '''this function joins rows that have the same mixture entries'''\n",
        "\n",
        "  ## Here we correct the No! and No. discrepancy in the switch funcion in the make table if applicable\n",
        "  no, no_ = [], []\n",
        "  if 'No.' in df.columns and 'No!' in df.columns:\n",
        "    for i in df['No.']:\n",
        "      if not isNaN(i):\n",
        "        try:\n",
        "          new = str(float(i))\n",
        "        except:\n",
        "          new= str(i)\n",
        "        no.append(new)\n",
        "    for i in df['No!']:\n",
        "      if not isNaN(i):\n",
        "        try:\n",
        "          new = str(float(i))\n",
        "        except:\n",
        "          new= str(i)        \n",
        "        no_.append(new)\n",
        "    no__ = no+no_\n",
        "    ##print(len(no__), no__)\n",
        "    df['No.'] = no__\n",
        "    del df['No!']\n",
        "\n",
        "  ##Here we clean up entries in table with math symbols\n",
        "  \n",
        "  df = remove_math_symbols_in_table(df)\n",
        "  \n",
        "  ##display(df)\n",
        "\n",
        "\n",
        "  must_transpose = [j for i in list(prop_dict.values()) for j in i]  \n",
        "\n",
        "  fin_mat_col = '/'.join(material.keys())\n",
        "\n",
        "  df_headers = [header for header in df.columns if any(head in header for head in headers_to_look_for) and not any(compo in header for compo in must_transpose)]  \n",
        "  new_df_cols = pd.Index(list(df.columns)+[fin_mat_col])\n",
        "  new_df = pd.DataFrame(columns = new_df_cols)\n",
        "  from collections import Counter\n",
        "  checker = []\n",
        "  ##print('Y', df_headers)\n",
        "  for col in df_headers:    \n",
        "    check = list(Counter(df[col]).values())\n",
        "    ##print(check)\n",
        "    ##print(df[col])#.values())\n",
        "    checker.append(sum([1 for i in check if i > 1])) ##number of repeats in frame\n",
        "  try:\n",
        "    ##print(checker)\n",
        "    col = df_headers[checker.index(max(checker))]\n",
        "  except:\n",
        "    pass\n",
        "      \n",
        "  used = []\n",
        "  \n",
        "  try:\n",
        "    #print('THIS COL', col)\n",
        "    pass\n",
        "  except:\n",
        "    return df\n",
        "  table_id_numbers = [int(i.split('.')[0].split('Table')[1]) for i in tab_titles] #[for i in range(1, len(tab_titles)+1)]\n",
        "  \n",
        "  for index, row in df.iterrows():\n",
        "    found = False\n",
        "    which_tables = [tab_titles[index] for index, i in enumerate(table_id_numbers) if str(i) in row['Table Entry']]\n",
        "    the_material = [mat for mat in [concrete_mortar_paste(t_table) for t_table in which_tables] if mat != None]\n",
        "    try:\n",
        "      if the_material.count(the_material[0]) == len(the_material):\n",
        "        the_material = the_material[0]\n",
        "      else:\n",
        "        the_material = '/'.join(the_material)\n",
        "    except:\n",
        "      the_material = 'UNKNOWN' \n",
        "    for keys in material.keys():\n",
        "      if any(mat in str(row[col]) for mat in material[keys]):\n",
        "        the_material = concrete_mortar_paste(row[col])\n",
        "        break\n",
        "    for index2, row2 in df.iterrows():\n",
        "      for col1 in df_headers:\n",
        "        for col2 in df_headers:\n",
        "          if row[col1] == row2[col2] and index != index2 and index2 not in used and index not in used:\n",
        "            ###print('T', row[col1], row[col2])\n",
        "            s1 = pd.Series(row.tolist())\n",
        "            s2 = pd.Series(row2.tolist())\n",
        "            new_row = s1.combine_first(s2)\n",
        "            new_row = new_row.tolist()\n",
        "            s1 = pd.Series(new_row+[the_material], index = new_df_cols)\n",
        "            new_df = new_df.append(s1, ignore_index=True)\n",
        "            used.append(index)\n",
        "            used.append(index2)\n",
        "            found = True\n",
        "            break\n",
        "    if not found and index not in used:\n",
        "      used.append(index)\n",
        "      hold = pd.Index(list(df.columns)+[fin_mat_col])      \n",
        "      s1 = pd.Series(row.tolist()+[the_material], index = new_df_cols)#df.columns+['CONCRETE/MORTAR/PASTE'])\n",
        "      new_df = new_df.append(s1, ignore_index=True)\n",
        "  return new_df    "
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gKbBTYUCzlz"
      },
      "source": [
        "def get_compound_and_material(string):\n",
        "  material, compound = 'NA', 'NA'\n",
        "  for i in prop_dict.keys():\n",
        "    if i in string:\n",
        "      material = i\n",
        "      break\n",
        "  for i in compounds_to_look_for:\n",
        "    if i in string:\n",
        "      compound = i\n",
        "      break    \n",
        "  return material, compound"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA4UApaTs1ij"
      },
      "source": [
        "**Step 1 (Extract Article Tables\n",
        "):** The first step involves of this process entails reading html files and parsing out tabular data from these files. In this step, the Beautifulsoup library was heavily used to read and extract data based on the pertinent html tags associated with table columns and rows in the file. Beautifulsoup uses various html parses but the htmlib4 was chosen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii1N274JgJLt"
      },
      "source": [
        " def get_doi(path): ## returns paper doi\n",
        "  '''this function extracts the doi of the article from its html file'''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        path: *str*\n",
        "            A string containing the path of the article to be extracted.\n",
        "\n",
        "        **Returns**\n",
        "          DOI of the article\n",
        "  '''            \n",
        "  soup = BeautifulSoup(path, 'html5lib')\n",
        "  s = soup.find_all('html')\n",
        "  h = s[0].find_all('head')\n",
        "  for mname in h[0].find_all('meta'):\n",
        "      mname = str(mname)\n",
        "      if 'name=\"citation_doi\"' in mname:\n",
        "        doi = mname.split('content=')[1].split('name=')[0]\n",
        "        doi = doi.replace('\"', '')\n",
        "        return doi    \n",
        " \n",
        " class HTMLTableParser:\n",
        "       \n",
        "        def parse_url(self, url):\n",
        "            response = requests.get(url)\n",
        "            soup = BeautifulSoup(response.text, 'xml') #'html5lib', 'html.parser', lxml, lxml-xml, xml \n",
        "            return [(table['id'],self.parse_html_table(table))\\\n",
        "                    for table in soup.find_all('table')]\n",
        "\n",
        "        def parse_html_file(self, path, table_id = 'All'):\n",
        "            ''' This method extracts the tables from articles (i.e. path) and returns each table as a pandas dataFrame, along with its title and table headers'''\n",
        "\n",
        "            '''    **Parameters**\n",
        "\n",
        "                  path: *str*\n",
        "                      A string containing the path of the article to be extracted.\n",
        "                  table_id: *int* or 'All'\n",
        "                      The specific ID of table to be extracted or extract 'All' the tables\n",
        "                \n",
        "                **Returns**\n",
        "                A list of table properties (table title, pandas Dataframe, table headers)\n",
        "            '''\n",
        "            soup = BeautifulSoup(path, 'html5lib') ## lxml or html.parser or xml or html5lib\n",
        "            #'html5lib', 'html.parser', lxml, lxml-xml, xml \n",
        "\n",
        "            all_tables = soup.find_all('table')\n",
        "            all_divs = soup.find_all('div')\n",
        "            table_title_index_list, table_title_list = [], []\n",
        "            \n",
        "            for i in all_divs:\n",
        "              table_title = self.parse_html_table_title(i)\n",
        "              if table_title != None:\n",
        "                table_index = int(table_title.split('.')[0].split('Table')[1])\n",
        "\n",
        "                if table_index not in table_title_index_list:\n",
        "                  table_title_index_list.append(table_index)\n",
        "                  table_title_list.append(table_title)\n",
        "              else:\n",
        "                continue\n",
        "            \n",
        "            c_m_p = concrete_mortar_paste(table_title_list)\n",
        "\n",
        "            if table_id == 'All':\n",
        "              all_list = []\n",
        "              new_c_m_p = []\n",
        "              for table, title, c_mp in zip(all_tables, table_title_list, c_m_p):\n",
        "                try:\n",
        "                  all_list.append(self.parse_html_table(table, title, c_mp))                 \n",
        "                except:\n",
        "                  pass\n",
        "              return all_list\n",
        "            else:  \n",
        "              return self.parse_html_table(all_tables[table_id-1], table_title_list[table_id-1], c_m_p[table_id-1])\n",
        "\n",
        "\n",
        "        def parse_html_table_title(self, div): ## returns table name and title\n",
        "          \n",
        "          '''this method extracts the title of a table'''\n",
        "          \n",
        "          if div.find_all('table') != []:\n",
        "\n",
        "            if div.find_all('span') != []:\n",
        "\n",
        "              for spans in div.find_all('span'):\n",
        "\n",
        "                spans = str(spans)\n",
        "                if 'span class=\"label\"' in spans:\n",
        "                  spans_list = spans.split('span class=\"label\"')[1].split('</span>') ## this identifies the Table id\n",
        "                  table_id = spans_list[0]\n",
        "                                  \n",
        "                  \n",
        "                  if 'Table' in table_id:\n",
        "                    table_title = spans_list[1]\n",
        "                    table_title = BeautifulSoup(table_title)\n",
        "                    table_title = table_title.get_text()\n",
        "\n",
        "                    table_title = table_id+table_title\n",
        "                    table_title = table_title.replace('>', '')\n",
        "                    \n",
        "                    return table_title\n",
        "                   \n",
        "          return None\n",
        "\n",
        "        def parse_html_table(self, table, title, c_m_p):\n",
        "            \n",
        "            '''this method returns the table as pandas DataFrame and table headers'''\n",
        "            n_columns = 0\n",
        "            n_rows=0\n",
        "            column_names = []\n",
        "            sub_column_names= []\n",
        "            sub_sub_column_names = []\n",
        "            header_row_count = 0\n",
        "            first_non_header_row = [] \n",
        "            move_to_second_column = False\n",
        "\n",
        "            # Find number of rows and columns, we also find the column titles if we can\n",
        "\n",
        "            for row in table.find_all('tr'):\n",
        "                \n",
        "                # Determine the number of rows in the table\n",
        "                td_tags = row.find_all('td')\n",
        "\n",
        "                holder = 0 \n",
        "\n",
        "                if len(td_tags) >= holder: ### switched from 0 to 1 - assumes that every table has at least two columns\n",
        "                    n_rows+=1\n",
        "                    if n_columns == 0:\n",
        "                        # Set the number of columns for our table\n",
        "                        n_columns = len(td_tags)\n",
        "                        for the_column in td_tags: ## getting the first non header row\n",
        "                          first_non_header_row.append(the_column.get_text())                          \n",
        "                          move_to_second_column = True\n",
        "\n",
        "\n",
        "                        \n",
        "                # Handle column names if we find them\n",
        "                th_tags = row.find_all('th') \n",
        "                if len(th_tags) > 0 and len(column_names) == 0 and header_row_count == 0:\n",
        "                    for th in th_tags:\n",
        "                        column_names.append(th.get_text())                                              \n",
        "                    header_row_count += 1\n",
        "                \n",
        "                # Handle sub_column_names if we find them\n",
        "                elif len(th_tags) > 0 and len(sub_column_names) == 0 and header_row_count == 1:\n",
        "                    for th in th_tags:\n",
        "                      sub_column_names.append(th.get_text())\n",
        "                    header_row_count += 1                \n",
        "                \n",
        "                #Handles the second sub header if we find them\n",
        "                elif len(th_tags) > 0 and len(sub_sub_column_names) == 0 and header_row_count == 2: ## Cases where there are two sub headers\n",
        "                    for th in th_tags:\n",
        "                      sub_sub_column_names.append(th.get_text())                \n",
        "                \n",
        "\n",
        "            header_row_count = 0\n",
        "            colspan_column_names = []\n",
        "            colspan_sub_column_names = []\n",
        "            colspan_sub_sub_column_names = []\n",
        "\n",
        "            for row in table.find_all('tr'):\n",
        "                th_tags = row.find_all('th')\n",
        "                if header_row_count == 0: \n",
        "                  for th in th_tags:\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_column_names.append(1)\n",
        "                  header_row_count += 1\n",
        "\n",
        "                elif header_row_count == 1: \n",
        "                  for th in th_tags:\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_sub_column_names.append(1)                    \n",
        "                  header_row_count += 1\n",
        "\n",
        "                elif header_row_count == 2: \n",
        "                  for th in th_tags:\n",
        "\n",
        "                    if 'colspan' in th.attrs and th.attrs['colspan'].isdigit():\n",
        "                      col = int(th.attrs['colspan'])\n",
        "                      colspan_column_names.append(col)\n",
        "                    else:\n",
        "                      colspan_sub_sub_column_names.append(1)\n",
        "                  header_row_count += 1                  \n",
        "                    \n",
        "\n",
        "            def get_rid_of_empty_space(col_name, colspan):\n",
        "              new_col_name = []\n",
        "              new_colspan = []\n",
        "              \n",
        "              for i, j in zip(col_name, colspan):\n",
        "                if i != '':\n",
        "                  new_col_name.append(i)\n",
        "                  new_colspan.append(j)\n",
        "              return new_col_name, new_colspan\n",
        "\n",
        "            def update_empty_space_in_first_row(col_name, colspan):\n",
        "              new_col_name = []\n",
        "              new_colspan = []\n",
        "              use_old_approach = False\n",
        "              empyt_first_column = False\n",
        "              index_track = -1\n",
        "              for i, j in zip(col_name, colspan):\n",
        "                index_track+=1\n",
        "                \n",
        "                if i != '':\n",
        "                  new_col_name.append(i)\n",
        "                  new_colspan.append(j)\n",
        "                \n",
        "                else:  \n",
        "                  if index_track == 0:\n",
        "                    new_col_name.append('Mix / COMP')\n",
        "                    new_colspan.append(1)\n",
        "                    empyt_first_column = True\n",
        "                    use_old_approach = True\n",
        "                  \n",
        "                  else:\n",
        "                    if new_colspan[index_track-1] == 0:\n",
        "                      new_colspan[index_track-1] += 1\n",
        "                    else:\n",
        "                      new_col_name.append('BLANK HEADER')\n",
        "                      new_colspan.append(j)\n",
        "                                 \n",
        "              return new_col_name, new_colspan, use_old_approach\n",
        "            \n",
        "            column_names, colspan_column_names, use_old_approach = update_empty_space_in_first_row(column_names, colspan_column_names)            \n",
        "            \n",
        "            sub_column_names, colspan_sub_column_names = get_rid_of_empty_space(sub_column_names, colspan_sub_column_names)\n",
        "            \n",
        "            sub_sub_column_names, colspan_sub_sub_column_names = get_rid_of_empty_space(sub_sub_column_names, colspan_sub_sub_column_names)\n",
        "\n",
        "            ## Using method 1 to determine column names\n",
        "            if not use_old_approach and max(len(colspan_column_names), len(colspan_sub_column_names), len(colspan_sub_sub_column_names)) != 0: \n",
        "              columns = []\n",
        "              cols_col_index_rec = 0\n",
        "              sub_cols_index_rec = 0\n",
        "              sub_sub_cols_index_rec = 0\n",
        "              full_header_list = []\n",
        "              for col, span in zip(column_names, colspan_column_names):\n",
        "\n",
        "                if span == 1:\n",
        "                  columns.append(col)\n",
        "                  full_header_list.append([col])\n",
        "\n",
        "                else:\n",
        "                  holder_list= [[col]]\n",
        "                  holder_list.append(sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec])\n",
        "                                   \n",
        "                  for sub_index, sub_span in enumerate(colspan_sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec]):\n",
        "\n",
        "                    if sub_span == 1:\n",
        "                      columns.append(sub_column_names[sub_cols_index_rec+sub_index])\n",
        "\n",
        "                    else:\n",
        "                      holder_list.append(sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec])\n",
        "                      for sub_sub_index, sub_sub_span in enumerate(colspan_sub_sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec]):               \n",
        "                        columns.append(sub_sub_column_names[sub_sub_cols_index_rec+sub_sub_index])\n",
        "\n",
        "                  full_header_list.append(holder_list)\n",
        "                  sub_cols_index_rec += span\n",
        "                  sub_sub_cols_index_rec +=  sub_span\n",
        "            \n",
        "            ## Using method 2 (an older approach) to determine column names\n",
        "            else:\n",
        "              columns = old_approach(column_names, sub_column_names, sub_sub_column_names, n_columns)\n",
        "              cols_col_index_rec = 0\n",
        "              sub_cols_index_rec = 0\n",
        "              sub_sub_cols_index_rec = 0\n",
        "              full_header_list = []\n",
        "              for col, span in zip(column_names, colspan_column_names):\n",
        "                if span == 1:\n",
        "                  full_header_list.append([col])\n",
        "                else:\n",
        "                  holder_list= [[col]]\n",
        "                  holder_list.append(sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec])\n",
        "                                   \n",
        "                  for sub_index, sub_span in enumerate(colspan_sub_column_names[sub_cols_index_rec:span+sub_cols_index_rec]):\n",
        "\n",
        "                    if sub_span == 1:\n",
        "                      pass\n",
        "                  \n",
        "                    else:\n",
        "                      holder_list.append(sub_column_names[sub_sub_cols_index_rec:sub_span+sub_sub_cols_index_rec])\n",
        "                    sub_sub_cols_index_rec +=  sub_span\n",
        "                  full_header_list.append(holder_list)\n",
        "                  sub_cols_index_rec += span\n",
        "                  \n",
        "\n",
        "            def priority_headers(columns):\n",
        "              #switch_2 = 1\n",
        "              change_No = False\n",
        "              mix_headers =  [header for header in columns if any(head in header for head in headers_to_look_for) and not any('('+unit_+')' in header for unit_ in list_of_all_units)] ##gets all Ids\n",
        "              \n",
        "              new_columns = []\n",
        "              ##print('O')\n",
        "              for index, col in enumerate(columns):\n",
        "                if col in mix_headers:\n",
        "                  if mix_headers.count(col) > 1:\n",
        "                    new_columns.append('!'*index+str(col))\n",
        "                  else:\n",
        "                    new_columns.append(col)\n",
        "                else:\n",
        "                  new_columns.append(col)\n",
        "              #print('R', new_columns, columns)  \n",
        "              #columns = new_columns  \n",
        "              for index, col in enumerate(columns):\n",
        "                if 'No.' in columns and 'No.' not in col and any(header in col for header in headers_to_look_for):\n",
        "                  switch_2 = index\n",
        "                  change_No = True\n",
        "\n",
        "\n",
        "          \n",
        "              if 'No.' in columns and change_No: ##No and material/mix etc\n",
        "                switch_1 = columns.index('No.')\n",
        "                columns[switch_1] = 'No!'\n",
        "                ###print(columns)\n",
        "                return columns, switch_1, switch_2\n",
        "\n",
        "              else:\n",
        "                return columns, 1, 1\n",
        "\n",
        "            columns, switch_1, switch_2 = priority_headers(columns)\n",
        "            \n",
        "            ###print('SW', switch_1, switch_2)\n",
        "            \n",
        "\n",
        "\n",
        "            columns = remove_math_symbols(columns)\n",
        "            final_column_names = columns\n",
        "            df = pd.DataFrame(columns = columns,\n",
        "                              index= range(0,n_rows))\n",
        "            \n",
        "            #row_marker = 0\n",
        " \n",
        "\n",
        "            '''Here we build the tables'''\n",
        " \n",
        "            final_row_list = []\n",
        "            final_final_row_list = []\n",
        "            max_copy_rows = -1\n",
        "            \n",
        "            for row_marker, row in enumerate(table.find_all('tr')):\n",
        "                empty = True\n",
        "                column_marker = 0\n",
        "\n",
        "                if row_marker == 0:\n",
        "                  pass\n",
        "                \n",
        "                columns = row.find_all('td')\n",
        "                if len(columns) == len(final_column_names)-1:\n",
        "                  columns=row.find_all(['th', 'td'])\n",
        "\n",
        "\n",
        "                holder_row_list = []\n",
        "               \n",
        "                \n",
        "                if row_marker > max_copy_rows:\n",
        "                  final_final_row_list = []\n",
        "                  for column in columns:\n",
        "                      final_row_list = []\n",
        "                      if 'rowspan' in column.attrs and column.attrs['rowspan'].isdigit():\n",
        "                        number_row = int(column.attrs['rowspan'])                                              \n",
        "                        holder_row_list = [row_marker+ i for i in range(1, number_row)]\n",
        "\n",
        "                        for i in holder_row_list:\n",
        "                          final_row_list.append(i)\n",
        "                        \n",
        "                        final_final_row_list.append(final_row_list)\n",
        "                        max_copy_rows = max(final_row_list)\n",
        "\n",
        "                    \n",
        "                      else:\n",
        "                        final_final_row_list.append([])\n",
        "                        pass\n",
        "\n",
        "\n",
        "                confirm = True\n",
        "                for index, i in enumerate(final_final_row_list):\n",
        "                  if i == []:\n",
        "                    col_index_to_add = index \n",
        "                    confirm = False\n",
        "                    break\n",
        "                                \n",
        "                try:\n",
        "                  new_add_rows_name +=1\n",
        "                except:\n",
        "                  pass\n",
        "                \n",
        "                for col_index, column in enumerate(columns):\n",
        "\n",
        "                    if row_marker in final_final_row_list[col_index]:                      \n",
        "                      add_rows_name +=1                      \n",
        "                      df.iat[row_marker,column_marker] = copy_forward_list[col_index]+'-'+str(new_add_rows_name) #copy_forward+'-'+str(add_rows_name)                                             \n",
        "                      df.iat[row_marker,col_index+col_index_to_add] = column.get_text()\n",
        "\n",
        "                    elif final_final_row_list[col_index] == [] and len(columns) < n_columns:\n",
        "                       df.iat[row_marker,column_marker+col_index_to_add] = column.get_text()\n",
        "                    else:\n",
        "                      df.iat[row_marker,column_marker] = column.get_text()                      \n",
        "                      \n",
        "                      if column_marker == 0:\n",
        "                        copy_forward = column.get_text()\n",
        "                        add_rows_name = 0\n",
        "                        new_add_rows_name = 0\n",
        "                        copy_forward_list = []                        \n",
        "                      copy_forward_list.append(column.get_text())\n",
        "\n",
        "                    column_marker += 1\n",
        "\n",
        "            # Convert to float if possible\n",
        "            for col in df:\n",
        "                try:\n",
        "                    df[col] = df[col].astype(float)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            df.dropna(0, 'all', inplace=True)\n",
        "\n",
        "            if switch_1 == 0:\n",
        "              df = df_column_switch(df, df.columns[switch_1], df.columns[switch_2])\n",
        "              final_column_names = list(df.columns)\n",
        "\n",
        "            \n",
        "            column_is_header = column_checkers(df)\n",
        "            is_first_column_a_header = column_is_header[0]\n",
        "            \n",
        "            \n",
        "            ### this section fills the column and sub_column_names and determines units\n",
        "\n",
        "            if  'BLANK HEADER' not in df.columns:\n",
        "              pass \n",
        "\n",
        "            else:\n",
        "              if is_first_column_a_header and len(sub_column_names) > len(sub_sub_column_names):\n",
        "                if sub_column_names[0] == 'BLANK HEADER':\n",
        "                  final_column_names = [column_names[0]]+sub_column_names[1:]                  \n",
        "                else:  \n",
        "                  final_column_names = [column_names[0]]+sub_column_names\n",
        "                df.columns = final_column_names\n",
        "              elif is_first_column_a_header and len(sub_column_names) < len(sub_sub_column_names):\n",
        "                final_column_names = [column_names[0]]+sub_sub_column_names\n",
        "                df.columns = final_column_names\n",
        "            \n",
        "            if len(sub_column_names) >= len(sub_sub_column_names):\n",
        "              likely_unit_col = column_names\n",
        "              likely_colspan = colspan_column_names\n",
        "            elif len(sub_column_names) < len(sub_sub_column_names):\n",
        "              likely_unit_col = sub_column_names\n",
        "              likely_colspan = colspan_sub_column_names\n",
        "\n",
        "\n",
        "\n",
        "            number_of_same_entries = sum(x == y for x, y in zip(final_column_names, likely_unit_col))\n",
        "            if number_of_same_entries != 0 and number_of_same_entries != len(final_column_names):\n",
        "              if check_units(likely_unit_col).count('No unit') == len(likely_unit_col): ##checking if units are in title\n",
        "                the_unit = check_units(title)\n",
        "                omit_unit = ['No.', 'Mix'] ## names of column that generally dont have units\n",
        "                for index, col in enumerate(final_column_names):\n",
        "                  if not column_is_header[index] and not check_units(col, True):\n",
        "                    final_column_names[index] = col +'('+the_unit+')'\n",
        "                    df.columns = final_column_names\n",
        "              else:\n",
        "                the_unit = check_units(likely_unit_col)\n",
        "                for index_p, i in enumerate(range(number_of_same_entries, len(likely_unit_col))):\n",
        "                  from_ = likely_colspan[i-1]*index_p+number_of_same_entries\n",
        "                  try:\n",
        "                    if the_unit[i+1] == 'No unit':\n",
        "                      to_ = from_+ likely_colspan[i]+1\n",
        "                    else:\n",
        "                      to_ = from_+ likely_colspan[i]\n",
        "\n",
        "                  except:\n",
        "                      to_ = from_+ likely_colspan[i]\n",
        "                  \n",
        "                  for index, col in zip(range(from_,to_), final_column_names[from_:to_]):\n",
        "                    if not check_units(col, True):\n",
        "                      final_column_names[index] = likely_unit_col[i]+'/'+ col +'('+the_unit[i]+')'\n",
        "                    else:\n",
        "                      final_column_names[index] = likely_unit_col[i]+'/'+ col\n",
        "                df.columns = final_column_names             \n",
        "            \n",
        "            else:\n",
        "              if check_units(likely_unit_col).count('No unit') == len(likely_unit_col): ##checking if units are in title\n",
        "                the_unit = check_units(title)\n",
        "                omit_unit = ['No.', 'Mix'] ## names of column that generally dont have units\n",
        "                for index, col in enumerate(final_column_names):\n",
        "                  if not column_is_header[index] and not check_units(col, True):\n",
        "                    final_column_names[index] = col +'('+the_unit+')'\n",
        "                    df.columns = final_column_names\n",
        "              else:\n",
        "                pass\n",
        "            \n",
        "\n",
        "\n",
        "            df = swap_first_and_second_column(df)\n",
        "\n",
        "            # ##print('1')\n",
        "            # #display(df)\n",
        "\n",
        "            df = convert_ids_to_string(df)\n",
        "\n",
        "            # ##print('2')\n",
        "            # #display(df)\n",
        "\n",
        "\n",
        "            if should_table_be_transposed(df):              \n",
        "              new_df, new_full_header_list = transpose_table(df)\n",
        "              new_df = make_first_colname_material(new_df)\n",
        "              new_df.columns = clean_table_headers(new_df.columns)\n",
        "              return [title, new_df, column_is_header, new_full_header_list, c_m_p]\n",
        "\n",
        "            df.columns = clean_table_headers(df.columns)\n",
        "            pot_new_df, t_f, new_col_added = special_table(df) \n",
        "\n",
        "            # ##print('3')\n",
        "            # #display(df)\n",
        "\n",
        "            if t_f:\n",
        "              df = pot_new_df.copy(deep = True)\n",
        "            if new_col_added:\n",
        "              column_is_header.append(True)\n",
        "              full_header_list.append([df.columns[-1]])\n",
        "            df = make_first_colname_material(df)\n",
        "\n",
        "            # ##print('4')\n",
        "            # #display(df)\n",
        "\n",
        "            if omit_table(df):\n",
        "              #display(df)\n",
        "              raise Exception('This table has too many empty cells so it wasnt extracted')\n",
        "\n",
        "            \n",
        "            df = sandwhich_table(df, full_header_list, df.columns)\n",
        "            \n",
        "            # ##print('5')\n",
        "            # #display(df)            \n",
        "            \n",
        "            ###print(title, df, column_is_header, full_header_list, c_m_p)\n",
        "            \n",
        "            return [title, df, column_is_header, full_header_list, c_m_p]\n"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXZAN1FEI0Gz"
      },
      "source": [
        "**Step 2 (Link all article Tables by mixture codes):** This process links each table in an article by their mixture identification (e.g. Mix no.) and chemical compositions of raw materials (e.g. OPC and FAM). This results in a aggregated table for each article containing its studied mixtures, their associated material and compositional properties, article DOI, and the article title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6I2D-eBsxoR"
      },
      "source": [
        "class ExtractDF:\n",
        "\n",
        "    '''takes in a list of tuples - table properties i.e. title, df, column_rows_are_headers, list of headers and sub_headers, and whether to transpose the table or not\n",
        "     for each paper and links the tables together'''\n",
        "\n",
        "    def __init__(self, t_prop, article_title, article_doi):\n",
        "      self.t_prop = t_prop[0]#[0] #'''all tables are linked together'''\n",
        "      self.article_title = article_title\n",
        "      self.doi = article_doi      \n",
        "\n",
        "\n",
        "    def check_improper_table_heading(self):\n",
        "      '''this method updates the tabular headers for tables in a particular articles'''\n",
        "\n",
        "      \n",
        "      df_of_tables = [table[1] for table in self.t_prop]\n",
        "      df_headers = [[header for header in df.columns if any(head in header for head in headers_to_look_for) and not any('('+unit_+')' in header for unit_ in list_of_all_units)] for df in df_of_tables]\n",
        "      df_title = [table[0] for table in self.t_prop]\n",
        "\n",
        "      def update_id_with_title(title):\n",
        "        broken = title.split()\n",
        "        ###print(broken)\n",
        "        for index, breaks in enumerate(broken):\n",
        "          if any(breaks == unit for unit in list_of_all_units):\n",
        "            return ' '.join(broken[index-1:])\n",
        "          elif '%' in breaks:\n",
        "            return ' '.join(broken[index:])\n",
        "\n",
        "        try:\n",
        "          ###print('A')\n",
        "          return ' '.join(broken[:5]) ##first 5 entries\n",
        "        except:\n",
        "          ###print('Y')\n",
        "          return ' '.join(broken[:])\n",
        "              \n",
        "\n",
        "      update_headers = []\n",
        "      checker_list = []\n",
        "      for df1, headers1 in zip(df_of_tables, df_headers):\n",
        "        df1_cols = df1.columns\n",
        "        for df2, headers2 in zip(df_of_tables, df_headers):\n",
        "          df2_cols = df2.columns\n",
        "          if not df1.equals(df2):\n",
        "            for head1 in headers1:\n",
        "              df1_entry = list(df1[head1])\n",
        "              for head2 in headers2:\n",
        "                df2_entry = list(df2[head2])\n",
        "                similar_entry = len(set(df1_entry) & set(df2_entry))\n",
        "                if similar_entry > 0 and head2 != head1:\n",
        "                  new_entry = '/'.join(sorted([head1, head2]))\n",
        "                  old_entry = head1\n",
        "                  if list(df1.columns) not in checker_list: \n",
        "                    update_headers.append([df1, {old_entry: new_entry}])\n",
        "                    checker_list.append(list(df1.columns))\n",
        "      new_df = []\n",
        "      for df in df_of_tables:\n",
        "        got_it = False\n",
        "        for df_to_up in update_headers:\n",
        "          if df_to_up[0].equals(df):\n",
        "           df.rename(columns = df_to_up[1], inplace = True)\n",
        "           new_df.append(df)\n",
        "           got_it = True\n",
        "        if not got_it:\n",
        "          new_df.append(df)\n",
        "        \n",
        "      \n",
        "      new_df_mix_headers = [[header for header in df.columns if any(head in header for head in headers_to_look_for) and not any('('+unit_+')' in header for unit_ in list_of_all_units)] for df in new_df]\n",
        "      '''this method looks for tables that repeat the same columns and first column IDs - see '''\n",
        "      #CASE A same headers and first columns across each table\n",
        "      dict_ = {}\n",
        "      joined_col = []\n",
        "      for n_df, title in zip(new_df, df_title):\n",
        "        columns = ''.join(list(n_df.columns))\n",
        "        mix_ids = ''.join(map(str, list(n_df.iloc[:, 0]))) ##first col only \n",
        "        table_id = int(title.split('.')[0].split('Table')[-1])\n",
        "        joined_col.append([columns, mix_ids, table_id])\n",
        "      \n",
        "      tables_to_check = []\n",
        "      for col1 in joined_col:\n",
        "        for col2 in joined_col:\n",
        "          if col1[2] != col2[2] and len(common(col1[0], col2[0])) >= 0.9*max(len(col1[0]), len(col2[0])):\n",
        "            if len(common(col1[1], col2[1])) >= 0.9*max(len(col1[1]), len(col2[1])):\n",
        "              tables_to_check.append(col1[2])\n",
        "              tables_to_check.append(col2[2])\n",
        "\n",
        "      tables_to_check = list(set(tables_to_check))\n",
        "\n",
        "\n",
        "      for n_df, headers, title in zip(new_df, new_df_mix_headers, df_title):\n",
        "        if any('Table '+str(id) in title for id in tables_to_check):\n",
        "          new_mixture_ids = []\n",
        "\n",
        "          for mix in list(n_df.iloc[:, 0]):\n",
        "            #got_it = False\n",
        "            ###print('A', holder_rep\n",
        "            ###print(str(mix) + '-' + update_id_with_title(''.join(title.split('.')[1])))\n",
        "            try:\n",
        "              new_mix = str(mix) + '-' + update_id_with_title(''.join(title.split('.')[1]))\n",
        "            except:\n",
        "              new_mix = mix\n",
        "            new_mixture_ids.append(new_mix)          \n",
        "          n_df.iloc[:, 0] = new_mixture_ids\n",
        "        ##display(n_df)\n",
        "      #CASE B Same mixture ID-s within the table \n",
        "      for n_df, headers, title in zip(new_df, new_df_mix_headers, df_title):\n",
        "        columns = n_df.columns\n",
        "        repeat = [] \n",
        "        for index1, header in enumerate(headers):\n",
        "          index_of_header = get_index_positions(list(columns), header)\n",
        "          if len(index_of_header) == 1:\n",
        "            index_of_header = index_of_header[0]\n",
        "            mixture_entries = list(n_df[header])\n",
        "          else:  \n",
        "            repeat.append(header)\n",
        "            break\n",
        "\n",
        "          holder_new = []\n",
        "          holder_rep = []\n",
        "          for mixture in mixture_entries:\n",
        "            if mixture not in holder_new:\n",
        "              holder_new.append(mixture)\n",
        "            else:\n",
        "              holder_rep.append(mixture)\n",
        "          new_mixture_ids = []\n",
        "          for index, mix in enumerate(mixture_entries):\n",
        "\n",
        "            if mix in control_ids:\n",
        "              new_mix = mix + '-' + update_id_with_title(''.join(title.split('.')[1]))\n",
        "              new_mixture_ids.append(new_mix) \n",
        "             \n",
        "            elif mix in holder_rep and not isNaN(mix):\n",
        "              try:\n",
        "                new_mix = mix+'-'+columns[index_of_header+1]+'='+str(n_df.iloc[index, index_of_header+1])\n",
        "              except:\n",
        "                new_mix = mix+'-'+columns[index_of_header+-1]+'='+str(n_df.iloc[index, index_of_header-1])\n",
        "\n",
        "              new_mixture_ids.append(new_mix)\n",
        "            else:\n",
        "               new_mixture_ids.append(mix)\n",
        "\n",
        "          n_df.iloc[:, index_of_header] = new_mixture_ids\n",
        "          ##display(n_df)\n",
        "\n",
        "      for i, n_df in zip(list(range(len(self.t_prop))), new_df):\n",
        "        self.t_prop[i][1] = n_df\n",
        "      \n",
        "      return self.t_prop\n",
        "        \n",
        "\n",
        "    def extract_compositions(self):\n",
        "      '''this method extracts the composition of cement, fly ash and slag in the article'''\n",
        "\n",
        "      keep = []\n",
        "      n_compounds_to_look_for = compounds_to_look_for + keep  #+ list_of_all_units                            \n",
        "      combinations = [' ', '', '(', ' (']\n",
        "      new_comp = []\n",
        "      for comp in n_compounds_to_look_for:\n",
        "        n_l = [comb1+comp+comb2 for comb1 in combinations for comb2 in combinations]\n",
        "        new_comp = new_comp + n_l\n",
        "\n",
        "      n_compounds_to_look_for = n_compounds_to_look_for + new_comp\n",
        "      full_header_list = []\n",
        "      full_property_list = []\n",
        "      for table_id, table in enumerate(self.t_prop):\n",
        "        df = table[1]\n",
        "        table_columns = df.columns\n",
        "        first_col = table_columns[0]\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "          holder_list = []\n",
        "          header_list = []\n",
        "          for material in prop_dict.keys():\n",
        "            if any(prop in str(row[first_col]) for prop in prop_dict[material]): ##if material is in table \n",
        "             for cols in table_columns:\n",
        "               if any(comps in str(cols) for comps in n_compounds_to_look_for): ##composition is in row\n",
        "                full_property_list.append(row[cols])\n",
        "                if '(' in row[first_col] and '%' not in row[first_col]:\n",
        "                  full_header_list.append(cols +' in/for '+row[first_col].split('(')[0] + ' ('+material+')' )\n",
        "                else:\n",
        "                  full_header_list.append(cols +' in/for '+row[first_col] + ' ('+material+')' )\n",
        "      final_header = []\n",
        "\n",
        "      holder = []\n",
        "      holder_prop = []\n",
        "      for i, j in zip(full_header_list, full_property_list):\n",
        "        if j != '–' and j != np.nan:\n",
        "          material, compound = get_compound_and_material(i)\n",
        "          holder.append(compound +' in/for '+material)\n",
        "          holder_prop.append(j) \n",
        "      full_header_list = holder\n",
        "      full_property_list = holder_prop\n",
        "\n",
        "      for i in full_header_list:\n",
        "        to_add = set(i)\n",
        "        for j in to_add:\n",
        "          if j not in final_header:\n",
        "            final_header.append(j)\n",
        "\n",
        "      final_header = full_header_list\n",
        "      new_df = pd.DataFrame(columns = final_header)\n",
        "      final_row = [np.nan]*len(final_header)\n",
        "      for prop, prop_header in zip(full_property_list, full_header_list):\n",
        "          index_of_val = final_header.index(prop_header)\n",
        "          final_row[index_of_val] = prop\n",
        "      row_series = pd.Series(final_row, index = new_df.columns)\n",
        "\n",
        "      number_nan = row_series.isna().sum(axis = 0)\n",
        "      number_nan = final_row.count(np.nan)\n",
        "      new_df = new_df.append(row_series, ignore_index=True)\n",
        "      new_df = new_df.dropna(thresh=3)\n",
        "      new_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      return new_df\n",
        "\n",
        "    #def mixture_checker(columns):\n",
        "\n",
        "\n",
        "    def make_table(self):\n",
        "      ''''extracting propery data based on mixture identification'''\n",
        "\n",
        "      all_id_w_table = []\n",
        "      \n",
        "      # headers_to_look_for = ['code', 'ID', 'No.', 'Mix', 'Mixtures', 'Code', 'name', 'mix', 'Mixture', 'Notation']\n",
        "      \n",
        "      table_id_list = []\n",
        "      table_title_list= []\n",
        "      splitters = [' ', '/', '.']\n",
        "\n",
        "      for table_id, table in enumerate(self.t_prop):\n",
        "        table_id_list.append(int(table[0].split('.')[0].split('Table')[1]))\n",
        "        ids = []\n",
        "        table_title_list.append(table[0])\n",
        "        df_columns = table[1].columns\n",
        "        ##print(table[2], df_columns)\n",
        "        for splitter in splitters:\n",
        "          for index, col_header in enumerate(table[2]):\n",
        "              if col_header and any(item in df_columns[index].split(splitter) for item in headers_to_look_for) and not any('('+unit_+')' in df_columns[index].split(splitter) for unit_ in list_of_all_units): ## conditionals for \n",
        "                ###print(df_columns[index])\n",
        "                if list(df_columns).count(df_columns[index]) == 1:\n",
        "                  loop_around = table[1][df_columns[index]]\n",
        "                  \n",
        "                else:\n",
        "                  loop_around = table[1].iloc[:, index]\n",
        "                for entries in loop_around:\n",
        "                  if entries not in ids:\n",
        "                    ids.append(entries)\n",
        "        if ids != []:\n",
        "          t_id = int(table[0].split('.')[0].split('Table')[1])\n",
        "          all_id_w_table.append([ids, t_id])      \n",
        "\n",
        "      '''searching for which ids repeat across different tables'''\n",
        "      removable_characters = ['-', '–']\n",
        "      non_entry_characters = ['–', '–']\n",
        "      \n",
        "      for remove in non_entry_characters:\n",
        "        for index, i in enumerate(all_id_w_table):\n",
        "          try:\n",
        "            all_id_w_table[index][0].remove(remove)\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "      ignore_sims = [np.nan, '', 'BLANK', 'RAW CONSTITUENTS']\n",
        "      new_id_list_w_table = []\n",
        "      for remove in removable_characters:\n",
        "        for index, ids_in_table in enumerate(all_id_w_table):\n",
        "          compare_list = list(range(len(all_id_w_table)))\n",
        "          compare_list.remove(index)\n",
        "          ids_to_keep = []\n",
        "          for checking_index in compare_list:\n",
        "              for id1 in ids_in_table[0]:\n",
        "                 for id2 in all_id_w_table[checking_index][0]:\n",
        "                   checker = min(len(str(id1).replace(remove, '')), len(str(id2).replace(remove, '')))\n",
        "                   if len(common(str(id1), str(id2))) >= checker:\n",
        "                      ids_to_keep.append(id1)\n",
        "                   else:\n",
        "                      ids_to_keep.append(id1)        ### DELETE THIS CODE BLOCK IF EDITING                                 \n",
        "          holder_list = []\n",
        "          ids_to_keep = list(dict.fromkeys(ids_to_keep))\n",
        "          for i in ids_to_keep:\n",
        "            if i not in ignore_sims:\n",
        "              holder_list.append(i)\n",
        "          if holder_list != []:\n",
        "             new_id_list_w_table.append([holder_list, ids_in_table[1]])\n",
        "      dictm = {}\n",
        "      \n",
        "      if new_id_list_w_table == []:\n",
        "        new_id_list_w_table = all_id_w_table            \n",
        "\n",
        "      for index, table in enumerate(new_id_list_w_table):\n",
        "        holder = [table[1]]\n",
        "        for index2, table2 in enumerate(new_id_list_w_table):\n",
        "\n",
        "          if index != index2 or len(new_id_list_w_table) == 1:\n",
        "            \n",
        "            for entry in table[0]:\n",
        "              for entry2 in table2[0]:\n",
        "                if entry == entry2:\n",
        "                  if table2[1] not in holder:\n",
        "                    holder.append(table2[1])\n",
        "                dictm[entry] = holder\n",
        "\n",
        "      rows = []\n",
        "      rows_headers = []\n",
        "      headers = []\n",
        "      ###print(dictm.keys())\n",
        "      for key, value in zip(dictm.keys(), dictm.values()):        \n",
        "        for table in value:          \n",
        "          df = self.t_prop[table_id_list.index(table)][1]\n",
        "          for index, cols in enumerate(df.columns):\n",
        "            if list(df.columns).count(df.columns[index]) == 1: ## if col_name not repated in table\n",
        "                list_row = df.loc[df[cols] == key].values.flatten().tolist()\n",
        "                if len(df.columns) != len(list_row):\n",
        "                  number_rep = list_row.count(key)\n",
        "                  for i in range(number_rep):\n",
        "                    m_holder_list = list_row[i*len(df.columns):(i+1)*len(df.columns)]\n",
        "                    ###print(m_holder_list)\n",
        "                    ###print(key)\n",
        "                    index_of_key = m_holder_list.index(key)\n",
        "                    try: \n",
        "                      m_holder_list[index_of_key] = str(key)+'-'+str(df.columns[0])+'='+str(m_holder_list[0])\n",
        "                    except: \n",
        "                      m_holder_list[index_of_key] = str(key)+'-'+str(df.columns[index_of_key + 1])+'='+str(m_holder_list[index_of_key + 1])\n",
        "                    value.sort()\n",
        "                    \n",
        "                    str_value = ['['+str(v)+']' for v in value]\n",
        "                    table_number = ''.join(str_value)\n",
        "                         \n",
        "                    rows.append(m_holder_list+[table_number])\n",
        "                    rows_headers.append(df.columns.tolist()+['Table Entry'])\n",
        "                  list_row = []\n",
        "            else:\n",
        "                mask = df.iloc[:, index] == key\n",
        "                pos = np.flatnonzero(mask)\n",
        "                list_row = df.iloc[pos].values.flatten().tolist()\n",
        "            try:\n",
        "              if list_row != []:\n",
        "                value.sort()\n",
        "                \n",
        "                str_value = ['['+str(v)+']' for v in value]\n",
        "                table_number = ''.join(str_value)\n",
        "                                \n",
        "                rows.append(list_row+[table_number])\n",
        "                rows_headers.append(df.columns.tolist()+['Table Entry'])\n",
        "                for i in df.columns.tolist():\n",
        "                  if i not in headers:\n",
        "                    headers.append(i)\n",
        "              else:\n",
        "                continue\n",
        "            except:\n",
        "              continue\n",
        "      \n",
        "      ### spliting up rows with different IDS in each row\n",
        "      new_rows = []\n",
        "      new_rows_header = []\n",
        "      top_row_index = -1\n",
        "      row_index = -1 \n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "            top_row_index += 1\n",
        "            row_index = -1 \n",
        "            for row2, row_header2 in zip(rows, rows_headers):\n",
        "              row_index += 1 \n",
        "              for index_j, j in enumerate(row2):\n",
        "                if row[0] == j and row != row2 and (index_j != 0):\n",
        "                  for index_i, i in enumerate(row):\n",
        "                    if row_header2[index_j] == row_header[index_i]:# found the id that is present eslewhere or row_header2 == row_header:\n",
        "                      if row_header2.count(row_header2[index_j]) > 1: ## if header is repeated  in the row\n",
        "                        new_row_to_add = row2[index_j:]\n",
        "                        new_row_header_to_add = row_header2[index_j:]\n",
        "                        rows[row_index][index_j:] = '-'\n",
        "                        rows_headers[row_index][index_j:] = '-'                      \n",
        "                        if new_row_to_add not in new_rows:\n",
        "                          new_rows.append(new_row_to_add)\n",
        "                          new_rows_header.append(new_row_header_to_add)\n",
        "\n",
        "      rows = rows+new_rows\n",
        "      rows_headers = rows_headers + new_rows_header\n",
        "      \n",
        "\n",
        "      ## cleaning 0 - removing rows with different dash or blank characters \n",
        "      charac_to_remove = ['', '-', '–', '–', '–']\n",
        "      new_rows = []\n",
        "      new_rows_headers = []\n",
        "      index_a = -1\n",
        "      \n",
        "      for row, header in zip(rows, rows_headers):\n",
        "        index_a +=1\n",
        "        if len(row) != len(header):\n",
        "          continue\n",
        "        holder_list, holder_header = [], []\n",
        "        for index, entry in enumerate(row):\n",
        "           if entry not in charac_to_remove:\n",
        "             holder_list.append(entry)\n",
        "             holder_header.append(header[index])\n",
        "        new_rows.append(holder_list)\n",
        "        new_rows_headers.append(holder_header)\n",
        "\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_headers\n",
        "\n",
        "      \n",
        "\n",
        "      ## cleaning 1 - removing any repeated entries\n",
        "      new_rows = []\n",
        "      new_rows_headers = []\n",
        "      indexz = -1\n",
        "      \n",
        "      for row, header in zip(rows, rows_headers):\n",
        "        indexz += 1\n",
        "        new_row_entry = []\n",
        "        new_header_entry = []\n",
        "        for index, entry in enumerate(row):\n",
        "          if entry not in charac_to_remove:\n",
        "            new_row_entry.append(entry)\n",
        "            new_header_entry.append(header[index])\n",
        "\n",
        "        if new_row_entry not in new_rows:\n",
        "          new_rows.append(new_row_entry)\n",
        "          new_rows_headers.append(new_header_entry)\n",
        "        else:\n",
        "          continue\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_headers\n",
        "\n",
        "      # cleaning 2 - joining all rows with identical first entry i.e. ID\n",
        "      used = []\n",
        "      new_rows = []\n",
        "      new_rows_header = []\n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "          holder_row = row\n",
        "          holder_row_header = row_header\n",
        "          if row[0] not in used:\n",
        "            for row2, row_header2 in zip(rows, rows_headers):\n",
        "              if row != row2 and row[0] not in used:\n",
        "                if row[0] == row2[0]:\n",
        "                  holder_row = holder_row + row2[1:]\n",
        "                  holder_row_header = holder_row_header + row_header2[1:]\n",
        "            used.append(row[0])\n",
        "            new_rows.append(holder_row)\n",
        "            new_rows_header.append(holder_row_header)\n",
        "      rows = new_rows\n",
        "      rows_headers = new_rows_header\n",
        "\n",
        "      \n",
        "      import itertools\n",
        "      headers = []\n",
        "      for row in rows_headers:\n",
        "        for r in row:\n",
        "          if r not in headers: \n",
        "            headers.append(r)\n",
        "      \n",
        "      \n",
        "      new_df = pd.DataFrame(columns = headers)\n",
        "      for row, row_header in zip(rows, rows_headers):\n",
        "          final_row = [np.nan]*len(headers)\n",
        "          for r, r_h in zip(row, row_header):\n",
        "            index_of_val = headers.index(r_h)\n",
        "            final_row[index_of_val] = r\n",
        "          row_series = pd.Series(final_row, index = new_df.columns)\n",
        "          new_df = new_df.append(row_series, ignore_index=True)\n",
        "      new_df = new_df.dropna(thresh=2)\n",
        "      new_df.reset_index(drop=True, inplace=True)\n",
        "      new_df['Article Title'] = len(new_df)*[self.article_title]\n",
        "      new_df['DOI'] = len(new_df)*[self.doi]\n",
        "\n",
        "      ### last step is grouping rows wit identical IDs###\n",
        "      to_group = []\n",
        "      non_group = []\n",
        "      for col in new_df.columns:\n",
        "        if any(ids in col for ids in headers_to_look_for):\n",
        "          to_group.append(col)\n",
        "        else:\n",
        "          non_group.append(col)\n",
        "      final_new_df = new_df\n",
        "      self.new_df = final_new_df\n",
        "      return final_new_df, table_title_list\n",
        "\n",
        "\n",
        "def join_comp_with_mix(mixtures, compositions):\n",
        "  if len(mixtures) != 0:\n",
        "    new_comp  = pd.DataFrame(np.repeat(compositions.values,len(mixtures),axis=0))\n",
        "    new_comp.columns  = compositions.columns\n",
        "    result = pd.concat([mixtures, new_comp], axis = 1)\n",
        "    return result\n",
        "  else:\n",
        "    return compositions\n",
        "\n",
        "def prettify(df):\n",
        "\n",
        "    df.columns = clean_table_headers(df.columns)\n",
        "    \n",
        "    comp_headers_to_look_for = [j for i in list(prop_dict.values()) for j in i]\n",
        "    \n",
        "\n",
        "    df_mix_headers = [header for header in df.columns if any(head in header for head in headers_to_look_for) and not any(head in header for head in comp_headers_to_look_for) and not any('('+unit_+')' in header for unit_ in list_of_all_units)]\n",
        "    ###print(df_mix_headers)\n",
        "    ###print(headers_to_look_for)\n",
        "    df_comp_headers = [header for header in df.columns if any(head in header for head in comp_headers_to_look_for)]\n",
        "\n",
        "    df_comp_headers = [header for header in df.columns if any(head in header for head in compounds_to_look_for)]\n",
        "    \n",
        "    headers_to_avoid = df_mix_headers+df_comp_headers+['Article Title', 'CONCRETE/MORTAR/PASTE', 'DOI']\n",
        "\n",
        "    ##print('A', df_mix_headers)\n",
        "    ##display(df)\n",
        "    for index, header in enumerate(df_mix_headers): #renaming all mixtures columns\n",
        "      new_entry = []\n",
        "      ###print(df[header])\n",
        "      for i in df[header]:\n",
        "          if '()' in str(i):\n",
        "            i = i.replace('()', '')\n",
        "            new_entry.append(i)\n",
        "          else:\n",
        "            new_entry.append(i)\n",
        "      ##print('B', new_entry)\n",
        "      df[header] = new_entry\n",
        "      df = df.rename(columns = {header: 'CODE/MIX TAG-'+str(index+1)})\n",
        "      headers_to_avoid.append('CODE/MIX TAG-'+str(index+1))\n",
        "\n",
        "    for index, header in enumerate(df_comp_headers):\n",
        "      df = df.rename(columns = {header: 'COMPOSITION: '+header})\n",
        "      headers_to_avoid.append('COMPOSITION: '+header)\n",
        "\n",
        "\n",
        "#    '''MIGHT NEED - DONT REMOVE!!!!!!\n",
        "    for header in df.columns:\n",
        "      if header not in headers_to_avoid:\n",
        "        df  = df.rename(columns = {header: 'PROPERTY: '+header})\n",
        "        #'''    \n",
        "\n",
        "    df.sort_index(axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "    if any(the_col.split('(')[0] in must_transpose for the_col in df[df.columns[0]]):\n",
        "      bs = [the_col.split('(')[0] in must_transpose for the_col in df[df.columns[0]]]\n",
        "      df = df.rename(columns = {df.columns[0]: 'RAW CONSTITUENTS'})\n"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t3alnqFJgb2"
      },
      "source": [
        "**Step 3 (ML-Clustering):** This final process involves merge all the aggregated article tables and gathering all the property headers (e.g. compression strength, Yield Stress) from this final table. We then use a ML-clustering algorithm to group property headers based on their lexical similarity and then assigning uniform labels to each cluster (a new property name). We perform this step because property headers are uniquely named across each research article, so there is a need to keep the naming consistent within our database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f1xUlEUZO4z"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, OPTICS, Birch\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import nltk, gensim\n",
        "#nltk.download('punkt')\n",
        "''' resources = https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm'''\n",
        "\n",
        "def ml_clustering_headers(df, algo = 'agglom', distance_threshold = 0.5, plot_dendo  = True, k = 20, num_feature = 10):\n",
        "  ''' this function runs a clustering algorithm on the table headers to derive a list of synonyms for properties extracted'''\n",
        "  ''' this function '''\n",
        "\n",
        "  '''    **Parameters**\n",
        "\n",
        "        1: *str*\n",
        "            A string containing the path of the article to be extracted.\n",
        "        \n",
        "        2: *int* or 'All'\n",
        "            The specific ID of table to be extracted or extract 'All' the tables\n",
        "      \n",
        "      **Returns**\n",
        "      A list of table properties (table title, pandas Dataframe, table headers)\n",
        "  '''\n",
        "  properties = df.columns.values.astype(\"U\")\n",
        "  new_properties = []\n",
        "  units_properties = []\n",
        "  avg_properties = []\n",
        "  to_omit = ['COMPOSITION', 'CODE/MIX TAG']\n",
        "  for prop in properties:\n",
        "    if not any(omit in prop for omit in to_omit):\n",
        "      prop = prop.split('PROPERTY:')[-1]\n",
        "      new_prop, unit = remove_unit(prop)\n",
        "      new_properties.append(new_prop)\n",
        "      units_properties.append(unit)\n",
        "\n",
        "  properties = []\n",
        "  for i,j,k in zip(new_properties, units_properties, avg_properties):\n",
        "    properties.append(i +' ' + j +' '+str(k))\n",
        "\n",
        "  properties = new_properties#.astype(\"U\")\n",
        "\n",
        "\n",
        "  ## Data preprocessing\n",
        "\n",
        "  from pint import UnitRegistry\n",
        "  ureg = UnitRegistry()\n",
        "  check = 10 * ureg('Pa')\n",
        "\n",
        "  ##change text data into unicode and getting feature vectors\n",
        "\n",
        "  ##Bag of words\n",
        "  vectorizer = CountVectorizer(stop_words='english')\n",
        "  features = vectorizer.fit_transform(properties) \n",
        "\n",
        "  ##Tdfif vectorizer - Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "  vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "  features = vectorizer.fit_transform(properties)\n",
        "  ##print(type(features))\n",
        "\n",
        "  ##word2vec features\n",
        "\n",
        "  w2vec_model = gensim.models.word2vec.Word2Vec(properties, size=300,   \n",
        "            window=8, min_count=1, sg=1, iter=30)\n",
        "  mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2vec_model)\n",
        "  #features = mean_embedding_vectorizer.fit_transform(properties) \n",
        "  ##print(features)\n",
        "  if algo == 'k_means':\n",
        "    model = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=1)\n",
        "    plot_dendo = False  \n",
        "  elif algo == 'agglom':\n",
        "    model =  AgglomerativeClustering(n_clusters=None, distance_threshold=distance_threshold)\n",
        "    features = features.toarray()\n",
        "  elif algo == 'DBSCAN':\n",
        "    model = DBSCAN(eps = 1.0, min_samples=1)\n",
        "    plot_dendo = False\n",
        "  elif algo == 'OPTICS':\n",
        "    model = OPTICS(min_samples =1)\n",
        "    features = features.toarray()\n",
        "    plot_dendo = False\n",
        "  elif algo == 'Birch':\n",
        "    model = Birch(threshold = distance_threshold+0.0, n_clusters=None)\n",
        "    features = features.toarray()\n",
        "    plot_dendo = False\n",
        "\n",
        "  model.fit(features)\n",
        "  \n",
        "  if plot_dendo:\n",
        "    plot_dendrogram(model)\n",
        "  \n",
        "\n",
        "  new_df = pd.DataFrame(columns = ['properties', 'cluster', 'terms'])\n",
        "  new_df['cluster'] = model.labels_\n",
        "  new_df['properties'] = properties\n",
        "\n",
        "  # order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "  terms = vectorizer.get_feature_names()\n",
        "\n",
        "  new_df.sort_values(['cluster'], inplace = True)\n",
        "  #display(new_df)\n",
        "\n",
        "  df_dict = {}\n",
        "  number_of_headers = len(new_df)\n",
        "  number_of_cluster = int(max(new_df['cluster']))\n",
        "  for i in range(number_of_cluster):\n",
        "    holder = new_df.loc[new_df['cluster'] == i]\n",
        "    ##print(holder)\n",
        "    df_dict[str(i)] = list(holder['properties']) \n",
        "  ##print(df_dict)\n",
        "  \n",
        "  final_df = pd.DataFrame.from_dict(df_dict, orient = 'index')\n",
        "  ##display(final_df)\n",
        "  f_name = str(number_of_headers)+'_headers_'+str(number_of_cluster)+'_clusters_birch-threshold_'+str(distance_threshold)+'.csv'\n",
        "  final_df.to_csv('/content/drive/My Drive/'+f_name, index = True)\n",
        "  \n",
        "  \n",
        "  #test = ['Tensile']\n",
        "  #vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "  test = vectorizer.transform(['Yield Paste 32 Stress']).toarray()\n",
        "  ##print(features, test)\n",
        "  ##print(model.predict(test), 'HERE')\n",
        "\n",
        "  derived_df = pd.read_csv('/content/drive/My Drive/'+f_name)\n",
        "  derived_df.rename(columns={ derived_df.columns[0]: \"Cluster\" }, inplace = True)\n",
        "\n",
        "  #display(derived_df)\n",
        "\n",
        "\n",
        "  #display(derived_df)\n",
        "  return new_df\n",
        "\n",
        "\n",
        "\n",
        "# A method for generating dendrogram\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    from scipy.cluster.hierarchy import dendrogram\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)\n",
        "\n",
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        transformed_X = []\n",
        "        for document in X:\n",
        "            tokenized_doc = []\n",
        "            for sent in nltk.sent_tokenize(document):\n",
        "                tokenized_doc += nltk.word_tokenize(sent)\n",
        "            transformed_X.append(np.array(tokenized_doc))\n",
        "        return np.array(transformed_X)\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        return self.transform(X)\n",
        "\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(word2vec.wv.syn0[0])\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = MyTokenizer().fit_transform(X)\n",
        "        \n",
        "        return np.array([\n",
        "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "    \n",
        "    def fit_transform(self, X, y=None):\n",
        "        return self.transform(X)\n"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2MKYeYVLYgZ"
      },
      "source": [
        "**Selecting 'ScienceDirect' files** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC2BqgmzLLA9"
      },
      "source": [
        "import os\n",
        "header_path = '/content/drive/My Drive/SERI_AI_Concrete/data_extraction/html/'\n",
        "list_of_html_files = os.listdir(header_path)\n",
        "content_of_html_files = []\n",
        "new_list_of_html_files = []\n",
        "for i in list_of_html_files:\n",
        "  if '.html' in i and 'ScienceDirect' in i:\n",
        "    contents = open(header_path+i, 'r').read()\n",
        "    content_of_html_files.append(contents)\n",
        "    new_list_of_html_files.append(i)\n",
        "list_of_html_files = new_list_of_html_files[:] "
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8kLmDP1K4JQ"
      },
      "source": [
        "**Processing a single Article**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJFxcAVOUVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29c8ab9b-31a3-4ebf-e141-51cfc101218f"
      },
      "source": [
        "  article = list_of_html_files[1] \n",
        "\n",
        "  article_name = article.split('.html')[0]\n",
        "  #print(article)\n",
        "  article, article1 = open(header_path+article, 'r'), open(header_path+article, 'r')  \n",
        "  #print(article)\n",
        "  doi = get_doi(article1)\n",
        "  #print(doi)\n",
        "  hp = HTMLTableParser()\n",
        "  #\n",
        "  \n",
        "  hp_table = hp.parse_html_file(article, table_id ='All')\n",
        "\n",
        "  # hp_table = hp.parse_html_file(article, table_id =4)  \n",
        "  # #display(hp_table[1])\n",
        "\n",
        "  \n",
        "  article_table = ExtractDF([hp_table], article_name, doi).check_improper_table_heading()\n",
        "  mixtures, tab_titles = ExtractDF([article_table], article_name, doi).make_table()\n",
        "  \n",
        "  ##display(mixtures)\n",
        "  \n",
        "  #clusters = ml_clustering_headers(mixtures, algo = 'Birch', k = 30) ## do not cluster for composition properties\n",
        "  ##print('COL/MAX number of clusters', len(clusters), '/',max(clusters['cluster'])+1)\n",
        "  \n",
        "  compositions = ExtractDF([article_table], article_name, doi).extract_compositions()\n",
        "  \n",
        "  ##display(compositions)\n",
        "  \n",
        "  mixtures = pandas_should_have_this(mixtures, tab_titles)\n",
        "  new_df = join_comp_with_mix(mixtures,  compositions)\n",
        "  #n_df = pandas_should_have_this(new_df, tab_titles)\n",
        "  ##display(n_df)\n",
        "  \n",
        "  ##display(new_df)\n",
        "  n_df = prettify(new_df)\n",
        "  \n",
        "  display(n_df)\n",
        "  \n",
        "  #ml_clustering_headers(n_df, k = 30)\n",
        "  #n_df = filter_prop(n_df)\n",
        "\n",
        "  #print(doi)\n",
        "\n",
        "  #ml_clustering_headers(n_df)"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Title</th>\n",
              "      <th>CODE/MIX TAG-1</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: CaO in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CaO in/for Slag</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Cement</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Loss on ignition in/for Slag</th>\n",
              "      <th>COMPOSITION: MgO in/for Cement</th>\n",
              "      <th>COMPOSITION: MgO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: MgO in/for Slag</th>\n",
              "      <th>COMPOSITION: SO3 in/for Cement</th>\n",
              "      <th>COMPOSITION: SO3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: SO3 in/for Slag</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Cement</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: SiO2 in/for Slag</th>\n",
              "      <th>DOI</th>\n",
              "      <th>PROPERTY: CONCRETE/PASTE/MORTAR</th>\n",
              "      <th>PROPERTY: Cement(%)</th>\n",
              "      <th>PROPERTY: Coarse Aggregate(%)</th>\n",
              "      <th>PROPERTY: Compressive Strength /28 d(MPa)</th>\n",
              "      <th>PROPERTY: Compressive Strength /3 d(MPa)</th>\n",
              "      <th>PROPERTY: Fine Aggregate(%)</th>\n",
              "      <th>PROPERTY: Fly Ash(%)</th>\n",
              "      <th>PROPERTY: Paste(%)</th>\n",
              "      <th>PROPERTY: Plastic Viscosity (Pa.s)</th>\n",
              "      <th>PROPERTY: Slag(%)</th>\n",
              "      <th>PROPERTY: Slump (mm)</th>\n",
              "      <th>PROPERTY: Table Entry</th>\n",
              "      <th>PROPERTY: Yield Stress (Pa)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.36</td>\n",
              "      <td>22.89</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.0</td>\n",
              "      <td>10.72</td>\n",
              "      <td>NaN</td>\n",
              "      <td>230.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>120.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>2</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>44.58</td>\n",
              "      <td>25.81</td>\n",
              "      <td>35.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>95.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>555.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>3</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>42.0</td>\n",
              "      <td>44.54</td>\n",
              "      <td>24.83</td>\n",
              "      <td>24.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.5</td>\n",
              "      <td>28.64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>125.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>364.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>4</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.0</td>\n",
              "      <td>42.85</td>\n",
              "      <td>24.95</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>15.53</td>\n",
              "      <td>NaN</td>\n",
              "      <td>205.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>223.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>5</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.0</td>\n",
              "      <td>41.67</td>\n",
              "      <td>24.47</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.0</td>\n",
              "      <td>21.51</td>\n",
              "      <td>NaN</td>\n",
              "      <td>195.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>247.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>6</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.0</td>\n",
              "      <td>43.11</td>\n",
              "      <td>23.17</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>155.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>312.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>7</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.57</td>\n",
              "      <td>22.14</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>21.79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>165.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>288.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>8</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.46</td>\n",
              "      <td>23.38</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>16.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>145.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>9</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.28</td>\n",
              "      <td>24.95</td>\n",
              "      <td>31.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>18.79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>160.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>339.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>I</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.70</td>\n",
              "      <td>25.13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.56</td>\n",
              "      <td>0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>286.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>II</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.22</td>\n",
              "      <td>10.11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.21</td>\n",
              "      <td>0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>250.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>III</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.52</td>\n",
              "      <td>11.64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.19</td>\n",
              "      <td>60</td>\n",
              "      <td>160.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>382.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>IV</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.67</td>\n",
              "      <td>15.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.04</td>\n",
              "      <td>0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>222.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>V</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.11</td>\n",
              "      <td>10.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.07</td>\n",
              "      <td>30</td>\n",
              "      <td>175.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>280.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>VI</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.09</td>\n",
              "      <td>16.81</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.95</td>\n",
              "      <td>30</td>\n",
              "      <td>170.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>264.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Mixture design of concrete using simplex centr...</td>\n",
              "      <td>VII</td>\n",
              "      <td>4.58</td>\n",
              "      <td>31.31</td>\n",
              "      <td>13.16</td>\n",
              "      <td>62.13</td>\n",
              "      <td>10.19</td>\n",
              "      <td>38.62</td>\n",
              "      <td>3.27</td>\n",
              "      <td>5.47</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.86</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>10.85</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.13</td>\n",
              "      <td>3.14</td>\n",
              "      <td>20.76</td>\n",
              "      <td>46.21</td>\n",
              "      <td>31.64</td>\n",
              "      <td>10.1016/j.cemconcomp.2018.03.001</td>\n",
              "      <td>CONCRETE</td>\n",
              "      <td>60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.29</td>\n",
              "      <td>13.39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.65</td>\n",
              "      <td>20</td>\n",
              "      <td>178.0</td>\n",
              "      <td>[2][3]</td>\n",
              "      <td>203.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Article Title  ... PROPERTY: Yield Stress (Pa)\n",
              "0   Mixture design of concrete using simplex centr...  ...                      120.29\n",
              "1   Mixture design of concrete using simplex centr...  ...                      555.18\n",
              "2   Mixture design of concrete using simplex centr...  ...                      364.71\n",
              "3   Mixture design of concrete using simplex centr...  ...                      223.11\n",
              "4   Mixture design of concrete using simplex centr...  ...                      247.86\n",
              "5   Mixture design of concrete using simplex centr...  ...                      312.25\n",
              "6   Mixture design of concrete using simplex centr...  ...                      288.50\n",
              "7   Mixture design of concrete using simplex centr...  ...                      145.68\n",
              "8   Mixture design of concrete using simplex centr...  ...                      339.42\n",
              "9   Mixture design of concrete using simplex centr...  ...                      286.58\n",
              "10  Mixture design of concrete using simplex centr...  ...                      250.37\n",
              "11  Mixture design of concrete using simplex centr...  ...                      382.92\n",
              "12  Mixture design of concrete using simplex centr...  ...                      222.51\n",
              "13  Mixture design of concrete using simplex centr...  ...                      280.85\n",
              "14  Mixture design of concrete using simplex centr...  ...                      264.64\n",
              "15  Mixture design of concrete using simplex centr...  ...                      203.31\n",
              "\n",
              "[16 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82wDf9CNLsbi"
      },
      "source": [
        "**Aggregating all articles** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrtkHXF4ow2q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36487188-fe68-4ecc-cdc8-d3339106bada"
      },
      "source": [
        "all_df = 0\n",
        "bad_mix = 0 \n",
        "bad_comp = 0 \n",
        "count_sci = 0\n",
        "count_succ = 0\n",
        "for article in list_of_html_files:  \n",
        "  if 'ScienceDirect' in article:\n",
        "    count_sci += 1\n",
        "    try:\n",
        "      article_name = article.split('.html')[0]\n",
        "      #print(article)\n",
        "      article, article1 = open(header_path+article, 'r'), open(header_path+article, 'r')  \n",
        "      doi = get_doi(article1)\n",
        "      hp = HTMLTableParser()\n",
        "\n",
        "      hp_table = hp.parse_html_file(article, table_id ='All')\n",
        "      #hp_table = hp.parse_html_file(article, table_id =1)\n",
        "      \n",
        "      article_table = ExtractDF([hp_table], article_name, doi).check_improper_table_heading()\n",
        "      mixtures, tab_titles = ExtractDF([article_table], article_name, doi).make_table()\n",
        "      if len(mixtures) == 0:\n",
        "        bad_mix += 1\n",
        "      #mixtures\n",
        "      #article_table\n",
        "      compositions = ExtractDF([article_table], article_name, doi).extract_compositions()\n",
        "      if len(compositions) == 0:\n",
        "        bad_comp += 1\n",
        "      ##display(compositions)\n",
        "      ##display(mixtures)\n",
        "      # new_df = join_comp_with_mix(mixtures,  compositions)\n",
        "\n",
        "      # n_df = pandas_should_have_this(new_df, tab_titles)\n",
        "      # n_df = prettify(n_df)\n",
        "\n",
        "      mixtures = pandas_should_have_this(mixtures, tab_titles)\n",
        "      new_df = join_comp_with_mix(mixtures,  compositions)      \n",
        "      \n",
        "      n_df = prettify(new_df)\n",
        "\n",
        "      try:\n",
        "        if all_df == 0:\n",
        "          all_df = n_df\n",
        "          mix_df = mixtures\n",
        "      except:\n",
        "        try:\n",
        "          all_df = all_df.append(n_df, sort = False, ignore_index = True)\n",
        "          mix_df = mix_df.append(mixtures, sort = False, ignore_index = True)\n",
        "        except:\n",
        "          all_df = all_df.append(n_df, sort = False, ignore_index = True)\n",
        "          mix_df = mix_df.append(mixtures, sort = False, ignore_index = True)\n",
        "\n",
        "          pass\n",
        "      count_succ += 1\n",
        "    except:\n",
        "      pass  \n",
        "all_df.sort_index(axis=1, inplace=True)\n",
        "thresh = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "thresh = [0.5]\n",
        "for i in thresh:\n",
        "  clusters = ml_clustering_headers(mix_df, algo = 'Birch', distance_threshold =i) ## do not cluster for composition properties\n",
        "  #print('COL/MAX number of clusters', len(clusters), '/',max(clusters['cluster'])+1)\n",
        "\n",
        "display(all_df)\n",
        "\n",
        "#print(count_succ, count_sci)\n",
        "all_df.sort_index(axis=1, inplace=True)\n",
        "#all_df.columns[421]\n",
        "all_df.columns\n",
        "print('SUCCESSFULLY EXTRACTED FILES', count_succ, 'out of', count_sci)\n",
        "#len(all_df.columns)\n",
        "# ## Next step is getting rid of repeated column entries"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mixture ID</th>\n",
              "      <th>Fitted ηθ for flexural strength</th>\n",
              "      <th>Fitted ηθ for tensile strength</th>\n",
              "      <th>Evaluated ηθ from image analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SF0-2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SF5-2</td>\n",
              "      <td>0.43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SF10-2</td>\n",
              "      <td>0.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SF15-2</td>\n",
              "      <td>0.62</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SF20-2</td>\n",
              "      <td>0.52</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SF25-2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Mixture ID  ...  Evaluated ηθ from image analysis\n",
              "1      SF0-2  ...                              0.35\n",
              "2      SF5-2  ...                               NaN\n",
              "3     SF10-2  ...                               NaN\n",
              "4     SF15-2  ...                               NaN\n",
              "5     SF20-2  ...                               NaN\n",
              "6     SF25-2  ...                               NaN\n",
              "\n",
              "[6 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fly ash source</th>\n",
              "      <th>Particle density (g/cm3)</th>\n",
              "      <th>SSA (m2/g)</th>\n",
              "      <th>IPV</th>\n",
              "      <th>Glassy phase (%)</th>\n",
              "      <th>[5]Fe2 + (mol)</th>\n",
              "      <th>[5]Fe3 + (mol)</th>\n",
              "      <th>cNM (mol)</th>\n",
              "      <th>nNF (mol)</th>\n",
              "      <th>I</th>\n",
              "      <th>28-day fc (MPa)</th>\n",
              "      <th>Notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Collie (West Australian)</td>\n",
              "      <td>2.40</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.470</td>\n",
              "      <td>52.420</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.356</td>\n",
              "      <td>0.687</td>\n",
              "      <td>0.79</td>\n",
              "      <td>53 ± 10</td>\n",
              "      <td>Ref. [18]fc was determined on the system with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.02</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.434</td>\n",
              "      <td>60.700</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.210</td>\n",
              "      <td>33 ± 8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.431</td>\n",
              "      <td>49.770</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.060</td>\n",
              "      <td>26 ± 4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gladstone (Queensland)</td>\n",
              "      <td>2.20</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.471</td>\n",
              "      <td>76.870</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.378</td>\n",
              "      <td>1.152</td>\n",
              "      <td>0.70</td>\n",
              "      <td>19 ± 2</td>\n",
              "      <td>Ref. [20]Density, SSA and IPV are calculated b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.416</td>\n",
              "      <td>67.500</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.325</td>\n",
              "      <td>1.007</td>\n",
              "      <td>0.390</td>\n",
              "      <td>7.5 ± 0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.60</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.391</td>\n",
              "      <td>67.360</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.053</td>\n",
              "      <td>1.113</td>\n",
              "      <td>0.050</td>\n",
              "      <td>4.5 ± 1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>FA1 (South Korea)</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.484</td>\n",
              "      <td>71.400</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.229</td>\n",
              "      <td>1.100</td>\n",
              "      <td>0.34</td>\n",
              "      <td>8.7 ± 2.2</td>\n",
              "      <td>Ref. [53]Density, SSA and IPV are estimated ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.25</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.508</td>\n",
              "      <td>80.800</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.676</td>\n",
              "      <td>1.060</td>\n",
              "      <td>1.230</td>\n",
              "      <td>41.6 ± 12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Fly ash source  ...                                              Notes\n",
              "1  Collie (West Australian)  ...  Ref. [18]fc was determined on the system with ...\n",
              "2                      2.02  ...                                                NaN\n",
              "3                      2.00  ...                                                NaN\n",
              "4    Gladstone (Queensland)  ...  Ref. [20]Density, SSA and IPV are calculated b...\n",
              "5                      2.00  ...                                                NaN\n",
              "6                      1.60  ...                                                NaN\n",
              "7         FA1 (South Korea)  ...  Ref. [53]Density, SSA and IPV are estimated ba...\n",
              "8                      2.25  ...                                                NaN\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C0 (MPa)</th>\n",
              "      <th>I1 (MPa)</th>\n",
              "      <th>P1 (MPa)</th>\n",
              "      <th>P2 (μm)</th>\n",
              "      <th>H1 (MPa)</th>\n",
              "      <th>H2 (MPa)</th>\n",
              "      <th>H3 (μm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>78.0</td>\n",
              "      <td>−66.8</td>\n",
              "      <td>12.9</td>\n",
              "      <td>10.59</td>\n",
              "      <td>24.0</td>\n",
              "      <td>33.8</td>\n",
              "      <td>11.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78.0-1</td>\n",
              "      <td>−82.3</td>\n",
              "      <td>12.9-1</td>\n",
              "      <td>26.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78.0-2</td>\n",
              "      <td>−94.8</td>\n",
              "      <td>12.9-2</td>\n",
              "      <td>10.10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>78.0-3</td>\n",
              "      <td>−103.8</td>\n",
              "      <td>12.9-3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  C0 (MPa) I1 (MPa) P1 (MPa)  P2 (μm)  H1 (MPa)  H2 (MPa)  H3 (μm)\n",
              "2     78.0    −66.8     12.9    10.59      24.0      33.8    11.02\n",
              "3   78.0-1    −82.3   12.9-1    26.80       NaN       NaN      NaN\n",
              "4   78.0-2    −94.8   12.9-2    10.10       NaN       NaN      NaN\n",
              "5   78.0-3   −103.8   12.9-3     0.00       NaN       NaN      NaN"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:205: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:178: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>properties</th>\n",
              "      <th>cluster</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flow spread</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Flow rate</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Flow value</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Flow time (s)</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Slump</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Quantity /mix NC</td>\n",
              "      <td>145</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Quantity /mix VM</td>\n",
              "      <td>145</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Yield stress (kPa)</td>\n",
              "      <td>146</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>Yield load (N)</td>\n",
              "      <td>147</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>Yield stress (MPa × 10−3)</td>\n",
              "      <td>148</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    properties  cluster terms\n",
              "1                 Flow spread         0   NaN\n",
              "2                   Flow rate         1   NaN\n",
              "76                 Flow value         2   NaN\n",
              "140              Flow time (s)        3   NaN\n",
              "18                      Slump         3   NaN\n",
              "..                         ...      ...   ...\n",
              "65           Quantity /mix NC       145   NaN\n",
              "66           Quantity /mix VM       145   NaN\n",
              "75          Yield stress (kPa)      146   NaN\n",
              "106             Yield load (N)      147   NaN\n",
              "107  Yield stress (MPa × 10−3)      148   NaN\n",
              "\n",
              "[270 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cluster</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Flow spread</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Flow rate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Flow value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Flow time (s)</td>\n",
              "      <td>Slump</td>\n",
              "      <td>Slump-flow</td>\n",
              "      <td>Slump flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flow energy Y.Sa (N.mm)</td>\n",
              "      <td>Flow energy Ub (N.mm)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>Silica fume  (x5)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>144</td>\n",
              "      <td>Dynamic yield stress τ0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145</td>\n",
              "      <td>Quantity /mix NC</td>\n",
              "      <td>Quantity /mix VM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>146</td>\n",
              "      <td>Yield stress (kPa)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>147</td>\n",
              "      <td>Yield load (N)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cluster                          0                      1  ...   15   16   17\n",
              "0          0               Flow spread                     NaN  ...  NaN  NaN  NaN\n",
              "1          1                 Flow rate                     NaN  ...  NaN  NaN  NaN\n",
              "2          2                Flow value                     NaN  ...  NaN  NaN  NaN\n",
              "3          3              Flow time (s)                 Slump   ...  NaN  NaN  NaN\n",
              "4          4    Flow energy Y.Sa (N.mm)  Flow energy Ub (N.mm)  ...  NaN  NaN  NaN\n",
              "..       ...                        ...                    ...  ...  ...  ...  ...\n",
              "143      143          Silica fume  (x5)                    NaN  ...  NaN  NaN  NaN\n",
              "144      144  Dynamic yield stress τ0                      NaN  ...  NaN  NaN  NaN\n",
              "145      145          Quantity /mix NC       Quantity /mix VM   ...  NaN  NaN  NaN\n",
              "146      146         Yield stress (kPa)                    NaN  ...  NaN  NaN  NaN\n",
              "147      147             Yield load (N)                    NaN  ...  NaN  NaN  NaN\n",
              "\n",
              "[148 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cluster</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Flow spread</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Flow rate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Flow value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Flow time (s)</td>\n",
              "      <td>Slump</td>\n",
              "      <td>Slump-flow</td>\n",
              "      <td>Slump flow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flow energy Y.Sa (N.mm)</td>\n",
              "      <td>Flow energy Ub (N.mm)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>Silica fume  (x5)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>144</td>\n",
              "      <td>Dynamic yield stress τ0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145</td>\n",
              "      <td>Quantity /mix NC</td>\n",
              "      <td>Quantity /mix VM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>146</td>\n",
              "      <td>Yield stress (kPa)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>147</td>\n",
              "      <td>Yield load (N)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cluster                          0                      1  ...   15   16   17\n",
              "0          0               Flow spread                     NaN  ...  NaN  NaN  NaN\n",
              "1          1                 Flow rate                     NaN  ...  NaN  NaN  NaN\n",
              "2          2                Flow value                     NaN  ...  NaN  NaN  NaN\n",
              "3          3              Flow time (s)                 Slump   ...  NaN  NaN  NaN\n",
              "4          4    Flow energy Y.Sa (N.mm)  Flow energy Ub (N.mm)  ...  NaN  NaN  NaN\n",
              "..       ...                        ...                    ...  ...  ...  ...  ...\n",
              "143      143          Silica fume  (x5)                    NaN  ...  NaN  NaN  NaN\n",
              "144      144  Dynamic yield stress τ0                      NaN  ...  NaN  NaN  NaN\n",
              "145      145          Quantity /mix NC       Quantity /mix VM   ...  NaN  NaN  NaN\n",
              "146      146         Yield stress (kPa)                    NaN  ...  NaN  NaN  NaN\n",
              "147      147             Yield load (N)                    NaN  ...  NaN  NaN  NaN\n",
              "\n",
              "[148 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Title</th>\n",
              "      <th>CODE/MIX TAG-1</th>\n",
              "      <th>CODE/MIX TAG-2</th>\n",
              "      <th>CODE/MIX TAG-3</th>\n",
              "      <th>CODE/MIX TAG-4</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Limestone</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Sand</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Silica</th>\n",
              "      <th>COMPOSITION: Al2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: BaO in/for Cement</th>\n",
              "      <th>COMPOSITION: BaO in/for Sand</th>\n",
              "      <th>COMPOSITION: C2S in/for Cement</th>\n",
              "      <th>COMPOSITION: C3A in/for Cement</th>\n",
              "      <th>COMPOSITION: C3S in/for Cement</th>\n",
              "      <th>COMPOSITION: C4AF in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Cement</th>\n",
              "      <th>COMPOSITION: CaO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CaO in/for Limestone</th>\n",
              "      <th>COMPOSITION: CaO in/for Sand</th>\n",
              "      <th>COMPOSITION: CaO in/for Silica</th>\n",
              "      <th>COMPOSITION: CaO in/for Slag</th>\n",
              "      <th>COMPOSITION: Cl in/for Cement</th>\n",
              "      <th>COMPOSITION: Cl in/for Sand</th>\n",
              "      <th>COMPOSITION: Cr2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: CuO in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Cement</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Fly ash</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Limestone</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Sand</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Silica</th>\n",
              "      <th>COMPOSITION: Fe2O3 in/for Slag</th>\n",
              "      <th>COMPOSITION: K2O in/for Cement</th>\n",
              "      <th>COMPOSITION: K2O in/for Fly ash</th>\n",
              "      <th>COMPOSITION: K2O in/for Sand</th>\n",
              "      <th>COMPOSITION: K2O in/for Silica</th>\n",
              "      <th>COMPOSITION: K2O in/for Slag</th>\n",
              "      <th>COMPOSITION: LOI in/for Cement</th>\n",
              "      <th>COMPOSITION: LOI in/for Fly ash</th>\n",
              "      <th>...</th>\n",
              "      <th>PROPERTY: Test result/b  (h−1)</th>\n",
              "      <th>PROPERTY: Test result/df  (mm)</th>\n",
              "      <th>PROPERTY: Test result/rw  (h−1)</th>\n",
              "      <th>PROPERTY: Test result/τd  (Pa)</th>\n",
              "      <th>PROPERTY: Test result/τs  (Pa)</th>\n",
              "      <th>PROPERTY: Time taken to reach peak temperature (hours)</th>\n",
              "      <th>PROPERTY: Total CH(%)</th>\n",
              "      <th>PROPERTY: V-Funnel (s)</th>\n",
              "      <th>PROPERTY: W(kg/m)</th>\n",
              "      <th>PROPERTY: W/CM  by mass/ (ratio)</th>\n",
              "      <th>PROPERTY: Water</th>\n",
              "      <th>PROPERTY: Water (%) (x4)</th>\n",
              "      <th>PROPERTY: Water (g)</th>\n",
              "      <th>PROPERTY: Water (kg/m3)</th>\n",
              "      <th>PROPERTY: Water weight ratio</th>\n",
              "      <th>PROPERTY: Water(kg/m3)</th>\n",
              "      <th>PROPERTY: Water/binder(by cement weight)</th>\n",
              "      <th>PROPERTY: Yield Stress (Pa)</th>\n",
              "      <th>PROPERTY: Yield load (N)</th>\n",
              "      <th>PROPERTY: Yield stress (MPa × 10−3)</th>\n",
              "      <th>PROPERTY: Yield stress (Pa)</th>\n",
              "      <th>PROPERTY: Yield stress (kPa)</th>\n",
              "      <th>PROPERTY: [Na+]/mol/L</th>\n",
              "      <th>PROPERTY: [Si]/mol/L</th>\n",
              "      <th>PROPERTY: a [kPa]</th>\n",
              "      <th>PROPERTY: b [min− 1]</th>\n",
              "      <th>PROPERTY: b [mm]</th>\n",
              "      <th>PROPERTY: c (MPa)</th>\n",
              "      <th>PROPERTY: d [mm]</th>\n",
              "      <th>PROPERTY: h [mm]</th>\n",
              "      <th>PROPERTY: p-value</th>\n",
              "      <th>PROPERTY: st. dev. dry density</th>\n",
              "      <th>PROPERTY: st. dev. strength</th>\n",
              "      <th>PROPERTY: w/c</th>\n",
              "      <th>PROPERTY: w/p ratio (by mass)</th>\n",
              "      <th>PROPERTY: w/p ratio (by vol.)</th>\n",
              "      <th>PROPERTY: wet density</th>\n",
              "      <th>PROPERTY: α(%)</th>\n",
              "      <th>PROPERTY: σ (MPa)</th>\n",
              "      <th>PROPERTY: φ (degrees)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.225</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.257</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-0.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.289</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Effects of fly ash microsphere on rheology, ad...</td>\n",
              "      <td>M-0-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>26.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.7</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.6</td>\n",
              "      <td>5.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.321</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G70D</td>\n",
              "      <td>Blended cement with 70 % GGBS-3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.59</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G00-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>Effect of GGBS and curing conditions on streng...</td>\n",
              "      <td>G40-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>810 rows × 331 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Article Title  ... PROPERTY: φ (degrees)\n",
              "0    Effects of fly ash microsphere on rheology, ad...  ...                   NaN\n",
              "1    Effects of fly ash microsphere on rheology, ad...  ...                   NaN\n",
              "2    Effects of fly ash microsphere on rheology, ad...  ...                   NaN\n",
              "3    Effects of fly ash microsphere on rheology, ad...  ...                   NaN\n",
              "4    Effects of fly ash microsphere on rheology, ad...  ...                   NaN\n",
              "..                                                 ...  ...                   ...\n",
              "805  Effect of GGBS and curing conditions on streng...  ...                   NaN\n",
              "806  Effect of GGBS and curing conditions on streng...  ...                   NaN\n",
              "807  Effect of GGBS and curing conditions on streng...  ...                   NaN\n",
              "808  Effect of GGBS and curing conditions on streng...  ...                   NaN\n",
              "809  Effect of GGBS and curing conditions on streng...  ...                   NaN\n",
              "\n",
              "[810 rows x 331 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "SUCCESSFULLY EXTRACTED FILES 24 out of 33\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}